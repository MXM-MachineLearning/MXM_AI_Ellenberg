{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Definition:\n",
    "Let $A = \\begin{bmatrix}1 & 2 \\\\ 0 & 1\\end{bmatrix}$, $B = \\begin{bmatrix}1 & 0 \\\\ 2 & 1\\end{bmatrix}$.\n",
    "The group $\\Gamma \\coloneqq \\langle A,B\\rangle \\subseteq SL_2(\\mathbb{Z})$ is an index $12$ subgroup. The diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. \n",
    "\n",
    "We define $C = A^{-1}$ and $D = B^{-1}$.\n",
    "\n",
    "We can generate with any coset by starting at a representative from each coset and see if we get our way back to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REWARD = 100\n",
    "STEP_PENALTY = -1\n",
    "\n",
    "\n",
    "def getReward(matrix: np.array) -> int:\n",
    "    if (matrix == np.identity(2)).all():\n",
    "        return MAX_REWARD\n",
    "    else:\n",
    "        return STEP_PENALTY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from ../Data_Generation/Data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../Data_Generation/Data_files/'\n",
    "base_fp = base_dir + 'subset_sl2_Z.csv'\n",
    "test_fp = base_dir + 'subset_test_rows_SL2Z_Q_learn.csv'\n",
    "train_fp = base_dir + 'subset_train_rows_SL2Z_Q_learn.csv'\n",
    "\n",
    "df = pd.read_csv(base_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>-27.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>847 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      val1  val2  val3  val4\n",
       "9      1.0   0.0  -2.0   1.0\n",
       "22     5.0  -2.0   8.0  -3.0\n",
       "28     5.0 -12.0  -2.0   5.0\n",
       "34     1.0   2.0   2.0   5.0\n",
       "37     1.0  -2.0   2.0  -3.0\n",
       "...    ...   ...   ...   ...\n",
       "9949   1.0  -8.0   0.0   1.0\n",
       "9971 -27.0 -20.0  -4.0  -3.0\n",
       "9974  -7.0  30.0  -4.0  17.0\n",
       "9988  -7.0  24.0   2.0  -7.0\n",
       "9989   9.0   4.0   2.0   1.0\n",
       "\n",
       "[847 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = df[df['val1'] % 4 == 1]\n",
    "filter_df = filter_df[filter_df['val2'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val3'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val4'] % 4 == 1]\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/4qjwq93d3_58jrsktchrftsr0000gn/T/ipykernel_54776/3450575276.py:21: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  [int(cur_row['val1']), int(cur_row['val2'])],\n",
      "/var/folders/nc/4qjwq93d3_58jrsktchrftsr0000gn/T/ipykernel_54776/3450575276.py:22: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  [int(cur_row['val3']), int(cur_row['val4'])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500\teps: 0.951\tAvg rwd: -20.000\n",
      "Episode 1000\teps: 0.905\tAvg rwd: -19.274\n",
      "Episode 1500\teps: 0.861\tAvg rwd: -20.000\n",
      "Episode 2000\teps: 0.819\tAvg rwd: -18.872\n",
      "Episode 2500\teps: 0.779\tAvg rwd: -18.448\n",
      "Episode 3000\teps: 0.741\tAvg rwd: -18.872\n",
      "Episode 3500\teps: 0.705\tAvg rwd: -18.544\n",
      "Episode 4000\teps: 0.670\tAvg rwd: -19.636\n",
      "Episode 4500\teps: 0.638\tAvg rwd: -17.052\n",
      "Episode 5000\teps: 0.607\tAvg rwd: -18.294\n",
      "Episode 5500\teps: 0.577\tAvg rwd: -16.148\n",
      "Episode 6000\teps: 0.549\tAvg rwd: -17.178\n",
      "Episode 6500\teps: 0.522\tAvg rwd: -18.168\n",
      "Episode 7000\teps: 0.497\tAvg rwd: -15.420\n",
      "Episode 7500\teps: 0.472\tAvg rwd: -18.410\n",
      "Episode 8000\teps: 0.449\tAvg rwd: -18.188\n",
      "Episode 8500\teps: 0.427\tAvg rwd: -16.526\n",
      "Episode 9000\teps: 0.407\tAvg rwd: -17.724\n",
      "Episode 9500\teps: 0.387\tAvg rwd: -16.908\n",
      "Episode 10000\teps: 0.368\tAvg rwd: -14.976\n",
      "Episode 10500\teps: 0.350\tAvg rwd: -17.316\n",
      "Episode 11000\teps: 0.333\tAvg rwd: -17.718\n",
      "Episode 11500\teps: 0.317\tAvg rwd: -17.302\n",
      "Episode 12000\teps: 0.301\tAvg rwd: -16.528\n",
      "Episode 12500\teps: 0.286\tAvg rwd: -16.558\n",
      "Episode 13000\teps: 0.273\tAvg rwd: -16.054\n",
      "Episode 13500\teps: 0.259\tAvg rwd: -16.950\n",
      "Episode 14000\teps: 0.247\tAvg rwd: -17.656\n",
      "Episode 14500\teps: 0.235\tAvg rwd: -17.266\n",
      "Episode 15000\teps: 0.223\tAvg rwd: -16.482\n",
      "Episode 15500\teps: 0.212\tAvg rwd: -18.058\n",
      "Episode 16000\teps: 0.202\tAvg rwd: -17.252\n",
      "Episode 16500\teps: 0.192\tAvg rwd: -16.460\n",
      "Episode 17000\teps: 0.183\tAvg rwd: -15.696\n",
      "Episode 17500\teps: 0.174\tAvg rwd: -18.052\n",
      "Episode 18000\teps: 0.165\tAvg rwd: -16.086\n",
      "Episode 18500\teps: 0.157\tAvg rwd: -16.888\n",
      "Episode 19000\teps: 0.150\tAvg rwd: -18.428\n",
      "Episode 19500\teps: 0.142\tAvg rwd: -16.084\n",
      "Episode 20000\teps: 0.135\tAvg rwd: -16.486\n",
      "Episode 20500\teps: 0.129\tAvg rwd: -17.626\n",
      "Episode 21000\teps: 0.122\tAvg rwd: -16.468\n",
      "Episode 21500\teps: 0.116\tAvg rwd: -17.658\n",
      "Episode 22000\teps: 0.111\tAvg rwd: -18.046\n",
      "Episode 22500\teps: 0.105\tAvg rwd: -17.276\n",
      "Episode 23000\teps: 0.100\tAvg rwd: -16.846\n",
      "Episode 23500\teps: 0.095\tAvg rwd: -17.628\n",
      "Episode 24000\teps: 0.091\tAvg rwd: -15.278\n",
      "Episode 24500\teps: 0.086\tAvg rwd: -18.044\n",
      "Episode 25000\teps: 0.082\tAvg rwd: -17.640\n",
      "Episode 25500\teps: 0.078\tAvg rwd: -17.248\n",
      "Episode 26000\teps: 0.074\tAvg rwd: -16.850\n",
      "Episode 26500\teps: 0.071\tAvg rwd: -17.642\n",
      "Episode 27000\teps: 0.067\tAvg rwd: -18.422\n",
      "Episode 27500\teps: 0.064\tAvg rwd: -16.850\n",
      "Episode 28000\teps: 0.061\tAvg rwd: -16.468\n",
      "Episode 28500\teps: 0.058\tAvg rwd: -16.076\n",
      "Episode 29000\teps: 0.055\tAvg rwd: -18.416\n",
      "Episode 29500\teps: 0.052\tAvg rwd: -14.880\n",
      "Episode 30000\teps: 0.050\tAvg rwd: -17.246\n"
     ]
    }
   ],
   "source": [
    "env = TabularQEnv(k_sl2z_2s_gen, defaultdict(lambda: 0), getReward, MAX_REWARD)\n",
    "\n",
    "EPISODES = 30000\n",
    "LEARNING_RATE = .9\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .9999\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# adapted from ChatGPT\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        obs, reward, done = env.step(LEARNING_RATE, DISCOUNT_FACTOR, EPSILON, obs)\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if (i+1)%500 ==0 and i>0:\n",
    "        print(\"Episode {i}\\teps: {eps:.3f}\\tAvg rwd: {rwd:.3f}\".format(i=i+1, eps=EPSILON, rwd=sum(list(episode_reward_record))/500))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_Q_table(mat):\n",
    "    return env.Q_table[matrix_to_tuple(mat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924.623115508713"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_Q_table(k_sl2z_2s_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(base_fp)\n",
    "test_df['num_moves_Q_learning_needs'] = test_df.apply(lambda row: env.play(df_row_to_mat(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \n",
      "1.0\n",
      "Of these, the proportion of times where we learned a path that was < 20 moves: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \")\n",
    "print(sum(test_df['num_moves_Q_learning_needs']<=50)/test_df.shape[0])\n",
    "\n",
    "print(\"Of these, the proportion of times where we learned a path that was < 20 moves: \")\n",
    "# encouraging because all of these were generated as sequences of 30 moves\n",
    "# so we've found significantly faster paths back to the origin for almost all moves that we find a path to the origin \n",
    "print(sum(test_df['num_moves_Q_learning_needs']<20)/sum(test_df['num_moves_Q_learning_needs']<=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_info_states_csv(fname_i, of_train, of_test, Q_env, prop_train=0.7):\n",
    "    \"\"\"\n",
    "    Given CSV with various states and tabular-Q environment trained on a set containing those states, \n",
    "    estimate next best move + number of moves to identity, and append them to the state information.\n",
    "    Then, split that dataset into train/test and write to corresponding CSVs\n",
    "    Args:\n",
    "        fname_i: csv to append to\n",
    "        of_train: where to write final train csv\n",
    "        of_test: where to write final test csv\n",
    "        Q_env: TabularQEnv used to make predictons\n",
    "        prop_train: proportion of data to be used for training\n",
    "    \"\"\"\n",
    "    test_df = pd.read_csv(fname_i)\n",
    "    test_df['num_moves_Q_learning_needs'] = test_df.apply(\n",
    "        lambda row: Q_env.play(df_row_to_mat(row)), axis=1)\n",
    "    filtered_df = test_df[test_df['num_moves_Q_learning_needs'] != 100]\n",
    "    filtered_df['first_move_by_Q_learning'] = filtered_df.apply(\n",
    "        lambda row: Q_env.best_move(df_row_to_mat(row)), axis=1)\n",
    "\n",
    "    print(filtered_df.shape)\n",
    "\n",
    "    bound = int(filtered_df.shape[0] * prop_train)\n",
    "    train = filtered_df.iloc[1:bound]\n",
    "    test = filtered_df.iloc[bound:filtered_df.shape[0]]\n",
    "\n",
    "    train.to_csv(of_train, index=False)\n",
    "    test.to_csv(of_test, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mappend_info_states_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtest_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m, in \u001b[0;36mappend_info_states_csv\u001b[0;34m(fname_i, of_train, of_test, Q_env, prop_train)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mGiven CSV with various states and tabular-Q environment trained on a set containing those states, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mestimate next best move + number of moves to identity, and append them to the state information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    prop_train: proportion of data to be used for training\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fname_i)\n\u001b[0;32m---> 14\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_moves_Q_learning_needs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_row_to_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m test_df[test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_moves_Q_learning_needs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m     17\u001b[0m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_move_by_Q_learning\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: Q_env\u001b[38;5;241m.\u001b[39mbest_move(df_row_to_mat(row)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mappend_info_states_csv.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mGiven CSV with various states and tabular-Q environment trained on a set containing those states, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mestimate next best move + number of moves to identity, and append them to the state information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    prop_train: proportion of data to be used for training\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fname_i)\n\u001b[1;32m     14\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_moves_Q_learning_needs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mQ_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_row_to_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m test_df[test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_moves_Q_learning_needs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m     17\u001b[0m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_move_by_Q_learning\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: Q_env\u001b[38;5;241m.\u001b[39mbest_move(df_row_to_mat(row)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/repos/MXM_AI_Ellenberg/SL2_Z/Q_learning/../util.py:103\u001b[0m, in \u001b[0;36mTabularQEnv.play\u001b[0;34m(self, state, max_steps)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m i\n\u001b[1;32m    105\u001b[0m         state \u001b[38;5;241m=\u001b[39m apply_action(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_move(state)])\n",
      "File \u001b[0;32m~/Documents/code/repos/MXM_AI_Ellenberg/SL2_Z/Q_learning/../util.py:27\u001b[0m, in \u001b[0;36mis_done\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_done\u001b[39m(m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \n\u001b[1;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/numeric.py:2350\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n\u001b[1;32m   2349\u001b[0m yfin \u001b[38;5;241m=\u001b[39m isfinite(y)\n\u001b[0;32m-> 2350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xfin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myfin\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n\u001b[1;32m   2352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2504\u001b[0m, in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;124;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \n\u001b[1;32m   2503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "append_info_states_csv(base_fp,\n",
    "                       train_fp,\n",
    "                       test_fp,\n",
    "                       env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
