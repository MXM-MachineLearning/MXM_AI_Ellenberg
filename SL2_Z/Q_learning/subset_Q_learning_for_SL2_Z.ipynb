{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Definition:\n",
    "Let $A = \\begin{bmatrix}1 & 2 \\\\ 0 & 1\\end{bmatrix}$, $B = \\begin{bmatrix}1 & 0 \\\\ 2 & 1\\end{bmatrix}$.\n",
    "The group $\\langle A,B\\rangle \\subseteq SL_2(\\mathbb{Z})$ is an index $12$ subgroup. The diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. \n",
    "\n",
    "We define $C = A^{-1}$ and $D = B^{-1}$.\n",
    "\n",
    "We can generate with any coset by starting at a representative from each coset and see if we get our way back to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_tuple(matrix: np.array) -> tuple:\n",
    "    return (matrix[0][0], matrix[0][1], \n",
    "            matrix[1][0], matrix[1][1]) \n",
    "\n",
    "def tuple_to_matrix(tuple: tuple) -> np.array:\n",
    "    return np.array([[tuple[0], tuple[1]], [tuple[2], tuple[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 12 according to alex's paper. Is it congruent to identity mod 2 or mod 4?\n",
    "# can generate with any coset I want by starting at a representative from each coset and see if we get our way back to it\n",
    "A = np.array([[1, 2], [0, 1]])\n",
    "B = np.array([[1, 0], [2, 1]])\n",
    "\n",
    "# elements on the diagonal are 1 mod 4. \n",
    "# elements not on the diagonal are 0 mod 2. \n",
    "\n",
    "# C is the inverse of A\n",
    "# D is the inverse of B\n",
    "C = np.linalg.inv(A)\n",
    "D = np.linalg.inv(B)\n",
    "\n",
    "identity = np.array([[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_search(Epsilon: float, qtable: dict, state: np.array) -> int:\n",
    "    '''\n",
    "    Makes a random step with probability Epsilon, and otherwise makes the best move from the Q_table.\n",
    "    (exploration vs exploitation)\n",
    "    '''\n",
    "    if (random.random() < Epsilon):\n",
    "        # 0 is 'apply matrix A', 1 is 'apply matrix B'\n",
    "        # 2 is 'apply matrix C', 3 is 'apply matrix D'\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    else:\n",
    "        # get the best move for the current state\n",
    "        return best_move_for_a_state(Q_table=qtable, state=state)\n",
    "    \n",
    "# I would like to return the best move for a given state\n",
    "def best_move_for_a_state(Q_table, state):\n",
    "    # vals = Q_table[(state[0][1], state[0][2], state[1][2])]\n",
    "\n",
    "    apply_A = state @ A\n",
    "    apply_B = state @ B\n",
    "    apply_C = state @ C\n",
    "    apply_D = state @ D\n",
    "\n",
    "    vals = [0, 0, 0, 0]\n",
    "    vals[0] = Q_table[matrix_to_tuple(apply_A)]\n",
    "    vals[1] = Q_table[matrix_to_tuple(apply_B)]\n",
    "    vals[2] = Q_table[matrix_to_tuple(apply_C)]\n",
    "    vals[3] = Q_table[matrix_to_tuple(apply_D)]\n",
    "\n",
    "    # if we haven't visited this state before, return a random choice of 0, 1, 2, or 3\n",
    "    if vals==[0, 0, 0, 0]:\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    \n",
    "    # if we have visited this state before, return the current best choice\n",
    "    return np.argmax(vals)\n",
    "\n",
    "# over a given state, return the maximum value of the table for that state\n",
    "def max_a_prime(Q_table, state):\n",
    "    apply_A = state @ A\n",
    "    apply_B = state @ B\n",
    "    apply_C = state @ C\n",
    "    apply_D = state @ D\n",
    "\n",
    "    vals = [0, 0, 0, 0]\n",
    "    vals[0] = Q_table[matrix_to_tuple(apply_A)]\n",
    "    vals[1] = Q_table[matrix_to_tuple(apply_B)]\n",
    "    vals[2] = Q_table[matrix_to_tuple(apply_C)]\n",
    "    vals[3] = Q_table[matrix_to_tuple(apply_D)]\n",
    "    \n",
    "    return max(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REWARD = 100\n",
    "STEP_PENALTY = -1\n",
    "\n",
    "def getReward(matrix: np.array) -> int:\n",
    "    if (matrix == identity).all():\n",
    "        return MAX_REWARD\n",
    "    else:\n",
    "        return STEP_PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Generation/Data_files/subset_sl2_Z.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(oldObs: np.array, action: int) -> tuple[np.array, int, bool]:\n",
    "    '''\n",
    "    Apply matrix multiplication to take a step and get associated reward\n",
    "\n",
    "    returns: 3-tuple of the (step taken, associated reward of step, true if at identity)\n",
    "    '''\n",
    "\n",
    "    assert(action in [0, 1, 2, 3])\n",
    "\n",
    "    next_state = []\n",
    "    if action==0:\n",
    "        next_state = oldObs @ A\n",
    "    elif action==1:\n",
    "        next_state = oldObs @ B\n",
    "    elif action==2:\n",
    "        next_state = oldObs @ C\n",
    "    else:\n",
    "        next_state = oldObs @ D\n",
    "    curReward = getReward(next_state)\n",
    "    done = (curReward == MAX_REWARD)\n",
    "    return (next_state, curReward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mat(mat: np.array, index: int) -> np.array:\n",
    "    if index==0:\n",
    "        return mat @ A\n",
    "    elif index==1:\n",
    "        return mat @ B\n",
    "    elif index==2:\n",
    "        return mat @ C\n",
    "    elif index==3:\n",
    "        return mat @ D\n",
    "    raise ValueError(\"Index is not between 0 and 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>961.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>-3138.0</td>\n",
       "      <td>-11063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2209.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>-3802.0</td>\n",
       "      <td>-2475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1509.0</td>\n",
       "      <td>-4120.0</td>\n",
       "      <td>3652.0</td>\n",
       "      <td>-9971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9033.0</td>\n",
       "      <td>16024.0</td>\n",
       "      <td>-4198.0</td>\n",
       "      <td>-7447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-35.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>104501.0</td>\n",
       "      <td>43952.0</td>\n",
       "      <td>-22604.0</td>\n",
       "      <td>-9507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          val1     val2     val3     val4\n",
       "0         49.0   -226.0     18.0    -83.0\n",
       "1        961.0   3388.0  -3138.0 -11063.0\n",
       "2       2209.0   1438.0  -3802.0  -2475.0\n",
       "3         17.0      4.0    140.0     33.0\n",
       "4          1.0     -2.0      0.0      1.0\n",
       "...        ...      ...      ...      ...\n",
       "9995       1.0      0.0      8.0      1.0\n",
       "9996    1509.0  -4120.0   3652.0  -9971.0\n",
       "9997    9033.0  16024.0  -4198.0  -7447.0\n",
       "9998     -35.0    -48.0     -8.0    -11.0\n",
       "9999  104501.0  43952.0 -22604.0  -9507.0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['val1'] % 2 == 1) & (df['val2'] % 2 == 0) & (df['val3'] % 2 == 0) & (df['val4'] % 2 == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>961.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>-3138.0</td>\n",
       "      <td>-11063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2209.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>-3802.0</td>\n",
       "      <td>-2475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1509.0</td>\n",
       "      <td>-4120.0</td>\n",
       "      <td>3652.0</td>\n",
       "      <td>-9971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9033.0</td>\n",
       "      <td>16024.0</td>\n",
       "      <td>-4198.0</td>\n",
       "      <td>-7447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-35.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>104501.0</td>\n",
       "      <td>43952.0</td>\n",
       "      <td>-22604.0</td>\n",
       "      <td>-9507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          val1     val2     val3     val4\n",
       "0         49.0   -226.0     18.0    -83.0\n",
       "1        961.0   3388.0  -3138.0 -11063.0\n",
       "2       2209.0   1438.0  -3802.0  -2475.0\n",
       "3         17.0      4.0    140.0     33.0\n",
       "4          1.0     -2.0      0.0      1.0\n",
       "...        ...      ...      ...      ...\n",
       "9995       1.0      0.0      8.0      1.0\n",
       "9996    1509.0  -4120.0   3652.0  -9971.0\n",
       "9997    9033.0  16024.0  -4198.0  -7447.0\n",
       "9998     -35.0    -48.0     -8.0    -11.0\n",
       "9999  104501.0  43952.0 -22604.0  -9507.0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = df[df['val1'] % 4 == 1]\n",
    "filter_df = filter_df[filter_df['val2'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val3'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val4'] % 4 == 1]\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for the last 100 iterations: -96.29\n",
      "epsilon: 0.989950333757503\n",
      "Average reward for the last 100 iterations: -98.15\n",
      "epsilon: 0.9800996732739187\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9703470333764725\n",
      "Average reward for the last 100 iterations: -94.12\n",
      "epsilon: 0.9606914386955115\n",
      "Average reward for the last 100 iterations: -98.0\n",
      "epsilon: 0.9511319235669539\n",
      "Average reward for the last 100 iterations: -90.14\n",
      "epsilon: 0.9416675319357145\n",
      "Average reward for the last 100 iterations: -96.01\n",
      "epsilon: 0.9322973172600907\n",
      "Average reward for the last 100 iterations: -90.11\n",
      "epsilon: 0.9230203424170932\n",
      "Average reward for the last 100 iterations: -92.04\n",
      "epsilon: 0.9138356796087268\n",
      "Average reward for the last 100 iterations: -90.2\n",
      "epsilon: 0.9047424102692004\n",
      "Average reward for the last 100 iterations: -86.29\n",
      "epsilon: 0.89573962497306\n",
      "Average reward for the last 100 iterations: -94.07\n",
      "epsilon: 0.8868264233442354\n",
      "Average reward for the last 100 iterations: -94.27\n",
      "epsilon: 0.8780019139659949\n",
      "Average reward for the last 100 iterations: -92.26\n",
      "epsilon: 0.8692652142917918\n",
      "Average reward for the last 100 iterations: -88.57\n",
      "epsilon: 0.8606154505570021\n",
      "Average reward for the last 100 iterations: -86.1\n",
      "epsilon: 0.8520517576915366\n",
      "Average reward for the last 100 iterations: -90.18\n",
      "epsilon: 0.8435732792333273\n",
      "Average reward for the last 100 iterations: -78.57\n",
      "epsilon: 0.8351791672426676\n",
      "Average reward for the last 100 iterations: -86.24\n",
      "epsilon: 0.8268685822174137\n",
      "Average reward for the last 100 iterations: -82.88\n",
      "epsilon: 0.8186406930090225\n",
      "Average reward for the last 100 iterations: -78.32\n",
      "epsilon: 0.8104946767394292\n",
      "Average reward for the last 100 iterations: -88.47\n",
      "epsilon: 0.802429718718749\n",
      "Average reward for the last 100 iterations: -81.47\n",
      "epsilon: 0.7944450123638009\n",
      "Average reward for the last 100 iterations: -76.06\n",
      "epsilon: 0.78653975911744\n",
      "Average reward for the last 100 iterations: -79.24\n",
      "epsilon: 0.7787131683686925\n",
      "Average reward for the last 100 iterations: -67.88\n",
      "epsilon: 0.7709644573736867\n",
      "Average reward for the last 100 iterations: -83.71\n",
      "epsilon: 0.763292851177371\n",
      "Average reward for the last 100 iterations: -82.05\n",
      "epsilon: 0.7556975825360077\n",
      "Average reward for the last 100 iterations: -77.28\n",
      "epsilon: 0.7481778918404428\n",
      "Average reward for the last 100 iterations: -80.04\n",
      "epsilon: 0.7407330270401349\n",
      "Average reward for the last 100 iterations: -71.34\n",
      "epsilon: 0.7333622435679438\n",
      "Average reward for the last 100 iterations: -58.3\n",
      "epsilon: 0.7260648042656639\n",
      "Average reward for the last 100 iterations: -76.56\n",
      "epsilon: 0.7188399793103014\n",
      "Average reward for the last 100 iterations: -70.73\n",
      "epsilon: 0.7116870461410829\n",
      "Average reward for the last 100 iterations: -65.38\n",
      "epsilon: 0.7046052893871948\n",
      "Average reward for the last 100 iterations: -59.61\n",
      "epsilon: 0.6975940007962347\n",
      "Average reward for the last 100 iterations: -70.98\n",
      "epsilon: 0.690652479163381\n",
      "Average reward for the last 100 iterations: -63.25\n",
      "epsilon: 0.6837800302612622\n",
      "Average reward for the last 100 iterations: -48.62\n",
      "epsilon: 0.6769759667705286\n",
      "Average reward for the last 100 iterations: -46.21\n",
      "epsilon: 0.6702396082111141\n",
      "Average reward for the last 100 iterations: -65.04\n",
      "epsilon: 0.6635702808741777\n",
      "Average reward for the last 100 iterations: -49.82\n",
      "epsilon: 0.6569673177547274\n",
      "Average reward for the last 100 iterations: -47.27\n",
      "epsilon: 0.6504300584849119\n",
      "Average reward for the last 100 iterations: -57.98\n",
      "epsilon: 0.6439578492679773\n",
      "Average reward for the last 100 iterations: -43.33\n",
      "epsilon: 0.6375500428128791\n",
      "Average reward for the last 100 iterations: -52.73\n",
      "epsilon: 0.6312059982695464\n",
      "Average reward for the last 100 iterations: -29.99\n",
      "epsilon: 0.6249250811647913\n",
      "Average reward for the last 100 iterations: -30.09\n",
      "epsilon: 0.6187066633388536\n",
      "Average reward for the last 100 iterations: -29.32\n",
      "epsilon: 0.6125501228825772\n",
      "Average reward for the last 100 iterations: -39.44\n",
      "epsilon: 0.6064548440752141\n",
      "Average reward for the last 100 iterations: -38.24\n",
      "epsilon: 0.6004202173228442\n",
      "Average reward for the last 100 iterations: -37.03\n",
      "epsilon: 0.5944456390974114\n",
      "Average reward for the last 100 iterations: -27.49\n",
      "epsilon: 0.5885305118763617\n",
      "Average reward for the last 100 iterations: -19.07\n",
      "epsilon: 0.5826742440828869\n",
      "Average reward for the last 100 iterations: -23.26\n",
      "epsilon: 0.576876250026757\n",
      "Average reward for the last 100 iterations: -27.97\n",
      "epsilon: 0.5711359498457492\n",
      "Average reward for the last 100 iterations: -38.42\n",
      "epsilon: 0.5654527694476531\n",
      "Average reward for the last 100 iterations: -27.88\n",
      "epsilon: 0.559826140452854\n",
      "Average reward for the last 100 iterations: -26.52\n",
      "epsilon: 0.5542555001374916\n",
      "Average reward for the last 100 iterations: -17.97\n",
      "epsilon: 0.548740291377179\n",
      "Average reward for the last 100 iterations: -9.41\n",
      "epsilon: 0.5432799625912865\n",
      "Average reward for the last 100 iterations: -20.33\n",
      "epsilon: 0.5378739676877772\n",
      "Average reward for the last 100 iterations: 1.15\n",
      "epsilon: 0.532521766008588\n",
      "Average reward for the last 100 iterations: 5.63\n",
      "epsilon: 0.5272228222755642\n",
      "Average reward for the last 100 iterations: -10.71\n",
      "epsilon: 0.5219766065369207\n",
      "Average reward for the last 100 iterations: -5.02\n",
      "epsilon: 0.5167825941142447\n",
      "Average reward for the last 100 iterations: -4.47\n",
      "epsilon: 0.5116402655500194\n",
      "Average reward for the last 100 iterations: -0.79\n",
      "epsilon: 0.5065491065556748\n",
      "Average reward for the last 100 iterations: -6.66\n",
      "epsilon: 0.5015086079601511\n",
      "Average reward for the last 100 iterations: 3.39\n",
      "epsilon: 0.4965182656589779\n",
      "Average reward for the last 100 iterations: -5.09\n",
      "epsilon: 0.491577580563858\n",
      "Average reward for the last 100 iterations: -7.03\n",
      "epsilon: 0.4866860585527523\n",
      "Average reward for the last 100 iterations: -0.46\n",
      "epsilon: 0.4818432104204629\n",
      "Average reward for the last 100 iterations: -16.08\n",
      "epsilon: 0.4770485518297069\n",
      "Average reward for the last 100 iterations: 11.31\n",
      "epsilon: 0.47230160326267795\n",
      "Average reward for the last 100 iterations: 1.04\n",
      "epsilon: 0.46760188997308916\n",
      "Average reward for the last 100 iterations: -7.59\n",
      "epsilon: 0.4629489419386927\n",
      "Average reward for the last 100 iterations: -12.8\n",
      "epsilon: 0.45834229381427294\n",
      "Average reward for the last 100 iterations: -12.03\n",
      "epsilon: 0.4537814848851073\n",
      "Average reward for the last 100 iterations: -17.07\n",
      "epsilon: 0.4492660590208893\n",
      "Average reward for the last 100 iterations: 12.85\n",
      "epsilon: 0.44479556463011005\n",
      "Average reward for the last 100 iterations: -5.49\n",
      "epsilon: 0.44036955461489585\n",
      "Average reward for the last 100 iterations: 5.22\n",
      "epsilon: 0.4359875863262917\n",
      "Average reward for the last 100 iterations: -8.39\n",
      "epsilon: 0.4316492215199928\n",
      "Average reward for the last 100 iterations: -6.9\n",
      "epsilon: 0.42735402631251446\n",
      "Average reward for the last 100 iterations: -3.27\n",
      "epsilon: 0.4231015711378002\n",
      "Average reward for the last 100 iterations: -8.84\n",
      "epsilon: 0.4188914307042601\n",
      "Average reward for the last 100 iterations: -7.87\n",
      "epsilon: 0.41472318395223523\n",
      "Average reward for the last 100 iterations: 1.88\n",
      "epsilon: 0.4105964140118904\n",
      "Average reward for the last 100 iterations: -3.25\n",
      "epsilon: 0.406510708161521\n",
      "Average reward for the last 100 iterations: -15.58\n",
      "epsilon: 0.4024656577862749\n",
      "Average reward for the last 100 iterations: -2.03\n",
      "epsilon: 0.39846085833728956\n",
      "Average reward for the last 100 iterations: 11.39\n",
      "epsilon: 0.3944959092912299\n",
      "Average reward for the last 100 iterations: -7.29\n",
      "epsilon: 0.39057041411023374\n",
      "Average reward for the last 100 iterations: -3.4\n",
      "epsilon: 0.3866839802022521\n",
      "Average reward for the last 100 iterations: 6.04\n",
      "epsilon: 0.3828362188817869\n",
      "Average reward for the last 100 iterations: 1.26\n",
      "epsilon: 0.3790267453310186\n",
      "Average reward for the last 100 iterations: 3.6\n",
      "epsilon: 0.3752551785613178\n",
      "Average reward for the last 100 iterations: 10.45\n",
      "epsilon: 0.3715211413751451\n",
      "Average reward for the last 100 iterations: -9.86\n",
      "epsilon: 0.3678242603283259\n",
      "Average reward for the last 100 iterations: -15.08\n",
      "epsilon: 0.3641641656927023\n",
      "Average reward for the last 100 iterations: -4.76\n",
      "epsilon: 0.36054049141915495\n",
      "Average reward for the last 100 iterations: -9.6\n",
      "epsilon: 0.3569528751009966\n",
      "Average reward for the last 100 iterations: -0.49\n",
      "epsilon: 0.3534009579377257\n",
      "Average reward for the last 100 iterations: -17.62\n",
      "epsilon: 0.3498843846991425\n",
      "Average reward for the last 100 iterations: 9.22\n",
      "epsilon: 0.34640280368982374\n",
      "Average reward for the last 100 iterations: -6.86\n",
      "epsilon: 0.34295586671394696\n",
      "Average reward for the last 100 iterations: -6.47\n",
      "epsilon: 0.33954322904046974\n",
      "Average reward for the last 100 iterations: -16.45\n",
      "epsilon: 0.33616454936865003\n",
      "Average reward for the last 100 iterations: 0.98\n",
      "epsilon: 0.332819489793915\n",
      "Average reward for the last 100 iterations: -3.23\n",
      "epsilon: 0.32950771577406535\n",
      "Average reward for the last 100 iterations: 12.06\n",
      "epsilon: 0.326228896095818\n",
      "Average reward for the last 100 iterations: 8.61\n",
      "epsilon: 0.32298270284168096\n",
      "Average reward for the last 100 iterations: -7.01\n",
      "epsilon: 0.3197688113571579\n",
      "Average reward for the last 100 iterations: -0.65\n",
      "epsilon: 0.3165869002182801\n",
      "Average reward for the last 100 iterations: -2.71\n",
      "epsilon: 0.3134366511994595\n",
      "Average reward for the last 100 iterations: -12.81\n",
      "epsilon: 0.31031774924166283\n",
      "Average reward for the last 100 iterations: 22.3\n",
      "epsilon: 0.30722988242090343\n",
      "Average reward for the last 100 iterations: -14.22\n",
      "epsilon: 0.3041727419170432\n",
      "Average reward for the last 100 iterations: -12.24\n",
      "epsilon: 0.3011460219829101\n",
      "Average reward for the last 100 iterations: 24.69\n",
      "epsilon: 0.2981494199137175\n",
      "Average reward for the last 100 iterations: 17.23\n",
      "epsilon: 0.29518263601679207\n",
      "Average reward for the last 100 iterations: -9.95\n",
      "epsilon: 0.2922453735816008\n",
      "Average reward for the last 100 iterations: 5.27\n",
      "epsilon: 0.2893373388500768\n",
      "Average reward for the last 100 iterations: 7.76\n",
      "epsilon: 0.28645824098724004\n",
      "Average reward for the last 100 iterations: 13.76\n",
      "epsilon: 0.2836077920521105\n",
      "Average reward for the last 100 iterations: 16.9\n",
      "epsilon: 0.28078570696891186\n",
      "Average reward for the last 100 iterations: 9.82\n",
      "epsilon: 0.27799170349856034\n",
      "Average reward for the last 100 iterations: 20.22\n",
      "epsilon: 0.2752255022104372\n",
      "Average reward for the last 100 iterations: 1.52\n",
      "epsilon: 0.27248682645444433\n",
      "Average reward for the last 100 iterations: 1.7\n",
      "epsilon: 0.2697754023333332\n",
      "Average reward for the last 100 iterations: -3.96\n",
      "epsilon: 0.2670909586753151\n",
      "Average reward for the last 100 iterations: 5.91\n",
      "epsilon: 0.2644332270069402\n",
      "Average reward for the last 100 iterations: -4.29\n",
      "epsilon: 0.26180194152624664\n",
      "Average reward for the last 100 iterations: 16.81\n",
      "epsilon: 0.2591968390761776\n",
      "Average reward for the last 100 iterations: -15.63\n",
      "epsilon: 0.2566176591182636\n",
      "Average reward for the last 100 iterations: 8.23\n",
      "epsilon: 0.2540641437065648\n",
      "Average reward for the last 100 iterations: 9.59\n",
      "epsilon: 0.2515360374618739\n",
      "Average reward for the last 100 iterations: 2.36\n",
      "epsilon: 0.24903308754617642\n",
      "Average reward for the last 100 iterations: -7.72\n",
      "epsilon: 0.24655504363736244\n",
      "Average reward for the last 100 iterations: -15.16\n",
      "epsilon: 0.24410165790419308\n",
      "Average reward for the last 100 iterations: -12.04\n",
      "epsilon: 0.24167268498151395\n",
      "Average reward for the last 100 iterations: 9.84\n",
      "epsilon: 0.2392678819457161\n",
      "Average reward for the last 100 iterations: -14.82\n",
      "epsilon: 0.2368870082904414\n",
      "Average reward for the last 100 iterations: -3.49\n",
      "epsilon: 0.23452982590252897\n",
      "Average reward for the last 100 iterations: 15.99\n",
      "epsilon: 0.2321960990382015\n",
      "Average reward for the last 100 iterations: 4.3\n",
      "epsilon: 0.22988559429948774\n",
      "Average reward for the last 100 iterations: 6.1\n",
      "epsilon: 0.2275980806108809\n",
      "Average reward for the last 100 iterations: -9.58\n",
      "epsilon: 0.2253333291962282\n",
      "Average reward for the last 100 iterations: -4.2\n",
      "epsilon: 0.22309111355585096\n",
      "Average reward for the last 100 iterations: 14.09\n",
      "epsilon: 0.2208712094438921\n",
      "Average reward for the last 100 iterations: 2.41\n",
      "epsilon: 0.2186733948458889\n",
      "Average reward for the last 100 iterations: -5.25\n",
      "epsilon: 0.2164974499565696\n",
      "Average reward for the last 100 iterations: 0.42\n",
      "epsilon: 0.2143431571578701\n",
      "Average reward for the last 100 iterations: 9.78\n",
      "epsilon: 0.21221030099717023\n",
      "Average reward for the last 100 iterations: 10.77\n",
      "epsilon: 0.2100986681657454\n",
      "Average reward for the last 100 iterations: 7.69\n",
      "epsilon: 0.2080080474774341\n",
      "Average reward for the last 100 iterations: -9.79\n",
      "epsilon: 0.20593822984751717\n",
      "Average reward for the last 100 iterations: 6.6\n",
      "epsilon: 0.20388900827180606\n",
      "Average reward for the last 100 iterations: -18.96\n",
      "epsilon: 0.20186017780594118\n",
      "Average reward for the last 100 iterations: 12.03\n",
      "epsilon: 0.19985153554489493\n",
      "Average reward for the last 100 iterations: 2.6\n",
      "epsilon: 0.19786288060267845\n",
      "Average reward for the last 100 iterations: 8.81\n",
      "epsilon: 0.19589401409225174\n",
      "Average reward for the last 100 iterations: -5.52\n",
      "epsilon: 0.19394473910563204\n",
      "Average reward for the last 100 iterations: -5.26\n",
      "epsilon: 0.19201486069420162\n",
      "Average reward for the last 100 iterations: -15.93\n",
      "epsilon: 0.1901041858492102\n",
      "Average reward for the last 100 iterations: -5.23\n",
      "epsilon: 0.1882125234824722\n",
      "Average reward for the last 100 iterations: 6.59\n",
      "epsilon: 0.18633968440725585\n",
      "Average reward for the last 100 iterations: 8.33\n",
      "epsilon: 0.18448548131936265\n",
      "Average reward for the last 100 iterations: -7.18\n",
      "epsilon: 0.1826497287783945\n",
      "Average reward for the last 100 iterations: -9.22\n",
      "epsilon: 0.1808322431892079\n",
      "Average reward for the last 100 iterations: -4.71\n",
      "epsilon: 0.17903284278355266\n",
      "Average reward for the last 100 iterations: 2.43\n",
      "epsilon: 0.17725134760189254\n",
      "Average reward for the last 100 iterations: 0.5\n",
      "epsilon: 0.1754875794754081\n",
      "Average reward for the last 100 iterations: 0.84\n",
      "epsilon: 0.17374136200817725\n",
      "Average reward for the last 100 iterations: 6.78\n",
      "epsilon: 0.17201252055953417\n",
      "Average reward for the last 100 iterations: 4.47\n",
      "epsilon: 0.17030088222660275\n",
      "Average reward for the last 100 iterations: -5.16\n",
      "epsilon: 0.16860627582700524\n",
      "Average reward for the last 100 iterations: -14.5\n",
      "epsilon: 0.16692853188174173\n",
      "Average reward for the last 100 iterations: 8.82\n",
      "epsilon: 0.16526748259824006\n",
      "Average reward for the last 100 iterations: 0.8\n",
      "epsilon: 0.1636229618535754\n",
      "Average reward for the last 100 iterations: 20.03\n",
      "epsilon: 0.16199480517785583\n",
      "Average reward for the last 100 iterations: 6.45\n",
      "epsilon: 0.16038284973777372\n",
      "Average reward for the last 100 iterations: 13.9\n",
      "epsilon: 0.15878693432032062\n",
      "Average reward for the last 100 iterations: 6.25\n",
      "epsilon: 0.1572068993166638\n",
      "Average reward for the last 100 iterations: 8.7\n",
      "epsilon: 0.15564258670618408\n",
      "Average reward for the last 100 iterations: 19.59\n",
      "epsilon: 0.15409384004067206\n",
      "Average reward for the last 100 iterations: -10.69\n",
      "epsilon: 0.15256050442868138\n",
      "Average reward for the last 100 iterations: -2.59\n",
      "epsilon: 0.1510424265200381\n",
      "Average reward for the last 100 iterations: -0.85\n",
      "epsilon: 0.14953945449050376\n",
      "Average reward for the last 100 iterations: 6.99\n",
      "epsilon: 0.1480514380265917\n",
      "Average reward for the last 100 iterations: -4.7\n",
      "epsilon: 0.14657822831053363\n",
      "Average reward for the last 100 iterations: -6.93\n",
      "epsilon: 0.14511967800539669\n",
      "Average reward for the last 100 iterations: 5.05\n",
      "epsilon: 0.14367564124034787\n",
      "Average reward for the last 100 iterations: -1.27\n",
      "epsilon: 0.14224597359606533\n",
      "Average reward for the last 100 iterations: 10.36\n",
      "epsilon: 0.1408305320902949\n",
      "Average reward for the last 100 iterations: -14.28\n",
      "epsilon: 0.13942917516355058\n",
      "Average reward for the last 100 iterations: -8.66\n",
      "epsilon: 0.1380417626649567\n",
      "Average reward for the last 100 iterations: -10.85\n",
      "epsilon: 0.13666815583823175\n",
      "Average reward for the last 100 iterations: 13.0\n",
      "epsilon: 0.13530821730781062\n",
      "Average reward for the last 100 iterations: -10.99\n",
      "epsilon: 0.1339618110651063\n",
      "Average reward for the last 100 iterations: 12.38\n",
      "epsilon: 0.13262880245490677\n",
      "Average reward for the last 100 iterations: 8.82\n",
      "epsilon: 0.13130905816190905\n",
      "Average reward for the last 100 iterations: 1.07\n",
      "epsilon: 0.1300024461973849\n",
      "Average reward for the last 100 iterations: -8.44\n",
      "epsilon: 0.1287088358859816\n",
      "Average reward for the last 100 iterations: 17.03\n",
      "epsilon: 0.12742809785265258\n",
      "Average reward for the last 100 iterations: 6.78\n",
      "epsilon: 0.12616010400971825\n",
      "Average reward for the last 100 iterations: 8.9\n",
      "epsilon: 0.1249047275440563\n",
      "Average reward for the last 100 iterations: -0.82\n",
      "epsilon: 0.12366184290441894\n",
      "Average reward for the last 100 iterations: 1.0\n",
      "epsilon: 0.12243132578887629\n",
      "Average reward for the last 100 iterations: -9.09\n",
      "epsilon: 0.12121305313238478\n",
      "Average reward for the last 100 iterations: -4.66\n",
      "epsilon: 0.1200069030944797\n",
      "Average reward for the last 100 iterations: 16.43\n",
      "epsilon: 0.11881275504708917\n",
      "Average reward for the last 100 iterations: 8.5\n",
      "epsilon: 0.11763048956247056\n",
      "Average reward for the last 100 iterations: 1.34\n",
      "epsilon: 0.11645998840126634\n",
      "Average reward for the last 100 iterations: -4.96\n",
      "epsilon: 0.11530113450067855\n",
      "Average reward for the last 100 iterations: 4.92\n",
      "epsilon: 0.11415381196276177\n",
      "Average reward for the last 100 iterations: 7.26\n",
      "epsilon: 0.11301790604283157\n",
      "Average reward for the last 100 iterations: 6.97\n",
      "epsilon: 0.11189330313798898\n",
      "Average reward for the last 100 iterations: -6.62\n",
      "epsilon: 0.11077989077575923\n",
      "Average reward for the last 100 iterations: 6.97\n",
      "epsilon: 0.10967755760284283\n",
      "Average reward for the last 100 iterations: 6.72\n",
      "epsilon: 0.10858619337397935\n",
      "Average reward for the last 100 iterations: 3.06\n",
      "epsilon: 0.10750568894092176\n",
      "Average reward for the last 100 iterations: 9.24\n",
      "epsilon: 0.10643593624151992\n",
      "Average reward for the last 100 iterations: 4.9\n",
      "epsilon: 0.1053768282889138\n",
      "Average reward for the last 100 iterations: 22.41\n",
      "epsilon: 0.1043282591608334\n",
      "Average reward for the last 100 iterations: 18.77\n",
      "epsilon: 0.10329012398900515\n",
      "Average reward for the last 100 iterations: 5.2\n",
      "epsilon: 0.10226231894866437\n",
      "Average reward for the last 100 iterations: 8.8\n",
      "epsilon: 0.10124474124817139\n",
      "Average reward for the last 100 iterations: 12.63\n",
      "epsilon: 0.10023728911873117\n",
      "Average reward for the last 100 iterations: 5.02\n",
      "epsilon: 0.09923986180421565\n",
      "Average reward for the last 100 iterations: -6.74\n",
      "epsilon: 0.0982523595510868\n",
      "Average reward for the last 100 iterations: 26.36\n",
      "epsilon: 0.09727468359842038\n",
      "Average reward for the last 100 iterations: 0.96\n",
      "epsilon: 0.09630673616802857\n",
      "Average reward for the last 100 iterations: 5.03\n",
      "epsilon: 0.09534842045468113\n",
      "Average reward for the last 100 iterations: 10.91\n",
      "epsilon: 0.09439964061642395\n",
      "Average reward for the last 100 iterations: 7.24\n",
      "epsilon: 0.09346030176499369\n",
      "Average reward for the last 100 iterations: 18.53\n",
      "epsilon: 0.09253030995632805\n",
      "Average reward for the last 100 iterations: -6.3\n",
      "epsilon: 0.09160957218117023\n",
      "Average reward for the last 100 iterations: 20.45\n",
      "epsilon: 0.09069799635576713\n",
      "Average reward for the last 100 iterations: 22.39\n",
      "epsilon: 0.08979549131265965\n",
      "Average reward for the last 100 iterations: 14.86\n",
      "epsilon: 0.08890196679156555\n",
      "Average reward for the last 100 iterations: 8.79\n",
      "epsilon: 0.08801733343035181\n",
      "Average reward for the last 100 iterations: 7.45\n",
      "epsilon: 0.0871415027560978\n",
      "Average reward for the last 100 iterations: -0.74\n",
      "epsilon: 0.0862743871762469\n",
      "Average reward for the last 100 iterations: 18.8\n",
      "epsilon: 0.08541589996984655\n",
      "Average reward for the last 100 iterations: -0.38\n",
      "epsilon: 0.08456595527887494\n",
      "Average reward for the last 100 iterations: 7.39\n",
      "epsilon: 0.08372446809965417\n",
      "Average reward for the last 100 iterations: 12.59\n",
      "epsilon: 0.08289135427434946\n",
      "Average reward for the last 100 iterations: 1.48\n",
      "epsilon: 0.08206653048255198\n",
      "Average reward for the last 100 iterations: 13.14\n",
      "epsilon: 0.08124991423294586\n",
      "Average reward for the last 100 iterations: 4.8\n",
      "epsilon: 0.08044142385505873\n",
      "Average reward for the last 100 iterations: 20.63\n",
      "epsilon: 0.07964097849109329\n",
      "Average reward for the last 100 iterations: -6.43\n",
      "epsilon: 0.07884849808784071\n",
      "Average reward for the last 100 iterations: 18.86\n",
      "epsilon: 0.07806390338867449\n",
      "Average reward for the last 100 iterations: -0.61\n",
      "epsilon: 0.0772871159256243\n",
      "Average reward for the last 100 iterations: 5.62\n",
      "epsilon: 0.07651805801152776\n",
      "Average reward for the last 100 iterations: 3.52\n",
      "epsilon: 0.07575665273226108\n",
      "Average reward for the last 100 iterations: 15.29\n",
      "epsilon: 0.07500282393904703\n",
      "Average reward for the last 100 iterations: 3.43\n",
      "epsilon: 0.0742564962408389\n",
      "Average reward for the last 100 iterations: -0.45\n",
      "epsilon: 0.07351759499678091\n",
      "Average reward for the last 100 iterations: -14.06\n",
      "epsilon: 0.07278604630874305\n",
      "Average reward for the last 100 iterations: 8.71\n",
      "epsilon: 0.07206177701393056\n",
      "Average reward for the last 100 iterations: 8.95\n",
      "epsilon: 0.07134471467756703\n",
      "Average reward for the last 100 iterations: 15.18\n",
      "epsilon: 0.07063478758564987\n",
      "Average reward for the last 100 iterations: 21.28\n",
      "epsilon: 0.06993192473777823\n",
      "Average reward for the last 100 iterations: -2.73\n",
      "epsilon: 0.06923605584005207\n",
      "Average reward for the last 100 iterations: -0.77\n",
      "epsilon: 0.06854711129804245\n",
      "Average reward for the last 100 iterations: -0.94\n",
      "epsilon: 0.0678650222098307\n",
      "Average reward for the last 100 iterations: 9.45\n",
      "epsilon: 0.0671897203591181\n",
      "Average reward for the last 100 iterations: 17.17\n",
      "epsilon: 0.0665211382084031\n",
      "Average reward for the last 100 iterations: 7.2\n",
      "epsilon: 0.06585920889222686\n",
      "Average reward for the last 100 iterations: 3.33\n",
      "epsilon: 0.06520386621048607\n",
      "Average reward for the last 100 iterations: 3.31\n",
      "epsilon: 0.06455504462181237\n",
      "Average reward for the last 100 iterations: 13.14\n",
      "epsilon: 0.06391267923701738\n",
      "Average reward for the last 100 iterations: 6.79\n",
      "epsilon: 0.0632767058126029\n",
      "Average reward for the last 100 iterations: 1.55\n",
      "epsilon: 0.06264706074433596\n",
      "Average reward for the last 100 iterations: 16.82\n",
      "epsilon: 0.06202368106088804\n",
      "Average reward for the last 100 iterations: -4.76\n",
      "epsilon: 0.061406504417536784\n",
      "Average reward for the last 100 iterations: 9.25\n",
      "epsilon: 0.06079546908993113\n",
      "Average reward for the last 100 iterations: 5.32\n",
      "epsilon: 0.060190513967918045\n",
      "Average reward for the last 100 iterations: 15.41\n",
      "epsilon: 0.059591578549431055\n",
      "Average reward for the last 100 iterations: 18.72\n",
      "epsilon: 0.05899860293443916\n",
      "Average reward for the last 100 iterations: 9.02\n",
      "epsilon: 0.05841152781895632\n",
      "Average reward for the last 100 iterations: 15.4\n",
      "epsilon: 0.05783029448911036\n",
      "Average reward for the last 100 iterations: -2.89\n",
      "epsilon: 0.057254844815271044\n",
      "Average reward for the last 100 iterations: 18.83\n",
      "epsilon: 0.056685121246236224\n",
      "Average reward for the last 100 iterations: 20.93\n",
      "epsilon: 0.05612106680347639\n",
      "Average reward for the last 100 iterations: -4.42\n",
      "epsilon: 0.055562625075436065\n",
      "Average reward for the last 100 iterations: -6.83\n",
      "epsilon: 0.0550097402118921\n",
      "Average reward for the last 100 iterations: 11.24\n",
      "epsilon: 0.05446235691836792\n",
      "Average reward for the last 100 iterations: -4.25\n",
      "epsilon: 0.05392042045060362\n",
      "Average reward for the last 100 iterations: 5.5\n",
      "epsilon: 0.053383876609080824\n",
      "Average reward for the last 100 iterations: 13.08\n",
      "epsilon: 0.052852671733602266\n",
      "Average reward for the last 100 iterations: 28.73\n",
      "epsilon: 0.052326752697925104\n",
      "Average reward for the last 100 iterations: 18.78\n",
      "epsilon: 0.051806066904447695\n",
      "Average reward for the last 100 iterations: 16.95\n",
      "epsilon: 0.051290562278949396\n",
      "Average reward for the last 100 iterations: -4.62\n",
      "epsilon: 0.05078018726538244\n",
      "Average reward for the last 100 iterations: -4.54\n",
      "epsilon: 0.050274890820715915\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 30000\n",
    "LEARNING_RATE = .9\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .9999\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# starts with an estimate of zero reward for each state.\n",
    "# adapted from ChatGPT\n",
    "Q_table = defaultdict(lambda: 0)\n",
    "\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        action = epsilon_greedy_search(Epsilon=EPSILON, qtable=Q_table, state=obs)\n",
    "\n",
    "        oldObs = obs\n",
    "        obs,reward,done = get_next_step(oldObs, action)\n",
    "\n",
    "        # if done:\n",
    "        #     assert(1==2)\n",
    "        \n",
    "        Q_table[matrix_to_tuple(obs)] = (1-LEARNING_RATE) * Q_table[matrix_to_tuple(obs)] + (LEARNING_RATE) * (reward + DISCOUNT_FACTOR * (max_a_prime(Q_table, obs)))\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if i%100 ==0 and i>0:\n",
    "        print(\"Average reward for the last 100 iterations: \" + str(sum(list(episode_reward_record))/100))\n",
    "        print(\"epsilon: \" + str(EPSILON) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_Q_table(mat):\n",
    "    return Q_table[matrix_to_tuple(mat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_Q_table(np.array([[1, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924.623115577806"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_Q_table(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(\"../Data_Generation/Data_files/subset_sl2_Z_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_num_steps(cur_matrix):\n",
    "    index = 1\n",
    "    for i in range(50):\n",
    "        if (cur_matrix==identity).all():\n",
    "            return i\n",
    "        outputs = [0] * 4\n",
    "        outputs[0] = Q_table[matrix_to_tuple(cur_matrix@ A)]\n",
    "        outputs[1] = Q_table[matrix_to_tuple(cur_matrix@ B)]\n",
    "        outputs[2] = Q_table[matrix_to_tuple(cur_matrix@ C)]\n",
    "        outputs[3] = Q_table[matrix_to_tuple(cur_matrix@ D)]\n",
    "        index = np.argmax(outputs)\n",
    "        if index==0:\n",
    "            cur_matrix = cur_matrix @ A\n",
    "        elif index==1:\n",
    "            cur_matrix = cur_matrix @ B\n",
    "        elif index==2:\n",
    "            cur_matrix = cur_matrix @ C\n",
    "        elif index==3:\n",
    "            cur_matrix = cur_matrix @ D\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q_learning(cur_row: np.array) -> int:\n",
    "    cur_matrix = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "    return matrix_to_num_steps(cur_matrix)\n",
    "\n",
    "test_df['num_moves_Q_learning_needs'] = test_df.apply(test_Q_learning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2827"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \")\n",
    "sum(test_df['num_moves_Q_learning_needs']!=100)/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of these, the proportion of times where we learned a path that was < 20 moves: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Of these, the proportion of times where we learned a path that was < 20 moves: \")\n",
    "# encouraging because all of these were generated as sequences of 30 moves\n",
    "# so we've found significantly faster paths back to the origin for almost all moves that we find a path to the origin \n",
    "sum(test_df['num_moves_Q_learning_needs']<20)/sum(test_df['num_moves_Q_learning_needs']!=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>num_moves_Q_learning_needs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1403.0</td>\n",
       "      <td>3382.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>-1051.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-935.0</td>\n",
       "      <td>-2012.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>4945.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1915.0</td>\n",
       "      <td>-3542.0</td>\n",
       "      <td>-512.0</td>\n",
       "      <td>-947.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69589.0</td>\n",
       "      <td>183160.0</td>\n",
       "      <td>-27010.0</td>\n",
       "      <td>-71091.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245.0</td>\n",
       "      <td>-508.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>-315.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-2947.0</td>\n",
       "      <td>-7592.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>4261.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>29.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>325.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-1116.0</td>\n",
       "      <td>-467.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-223.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>16829.0</td>\n",
       "      <td>9778.0</td>\n",
       "      <td>43532.0</td>\n",
       "      <td>25293.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         val1      val2     val3     val4  num_moves_Q_learning_needs\n",
       "0     -1403.0    3382.0    436.0  -1051.0                         100\n",
       "1      -935.0   -2012.0   2298.0   4945.0                         100\n",
       "2     -1915.0   -3542.0   -512.0   -947.0                         100\n",
       "3     69589.0  183160.0 -27010.0 -71091.0                         100\n",
       "4      1245.0    -508.0    772.0   -315.0                          10\n",
       "...       ...       ...      ...      ...                         ...\n",
       "9995  -2947.0   -7592.0   1654.0   4261.0                         100\n",
       "9996     29.0     -16.0    136.0    -75.0                           8\n",
       "9997    325.0     136.0  -1116.0   -467.0                          10\n",
       "9998   -223.0     -50.0    504.0    113.0                           9\n",
       "9999  16829.0    9778.0  43532.0  25293.0                         100\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test_df[test_df['num_moves_Q_learning_needs']!=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16089\\AppData\\Local\\Temp\\ipykernel_14152\\2721632581.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['first_move_by_Q_learning'] = filtered_df.apply(first_matrix_to_apply, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def first_matrix_to_apply(cur_row):\n",
    "    outputs = [0, 0, 0, 0]\n",
    "    cur_matrix = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "    outputs[0] = Q_table[matrix_to_tuple(cur_matrix@ A)]\n",
    "    outputs[1] = Q_table[matrix_to_tuple(cur_matrix@ B)]\n",
    "    outputs[2] = Q_table[matrix_to_tuple(cur_matrix@ C)]\n",
    "    outputs[3] = Q_table[matrix_to_tuple(cur_matrix@ D)]\n",
    "    return np.argmax(outputs)\n",
    "\n",
    "filtered_df['first_move_by_Q_learning'] = filtered_df.apply(first_matrix_to_apply, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>num_moves_Q_learning_needs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245.0</td>\n",
       "      <td>-508.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>-315.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-43.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-707.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-159.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>625.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>29.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>325.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-1116.0</td>\n",
       "      <td>-467.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-223.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2827 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        val1   val2    val3   val4  num_moves_Q_learning_needs\n",
       "4     1245.0 -508.0   772.0 -315.0                          10\n",
       "7      -43.0  200.0   152.0 -707.0                          10\n",
       "9        1.0    0.0     4.0    1.0                           2\n",
       "10    -159.0  574.0  -100.0  361.0                           9\n",
       "11      37.0  -20.0  -172.0   93.0                           8\n",
       "...      ...    ...     ...    ...                         ...\n",
       "9991    65.0 -142.0    38.0  -83.0                           8\n",
       "9992   625.0  146.0   244.0   57.0                           9\n",
       "9996    29.0  -16.0   136.0  -75.0                           8\n",
       "9997   325.0  136.0 -1116.0 -467.0                          10\n",
       "9998  -223.0  -50.0   504.0  113.0                           9\n",
       "\n",
       "[2827 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = int(filtered_df.shape[0] * 0.6)\n",
    "plus_one = bound+1\n",
    "train = filtered_df.iloc[1:bound]\n",
    "test = filtered_df.iloc[plus_one:filtered_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_value(row):\n",
    "    return Q_table[(int(row['val1']), \n",
    "    int(row['val2']), \n",
    "    int(row['val3']),\n",
    "    int(row['val4'])\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../Data_Generation/Data_files/subset_train_rows_SL2Z_Q_learn.csv\", index=False)\n",
    "test.to_csv(\"../Data_Generation/Data_files/subset_test_rows_SL2Z_Q_learn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_2_is_identity(test_tuple):\n",
    "    assert len(test_tuple)==4\n",
    "    return (test_tuple[0] % 2 == 1 and \n",
    "            test_tuple[1] % 2 == 0 and \n",
    "            test_tuple[2] % 2 == 0 and \n",
    "            test_tuple[3] % 2 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_2_is_identity([1, 2, 1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
