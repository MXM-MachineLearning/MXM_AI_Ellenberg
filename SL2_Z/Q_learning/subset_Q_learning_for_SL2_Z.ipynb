{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Definition:\n",
    "Let $A = \\begin{bmatrix}1 & 2 \\\\ 0 & 1\\end{bmatrix}$, $B = \\begin{bmatrix}1 & 0 \\\\ 2 & 1\\end{bmatrix}$.\n",
    "The group $\\Gamma \\coloneqq \\langle A,B\\rangle \\subseteq SL_2(\\mathbb{Z})$ is an index $12$ subgroup. The diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. \n",
    "\n",
    "We define $C = A^{-1}$ and $D = B^{-1}$.\n",
    "\n",
    "We can generate with any coset by starting at a representative from each coset and see if we get our way back to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_tuple(matrix: np.array) -> tuple:\n",
    "    return (matrix[0][0], matrix[0][1], \n",
    "            matrix[1][0], matrix[1][1]) \n",
    "\n",
    "def tuple_to_matrix(tuple: tuple) -> np.array:\n",
    "    return np.array([[tuple[0], tuple[1]], [tuple[2], tuple[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 12 according to alex's paper. Is it congruent to identity mod 2 or mod 4?\n",
    "# can generate with any coset I want by starting at a representative from each coset and see if we get our way back to it\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "B = np.array([[1, 0], [3, 1]])\n",
    "\n",
    "# elements on the diagonal are 1 mod 4. \n",
    "# elements not on the diagonal are 0 mod 2. \n",
    "\n",
    "# C is the inverse of A\n",
    "# D is the inverse of B\n",
    "C = np.linalg.inv(A)\n",
    "D = np.linalg.inv(B)\n",
    "\n",
    "identity = np.array([[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_search(Epsilon: float, qtable: dict, state: np.array) -> int:\n",
    "    '''\n",
    "    Makes a random step with probability Epsilon, and otherwise makes the best move from the Q_table.\n",
    "    (exploration vs exploitation)\n",
    "    '''\n",
    "    if (random.random() < Epsilon):\n",
    "        # 0 is 'apply matrix A', 1 is 'apply matrix B'\n",
    "        # 2 is 'apply matrix C', 3 is 'apply matrix D'\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    else:\n",
    "        # get the best move for the current state\n",
    "        return best_move_for_a_state(Q_table=qtable, state=state)\n",
    "    \n",
    "# I would like to return the best move for a given state\n",
    "def best_move_for_a_state(Q_table, state):\n",
    "    # vals = Q_table[(state[0][1], state[0][2], state[1][2])]\n",
    "\n",
    "    apply_A = state @ A\n",
    "    apply_B = state @ B\n",
    "    apply_C = state @ C\n",
    "    apply_D = state @ D\n",
    "\n",
    "    vals = [0, 0, 0, 0]\n",
    "    vals[0] = Q_table[matrix_to_tuple(apply_A)]\n",
    "    vals[1] = Q_table[matrix_to_tuple(apply_B)]\n",
    "    vals[2] = Q_table[matrix_to_tuple(apply_C)]\n",
    "    vals[3] = Q_table[matrix_to_tuple(apply_D)]\n",
    "\n",
    "    # if we haven't visited this state before, return a random choice of 0, 1, 2, or 3\n",
    "    if vals==[0, 0, 0, 0]:\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    \n",
    "    # if we have visited this state before, return the current best choice\n",
    "    return np.argmax(vals)\n",
    "\n",
    "# over a given state, return the maximum value of the table for that state\n",
    "def max_a_prime(Q_table, state):\n",
    "    apply_A = state @ A\n",
    "    apply_B = state @ B\n",
    "    apply_C = state @ C\n",
    "    apply_D = state @ D\n",
    "\n",
    "    vals = [0, 0, 0, 0]\n",
    "    vals[0] = Q_table[matrix_to_tuple(apply_A)]\n",
    "    vals[1] = Q_table[matrix_to_tuple(apply_B)]\n",
    "    vals[2] = Q_table[matrix_to_tuple(apply_C)]\n",
    "    vals[3] = Q_table[matrix_to_tuple(apply_D)]\n",
    "    \n",
    "    return max(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REWARD = 100\n",
    "STEP_PENALTY = -1\n",
    "\n",
    "def getReward(matrix: np.array) -> int:\n",
    "    if (matrix == identity).all():\n",
    "        return MAX_REWARD\n",
    "    else:\n",
    "        return STEP_PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Generation/Data_files/subset_sl2_Z_3s.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(oldObs: np.array, action: int) -> tuple[np.array, int, bool]:\n",
    "    '''\n",
    "    Apply matrix multiplication to take a step and get associated reward\n",
    "\n",
    "    returns: 3-tuple of the (step taken, associated reward of step, true if at identity)\n",
    "    '''\n",
    "\n",
    "    assert(action in [0, 1, 2, 3])\n",
    "\n",
    "    next_state = []\n",
    "    if action==0:\n",
    "        next_state = oldObs @ A\n",
    "    elif action==1:\n",
    "        next_state = oldObs @ B\n",
    "    elif action==2:\n",
    "        next_state = oldObs @ C\n",
    "    else:\n",
    "        next_state = oldObs @ D\n",
    "    curReward = getReward(next_state)\n",
    "    done = (curReward == MAX_REWARD)\n",
    "    return (next_state, curReward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mat(mat: np.array, index: int) -> np.array:\n",
    "    if index==0:\n",
    "        return mat @ A\n",
    "    elif index==1:\n",
    "        return mat @ B\n",
    "    elif index==2:\n",
    "        return mat @ C\n",
    "    elif index==3:\n",
    "        return mat @ D\n",
    "    raise ValueError(\"Index is not between 0 and 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_to_matrix(tuple):\n",
    "    return np.array([[tuple[0], tuple[1]], [tuple[2], tuple[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>271.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>213049.0</td>\n",
       "      <td>673746.0</td>\n",
       "      <td>601302.0</td>\n",
       "      <td>1901557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>93637.0</td>\n",
       "      <td>16578.0</td>\n",
       "      <td>16476.0</td>\n",
       "      <td>2917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>5221.0</td>\n",
       "      <td>-31926.0</td>\n",
       "      <td>14088.0</td>\n",
       "      <td>-86147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>1095211.0</td>\n",
       "      <td>-117576.0</td>\n",
       "      <td>3106386.0</td>\n",
       "      <td>-333485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>1763227.0</td>\n",
       "      <td>4690950.0</td>\n",
       "      <td>-285456.0</td>\n",
       "      <td>-759437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>-647.0</td>\n",
       "      <td>-246.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>42379021.0</td>\n",
       "      <td>-7530684.0</td>\n",
       "      <td>111421710.0</td>\n",
       "      <td>-19799459.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1661 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            val1       val2         val3        val4\n",
       "9            1.0        0.0          6.0         1.0\n",
       "19         271.0      -96.0         48.0       -17.0\n",
       "21      213049.0   673746.0     601302.0   1901557.0\n",
       "22       93637.0    16578.0      16476.0      2917.0\n",
       "24          37.0       -6.0         -6.0         1.0\n",
       "...          ...        ...          ...         ...\n",
       "9942      5221.0   -31926.0      14088.0    -86147.0\n",
       "9944   1095211.0  -117576.0    3106386.0   -333485.0\n",
       "9961   1763227.0  4690950.0    -285456.0   -759437.0\n",
       "9962      -647.0     -246.0        192.0        73.0\n",
       "9988  42379021.0 -7530684.0  111421710.0 -19799459.0\n",
       "\n",
       "[1661 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['val1'] % 2 == 1) & (df['val2'] % 2 == 0) & (df['val3'] % 2 == 0) & (df['val4'] % 2 == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>271.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>213049.0</td>\n",
       "      <td>673746.0</td>\n",
       "      <td>601302.0</td>\n",
       "      <td>1901557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>93637.0</td>\n",
       "      <td>16578.0</td>\n",
       "      <td>16476.0</td>\n",
       "      <td>2917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>5221.0</td>\n",
       "      <td>-31926.0</td>\n",
       "      <td>14088.0</td>\n",
       "      <td>-86147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>1095211.0</td>\n",
       "      <td>-117576.0</td>\n",
       "      <td>3106386.0</td>\n",
       "      <td>-333485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>1763227.0</td>\n",
       "      <td>4690950.0</td>\n",
       "      <td>-285456.0</td>\n",
       "      <td>-759437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>-647.0</td>\n",
       "      <td>-246.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>42379021.0</td>\n",
       "      <td>-7530684.0</td>\n",
       "      <td>111421710.0</td>\n",
       "      <td>-19799459.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1661 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            val1       val2         val3        val4\n",
       "9            1.0        0.0          6.0         1.0\n",
       "19         271.0      -96.0         48.0       -17.0\n",
       "21      213049.0   673746.0     601302.0   1901557.0\n",
       "22       93637.0    16578.0      16476.0      2917.0\n",
       "24          37.0       -6.0         -6.0         1.0\n",
       "...          ...        ...          ...         ...\n",
       "9942      5221.0   -31926.0      14088.0    -86147.0\n",
       "9944   1095211.0  -117576.0    3106386.0   -333485.0\n",
       "9961   1763227.0  4690950.0    -285456.0   -759437.0\n",
       "9962      -647.0     -246.0        192.0        73.0\n",
       "9988  42379021.0 -7530684.0  111421710.0 -19799459.0\n",
       "\n",
       "[1661 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Verify that the diagonal entries are congruent to $1\\pmod{4}$ and the non-diagonal entries and divisible by $2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = df[df['val1'] % 4 == 1]\n",
    "filter_df = filter_df[filter_df['val2'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val3'] % 2 == 0]\n",
    "filter_df = filter_df[filter_df['val4'] % 4 == 1]\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_5789/1460151504.py:22: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  [int(cur_row['val1']), int(cur_row['val2'])],\n",
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_5789/1460151504.py:23: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  [int(cur_row['val3']), int(cur_row['val4'])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for the last 100 iterations: -96.02\n",
      "epsilon: 0.989950333757503\n",
      "Average reward for the last 100 iterations: -98.01\n",
      "epsilon: 0.9800996732739187\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9703470333764725\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9606914386955115\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9511319235669539\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9416675319357145\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.9322973172600907\n",
      "Average reward for the last 100 iterations: -98.01\n",
      "epsilon: 0.9230203424170932\n",
      "Average reward for the last 100 iterations: -96.03\n",
      "epsilon: 0.9138356796087268\n",
      "Average reward for the last 100 iterations: -98.01\n",
      "epsilon: 0.9047424102692004\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.89573962497306\n",
      "Average reward for the last 100 iterations: -96.04\n",
      "epsilon: 0.8868264233442354\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.8780019139659949\n",
      "Average reward for the last 100 iterations: -98.0\n",
      "epsilon: 0.8692652142917918\n",
      "Average reward for the last 100 iterations: -98.04\n",
      "epsilon: 0.8606154505570021\n",
      "Average reward for the last 100 iterations: -98.28\n",
      "epsilon: 0.8520517576915366\n",
      "Average reward for the last 100 iterations: -98.01\n",
      "epsilon: 0.8435732792333273\n",
      "Average reward for the last 100 iterations: -100.0\n",
      "epsilon: 0.8351791672426676\n",
      "Average reward for the last 100 iterations: -88.63\n",
      "epsilon: 0.8268685822174137\n",
      "Average reward for the last 100 iterations: -96.24\n",
      "epsilon: 0.8186406930090225\n",
      "Average reward for the last 100 iterations: -98.0\n",
      "epsilon: 0.8104946767394292\n",
      "Average reward for the last 100 iterations: -98.13\n",
      "epsilon: 0.802429718718749\n",
      "Average reward for the last 100 iterations: -94.62\n",
      "epsilon: 0.7944450123638009\n",
      "Average reward for the last 100 iterations: -94.15\n",
      "epsilon: 0.78653975911744\n",
      "Average reward for the last 100 iterations: -96.11\n",
      "epsilon: 0.7787131683686925\n",
      "Average reward for the last 100 iterations: -94.2\n",
      "epsilon: 0.7709644573736867\n",
      "Average reward for the last 100 iterations: -91.53\n",
      "epsilon: 0.763292851177371\n",
      "Average reward for the last 100 iterations: -87.06\n",
      "epsilon: 0.7556975825360077\n",
      "Average reward for the last 100 iterations: -90.48\n",
      "epsilon: 0.7481778918404428\n",
      "Average reward for the last 100 iterations: -90.86\n",
      "epsilon: 0.7407330270401349\n",
      "Average reward for the last 100 iterations: -88.65\n",
      "epsilon: 0.7333622435679438\n",
      "Average reward for the last 100 iterations: -83.83\n",
      "epsilon: 0.7260648042656639\n",
      "Average reward for the last 100 iterations: -96.49\n",
      "epsilon: 0.7188399793103014\n",
      "Average reward for the last 100 iterations: -92.1\n",
      "epsilon: 0.7116870461410829\n",
      "Average reward for the last 100 iterations: -98.13\n",
      "epsilon: 0.7046052893871948\n",
      "Average reward for the last 100 iterations: -82.26\n",
      "epsilon: 0.6975940007962347\n",
      "Average reward for the last 100 iterations: -84.71\n",
      "epsilon: 0.690652479163381\n",
      "Average reward for the last 100 iterations: -87.88\n",
      "epsilon: 0.6837800302612622\n",
      "Average reward for the last 100 iterations: -92.12\n",
      "epsilon: 0.6769759667705286\n",
      "Average reward for the last 100 iterations: -80.91\n",
      "epsilon: 0.6702396082111141\n",
      "Average reward for the last 100 iterations: -78.58\n",
      "epsilon: 0.6635702808741777\n",
      "Average reward for the last 100 iterations: -71.25\n",
      "epsilon: 0.6569673177547274\n",
      "Average reward for the last 100 iterations: -79.75\n",
      "epsilon: 0.6504300584849119\n",
      "Average reward for the last 100 iterations: -73.98\n",
      "epsilon: 0.6439578492679773\n",
      "Average reward for the last 100 iterations: -76.09\n",
      "epsilon: 0.6375500428128791\n",
      "Average reward for the last 100 iterations: -86.44\n",
      "epsilon: 0.6312059982695464\n",
      "Average reward for the last 100 iterations: -77.68\n",
      "epsilon: 0.6249250811647913\n",
      "Average reward for the last 100 iterations: -77.78\n",
      "epsilon: 0.6187066633388536\n",
      "Average reward for the last 100 iterations: -72.92\n",
      "epsilon: 0.6125501228825772\n",
      "Average reward for the last 100 iterations: -71.9\n",
      "epsilon: 0.6064548440752141\n",
      "Average reward for the last 100 iterations: -74.67\n",
      "epsilon: 0.6004202173228442\n",
      "Average reward for the last 100 iterations: -70.38\n",
      "epsilon: 0.5944456390974114\n",
      "Average reward for the last 100 iterations: -81.12\n",
      "epsilon: 0.5885305118763617\n",
      "Average reward for the last 100 iterations: -71.87\n",
      "epsilon: 0.5826742440828869\n",
      "Average reward for the last 100 iterations: -71.53\n",
      "epsilon: 0.576876250026757\n",
      "Average reward for the last 100 iterations: -71.95\n",
      "epsilon: 0.5711359498457492\n",
      "Average reward for the last 100 iterations: -63.65\n",
      "epsilon: 0.5654527694476531\n",
      "Average reward for the last 100 iterations: -66.88\n",
      "epsilon: 0.559826140452854\n",
      "Average reward for the last 100 iterations: -69.96\n",
      "epsilon: 0.5542555001374916\n",
      "Average reward for the last 100 iterations: -79.65\n",
      "epsilon: 0.548740291377179\n",
      "Average reward for the last 100 iterations: -68.85\n",
      "epsilon: 0.5432799625912865\n",
      "Average reward for the last 100 iterations: -69.99\n",
      "epsilon: 0.5378739676877772\n",
      "Average reward for the last 100 iterations: -61.83\n",
      "epsilon: 0.532521766008588\n",
      "Average reward for the last 100 iterations: -76.07\n",
      "epsilon: 0.5272228222755642\n",
      "Average reward for the last 100 iterations: -71.32\n",
      "epsilon: 0.5219766065369207\n",
      "Average reward for the last 100 iterations: -61.98\n",
      "epsilon: 0.5167825941142447\n",
      "Average reward for the last 100 iterations: -82.54\n",
      "epsilon: 0.5116402655500194\n",
      "Average reward for the last 100 iterations: -74.76\n",
      "epsilon: 0.5065491065556748\n",
      "Average reward for the last 100 iterations: -61.06\n",
      "epsilon: 0.5015086079601511\n",
      "Average reward for the last 100 iterations: -73.32\n",
      "epsilon: 0.4965182656589779\n",
      "Average reward for the last 100 iterations: -75.43\n",
      "epsilon: 0.491577580563858\n",
      "Average reward for the last 100 iterations: -72.46\n",
      "epsilon: 0.4866860585527523\n",
      "Average reward for the last 100 iterations: -50.99\n",
      "epsilon: 0.4818432104204629\n",
      "Average reward for the last 100 iterations: -61.97\n",
      "epsilon: 0.4770485518297069\n",
      "Average reward for the last 100 iterations: -62.71\n",
      "epsilon: 0.47230160326267795\n",
      "Average reward for the last 100 iterations: -69.61\n",
      "epsilon: 0.46760188997308916\n",
      "Average reward for the last 100 iterations: -56.48\n",
      "epsilon: 0.4629489419386927\n",
      "Average reward for the last 100 iterations: -67.55\n",
      "epsilon: 0.45834229381427294\n",
      "Average reward for the last 100 iterations: -63.6\n",
      "epsilon: 0.4537814848851073\n",
      "Average reward for the last 100 iterations: -58.5\n",
      "epsilon: 0.4492660590208893\n",
      "Average reward for the last 100 iterations: -72.45\n",
      "epsilon: 0.44479556463011005\n",
      "Average reward for the last 100 iterations: -61.7\n",
      "epsilon: 0.44036955461489585\n",
      "Average reward for the last 100 iterations: -68.01\n",
      "epsilon: 0.4359875863262917\n",
      "Average reward for the last 100 iterations: -46.83\n",
      "epsilon: 0.4316492215199928\n",
      "Average reward for the last 100 iterations: -52.37\n",
      "epsilon: 0.42735402631251446\n",
      "Average reward for the last 100 iterations: -59.0\n",
      "epsilon: 0.4231015711378002\n",
      "Average reward for the last 100 iterations: -67.94\n",
      "epsilon: 0.4188914307042601\n",
      "Average reward for the last 100 iterations: -63.64\n",
      "epsilon: 0.41472318395223523\n",
      "Average reward for the last 100 iterations: -55.3\n",
      "epsilon: 0.4105964140118904\n",
      "Average reward for the last 100 iterations: -60.93\n",
      "epsilon: 0.406510708161521\n",
      "Average reward for the last 100 iterations: -49.7\n",
      "epsilon: 0.4024656577862749\n",
      "Average reward for the last 100 iterations: -37.62\n",
      "epsilon: 0.39846085833728956\n",
      "Average reward for the last 100 iterations: -47.45\n",
      "epsilon: 0.3944959092912299\n",
      "Average reward for the last 100 iterations: -65.02\n",
      "epsilon: 0.39057041411023374\n",
      "Average reward for the last 100 iterations: -57.33\n",
      "epsilon: 0.3866839802022521\n",
      "Average reward for the last 100 iterations: -42.22\n",
      "epsilon: 0.3828362188817869\n",
      "Average reward for the last 100 iterations: -66.32\n",
      "epsilon: 0.3790267453310186\n",
      "Average reward for the last 100 iterations: -53.03\n",
      "epsilon: 0.3752551785613178\n",
      "Average reward for the last 100 iterations: -50.95\n",
      "epsilon: 0.3715211413751451\n",
      "Average reward for the last 100 iterations: -59.51\n",
      "epsilon: 0.3678242603283259\n",
      "Average reward for the last 100 iterations: -54.78\n",
      "epsilon: 0.3641641656927023\n",
      "Average reward for the last 100 iterations: -68.13\n",
      "epsilon: 0.36054049141915495\n",
      "Average reward for the last 100 iterations: -59.94\n",
      "epsilon: 0.3569528751009966\n",
      "Average reward for the last 100 iterations: -67.83\n",
      "epsilon: 0.3534009579377257\n",
      "Average reward for the last 100 iterations: -66.12\n",
      "epsilon: 0.3498843846991425\n",
      "Average reward for the last 100 iterations: -60.46\n",
      "epsilon: 0.34640280368982374\n",
      "Average reward for the last 100 iterations: -58.97\n",
      "epsilon: 0.34295586671394696\n",
      "Average reward for the last 100 iterations: -47.33\n",
      "epsilon: 0.33954322904046974\n",
      "Average reward for the last 100 iterations: -58.43\n",
      "epsilon: 0.33616454936865003\n",
      "Average reward for the last 100 iterations: -52.61\n",
      "epsilon: 0.332819489793915\n",
      "Average reward for the last 100 iterations: -50.61\n",
      "epsilon: 0.32950771577406535\n",
      "Average reward for the last 100 iterations: -50.96\n",
      "epsilon: 0.326228896095818\n",
      "Average reward for the last 100 iterations: -40.98\n",
      "epsilon: 0.32298270284168096\n",
      "Average reward for the last 100 iterations: -60.95\n",
      "epsilon: 0.3197688113571579\n",
      "Average reward for the last 100 iterations: -52.59\n",
      "epsilon: 0.3165869002182801\n",
      "Average reward for the last 100 iterations: -55.04\n",
      "epsilon: 0.3134366511994595\n",
      "Average reward for the last 100 iterations: -58.12\n",
      "epsilon: 0.31031774924166283\n",
      "Average reward for the last 100 iterations: -44.74\n",
      "epsilon: 0.30722988242090343\n",
      "Average reward for the last 100 iterations: -50.89\n",
      "epsilon: 0.3041727419170432\n",
      "Average reward for the last 100 iterations: -42.5\n",
      "epsilon: 0.3011460219829101\n",
      "Average reward for the last 100 iterations: -58.35\n",
      "epsilon: 0.2981494199137175\n",
      "Average reward for the last 100 iterations: -64.41\n",
      "epsilon: 0.29518263601679207\n",
      "Average reward for the last 100 iterations: -53.65\n",
      "epsilon: 0.2922453735816008\n",
      "Average reward for the last 100 iterations: -53.85\n",
      "epsilon: 0.2893373388500768\n",
      "Average reward for the last 100 iterations: -54.83\n",
      "epsilon: 0.28645824098724004\n",
      "Average reward for the last 100 iterations: -60.16\n",
      "epsilon: 0.2836077920521105\n",
      "Average reward for the last 100 iterations: -46.63\n",
      "epsilon: 0.28078570696891186\n",
      "Average reward for the last 100 iterations: -60.02\n",
      "epsilon: 0.27799170349856034\n",
      "Average reward for the last 100 iterations: -47.15\n",
      "epsilon: 0.2752255022104372\n",
      "Average reward for the last 100 iterations: -61.93\n",
      "epsilon: 0.27248682645444433\n",
      "Average reward for the last 100 iterations: -65.13\n",
      "epsilon: 0.2697754023333332\n",
      "Average reward for the last 100 iterations: -65.66\n",
      "epsilon: 0.2670909586753151\n",
      "Average reward for the last 100 iterations: -58.69\n",
      "epsilon: 0.2644332270069402\n",
      "Average reward for the last 100 iterations: -54.19\n",
      "epsilon: 0.26180194152624664\n",
      "Average reward for the last 100 iterations: -56.2\n",
      "epsilon: 0.2591968390761776\n",
      "Average reward for the last 100 iterations: -46.56\n",
      "epsilon: 0.2566176591182636\n",
      "Average reward for the last 100 iterations: -54.35\n",
      "epsilon: 0.2540641437065648\n",
      "Average reward for the last 100 iterations: -73.56\n",
      "epsilon: 0.2515360374618739\n",
      "Average reward for the last 100 iterations: -61.4\n",
      "epsilon: 0.24903308754617642\n",
      "Average reward for the last 100 iterations: -42.53\n",
      "epsilon: 0.24655504363736244\n",
      "Average reward for the last 100 iterations: -55.95\n",
      "epsilon: 0.24410165790419308\n",
      "Average reward for the last 100 iterations: -55.75\n",
      "epsilon: 0.24167268498151395\n",
      "Average reward for the last 100 iterations: -63.96\n",
      "epsilon: 0.2392678819457161\n",
      "Average reward for the last 100 iterations: -56.12\n",
      "epsilon: 0.2368870082904414\n",
      "Average reward for the last 100 iterations: -61.36\n",
      "epsilon: 0.23452982590252897\n",
      "Average reward for the last 100 iterations: -51.73\n",
      "epsilon: 0.2321960990382015\n",
      "Average reward for the last 100 iterations: -69.44\n",
      "epsilon: 0.22988559429948774\n",
      "Average reward for the last 100 iterations: -53.89\n",
      "epsilon: 0.2275980806108809\n",
      "Average reward for the last 100 iterations: -56.11\n",
      "epsilon: 0.2253333291962282\n",
      "Average reward for the last 100 iterations: -41.16\n",
      "epsilon: 0.22309111355585096\n",
      "Average reward for the last 100 iterations: -60.0\n",
      "epsilon: 0.2208712094438921\n",
      "Average reward for the last 100 iterations: -46.18\n",
      "epsilon: 0.2186733948458889\n",
      "Average reward for the last 100 iterations: -44.17\n",
      "epsilon: 0.2164974499565696\n",
      "Average reward for the last 100 iterations: -46.21\n",
      "epsilon: 0.2143431571578701\n",
      "Average reward for the last 100 iterations: -43.95\n",
      "epsilon: 0.21221030099717023\n",
      "Average reward for the last 100 iterations: -67.38\n",
      "epsilon: 0.2100986681657454\n",
      "Average reward for the last 100 iterations: -57.48\n",
      "epsilon: 0.2080080474774341\n",
      "Average reward for the last 100 iterations: -61.78\n",
      "epsilon: 0.20593822984751717\n",
      "Average reward for the last 100 iterations: -74.91\n",
      "epsilon: 0.20388900827180606\n",
      "Average reward for the last 100 iterations: -63.9\n",
      "epsilon: 0.20186017780594118\n",
      "Average reward for the last 100 iterations: -42.56\n",
      "epsilon: 0.19985153554489493\n",
      "Average reward for the last 100 iterations: -69.15\n",
      "epsilon: 0.19786288060267845\n",
      "Average reward for the last 100 iterations: -35.02\n",
      "epsilon: 0.19589401409225174\n",
      "Average reward for the last 100 iterations: -46.59\n",
      "epsilon: 0.19394473910563204\n",
      "Average reward for the last 100 iterations: -63.9\n",
      "epsilon: 0.19201486069420162\n",
      "Average reward for the last 100 iterations: -52.08\n",
      "epsilon: 0.1901041858492102\n",
      "Average reward for the last 100 iterations: -65.3\n",
      "epsilon: 0.1882125234824722\n",
      "Average reward for the last 100 iterations: -32.66\n",
      "epsilon: 0.18633968440725585\n",
      "Average reward for the last 100 iterations: -50.06\n",
      "epsilon: 0.18448548131936265\n",
      "Average reward for the last 100 iterations: -55.61\n",
      "epsilon: 0.1826497287783945\n",
      "Average reward for the last 100 iterations: -49.84\n",
      "epsilon: 0.1808322431892079\n",
      "Average reward for the last 100 iterations: -36.2\n",
      "epsilon: 0.17903284278355266\n",
      "Average reward for the last 100 iterations: -51.93\n",
      "epsilon: 0.17725134760189254\n",
      "Average reward for the last 100 iterations: -42.2\n",
      "epsilon: 0.1754875794754081\n",
      "Average reward for the last 100 iterations: -46.37\n",
      "epsilon: 0.17374136200817725\n",
      "Average reward for the last 100 iterations: -53.92\n",
      "epsilon: 0.17201252055953417\n",
      "Average reward for the last 100 iterations: -51.87\n",
      "epsilon: 0.17030088222660275\n",
      "Average reward for the last 100 iterations: -48.19\n",
      "epsilon: 0.16860627582700524\n",
      "Average reward for the last 100 iterations: -40.69\n",
      "epsilon: 0.16692853188174173\n",
      "Average reward for the last 100 iterations: -53.47\n",
      "epsilon: 0.16526748259824006\n",
      "Average reward for the last 100 iterations: -45.81\n",
      "epsilon: 0.1636229618535754\n",
      "Average reward for the last 100 iterations: -63.44\n",
      "epsilon: 0.16199480517785583\n",
      "Average reward for the last 100 iterations: -53.4\n",
      "epsilon: 0.16038284973777372\n",
      "Average reward for the last 100 iterations: -55.49\n",
      "epsilon: 0.15878693432032062\n",
      "Average reward for the last 100 iterations: -55.57\n",
      "epsilon: 0.1572068993166638\n",
      "Average reward for the last 100 iterations: -53.77\n",
      "epsilon: 0.15564258670618408\n",
      "Average reward for the last 100 iterations: -73.15\n",
      "epsilon: 0.15409384004067206\n",
      "Average reward for the last 100 iterations: -54.02\n",
      "epsilon: 0.15256050442868138\n",
      "Average reward for the last 100 iterations: -58.02\n",
      "epsilon: 0.1510424265200381\n",
      "Average reward for the last 100 iterations: -46.19\n",
      "epsilon: 0.14953945449050376\n",
      "Average reward for the last 100 iterations: -48.01\n",
      "epsilon: 0.1480514380265917\n",
      "Average reward for the last 100 iterations: -42.16\n",
      "epsilon: 0.14657822831053363\n",
      "Average reward for the last 100 iterations: -57.79\n",
      "epsilon: 0.14511967800539669\n",
      "Average reward for the last 100 iterations: -59.68\n",
      "epsilon: 0.14367564124034787\n",
      "Average reward for the last 100 iterations: -57.34\n",
      "epsilon: 0.14224597359606533\n",
      "Average reward for the last 100 iterations: -44.16\n",
      "epsilon: 0.1408305320902949\n",
      "Average reward for the last 100 iterations: -55.6\n",
      "epsilon: 0.13942917516355058\n",
      "Average reward for the last 100 iterations: -57.26\n",
      "epsilon: 0.1380417626649567\n",
      "Average reward for the last 100 iterations: -65.09\n",
      "epsilon: 0.13666815583823175\n",
      "Average reward for the last 100 iterations: -46.05\n",
      "epsilon: 0.13530821730781062\n",
      "Average reward for the last 100 iterations: -51.91\n",
      "epsilon: 0.1339618110651063\n",
      "Average reward for the last 100 iterations: -59.64\n",
      "epsilon: 0.13262880245490677\n",
      "Average reward for the last 100 iterations: -49.87\n",
      "epsilon: 0.13130905816190905\n",
      "Average reward for the last 100 iterations: -70.71\n",
      "epsilon: 0.1300024461973849\n",
      "Average reward for the last 100 iterations: -45.92\n",
      "epsilon: 0.1287088358859816\n",
      "Average reward for the last 100 iterations: -40.28\n",
      "epsilon: 0.12742809785265258\n",
      "Average reward for the last 100 iterations: -43.85\n",
      "epsilon: 0.12616010400971825\n",
      "Average reward for the last 100 iterations: -45.85\n",
      "epsilon: 0.1249047275440563\n",
      "Average reward for the last 100 iterations: -44.3\n",
      "epsilon: 0.12366184290441894\n",
      "Average reward for the last 100 iterations: -51.88\n",
      "epsilon: 0.12243132578887629\n",
      "Average reward for the last 100 iterations: -50.08\n",
      "epsilon: 0.12121305313238478\n",
      "Average reward for the last 100 iterations: -65.16\n",
      "epsilon: 0.1200069030944797\n",
      "Average reward for the last 100 iterations: -70.91\n",
      "epsilon: 0.11881275504708917\n",
      "Average reward for the last 100 iterations: -47.89\n",
      "epsilon: 0.11763048956247056\n",
      "Average reward for the last 100 iterations: -53.94\n",
      "epsilon: 0.11645998840126634\n",
      "Average reward for the last 100 iterations: -51.88\n",
      "epsilon: 0.11530113450067855\n",
      "Average reward for the last 100 iterations: -46.2\n",
      "epsilon: 0.11415381196276177\n",
      "Average reward for the last 100 iterations: -40.15\n",
      "epsilon: 0.11301790604283157\n",
      "Average reward for the last 100 iterations: -47.81\n",
      "epsilon: 0.11189330313798898\n",
      "Average reward for the last 100 iterations: -43.87\n",
      "epsilon: 0.11077989077575923\n",
      "Average reward for the last 100 iterations: -42.06\n",
      "epsilon: 0.10967755760284283\n",
      "Average reward for the last 100 iterations: -59.48\n",
      "epsilon: 0.10858619337397935\n",
      "Average reward for the last 100 iterations: -38.21\n",
      "epsilon: 0.10750568894092176\n",
      "Average reward for the last 100 iterations: -45.82\n",
      "epsilon: 0.10643593624151992\n",
      "Average reward for the last 100 iterations: -44.07\n",
      "epsilon: 0.1053768282889138\n",
      "Average reward for the last 100 iterations: -47.74\n",
      "epsilon: 0.1043282591608334\n",
      "Average reward for the last 100 iterations: -39.91\n",
      "epsilon: 0.10329012398900515\n",
      "Average reward for the last 100 iterations: -32.29\n",
      "epsilon: 0.10226231894866437\n",
      "Average reward for the last 100 iterations: -40.43\n",
      "epsilon: 0.10124474124817139\n",
      "Average reward for the last 100 iterations: -49.83\n",
      "epsilon: 0.10023728911873117\n",
      "Average reward for the last 100 iterations: -49.89\n",
      "epsilon: 0.09923986180421565\n",
      "Average reward for the last 100 iterations: -59.26\n",
      "epsilon: 0.0982523595510868\n",
      "Average reward for the last 100 iterations: -40.33\n",
      "epsilon: 0.09727468359842038\n",
      "Average reward for the last 100 iterations: -51.66\n",
      "epsilon: 0.09630673616802857\n",
      "Average reward for the last 100 iterations: -55.73\n",
      "epsilon: 0.09534842045468113\n",
      "Average reward for the last 100 iterations: -49.84\n",
      "epsilon: 0.09439964061642395\n",
      "Average reward for the last 100 iterations: -53.54\n",
      "epsilon: 0.09346030176499369\n",
      "Average reward for the last 100 iterations: -53.53\n",
      "epsilon: 0.09253030995632805\n",
      "Average reward for the last 100 iterations: -49.64\n",
      "epsilon: 0.09160957218117023\n",
      "Average reward for the last 100 iterations: -49.78\n",
      "epsilon: 0.09069799635576713\n",
      "Average reward for the last 100 iterations: -59.27\n",
      "epsilon: 0.08979549131265965\n",
      "Average reward for the last 100 iterations: -45.88\n",
      "epsilon: 0.08890196679156555\n",
      "Average reward for the last 100 iterations: -45.94\n",
      "epsilon: 0.08801733343035181\n",
      "Average reward for the last 100 iterations: -37.95\n",
      "epsilon: 0.0871415027560978\n",
      "Average reward for the last 100 iterations: -49.5\n",
      "epsilon: 0.0862743871762469\n",
      "Average reward for the last 100 iterations: -42.06\n",
      "epsilon: 0.08541589996984655\n",
      "Average reward for the last 100 iterations: -53.63\n",
      "epsilon: 0.08456595527887494\n",
      "Average reward for the last 100 iterations: -36.21\n",
      "epsilon: 0.08372446809965417\n",
      "Average reward for the last 100 iterations: -59.25\n",
      "epsilon: 0.08289135427434946\n",
      "Average reward for the last 100 iterations: -34.19\n",
      "epsilon: 0.08206653048255198\n",
      "Average reward for the last 100 iterations: -53.68\n",
      "epsilon: 0.08124991423294586\n",
      "Average reward for the last 100 iterations: -47.52\n",
      "epsilon: 0.08044142385505873\n",
      "Average reward for the last 100 iterations: -55.49\n",
      "epsilon: 0.07964097849109329\n",
      "Average reward for the last 100 iterations: -47.74\n",
      "epsilon: 0.07884849808784071\n",
      "Average reward for the last 100 iterations: -42.02\n",
      "epsilon: 0.07806390338867449\n",
      "Average reward for the last 100 iterations: -51.33\n",
      "epsilon: 0.0772871159256243\n",
      "Average reward for the last 100 iterations: -47.44\n",
      "epsilon: 0.07651805801152776\n",
      "Average reward for the last 100 iterations: -65.1\n",
      "epsilon: 0.07575665273226108\n",
      "Average reward for the last 100 iterations: -51.72\n",
      "epsilon: 0.07500282393904703\n",
      "Average reward for the last 100 iterations: -36.59\n",
      "epsilon: 0.0742564962408389\n",
      "Average reward for the last 100 iterations: -67.14\n",
      "epsilon: 0.07351759499678091\n",
      "Average reward for the last 100 iterations: -59.14\n",
      "epsilon: 0.07278604630874305\n",
      "Average reward for the last 100 iterations: -33.88\n",
      "epsilon: 0.07206177701393056\n",
      "Average reward for the last 100 iterations: -47.35\n",
      "epsilon: 0.07134471467756703\n",
      "Average reward for the last 100 iterations: -57.29\n",
      "epsilon: 0.07063478758564987\n",
      "Average reward for the last 100 iterations: -61.31\n",
      "epsilon: 0.06993192473777823\n",
      "Average reward for the last 100 iterations: -53.52\n",
      "epsilon: 0.06923605584005207\n",
      "Average reward for the last 100 iterations: -61.17\n",
      "epsilon: 0.06854711129804245\n",
      "Average reward for the last 100 iterations: -59.33\n",
      "epsilon: 0.0678650222098307\n",
      "Average reward for the last 100 iterations: -38.18\n",
      "epsilon: 0.0671897203591181\n",
      "Average reward for the last 100 iterations: -55.53\n",
      "epsilon: 0.0665211382084031\n",
      "Average reward for the last 100 iterations: -61.24\n",
      "epsilon: 0.06585920889222686\n",
      "Average reward for the last 100 iterations: -49.81\n",
      "epsilon: 0.06520386621048607\n",
      "Average reward for the last 100 iterations: -53.59\n",
      "epsilon: 0.06455504462181237\n",
      "Average reward for the last 100 iterations: -59.16\n",
      "epsilon: 0.06391267923701738\n",
      "Average reward for the last 100 iterations: -47.72\n",
      "epsilon: 0.0632767058126029\n",
      "Average reward for the last 100 iterations: -34.13\n",
      "epsilon: 0.06264706074433596\n",
      "Average reward for the last 100 iterations: -67.07\n",
      "epsilon: 0.06202368106088804\n",
      "Average reward for the last 100 iterations: -53.54\n",
      "epsilon: 0.061406504417536784\n",
      "Average reward for the last 100 iterations: -65.16\n",
      "epsilon: 0.06079546908993113\n",
      "Average reward for the last 100 iterations: -28.19\n",
      "epsilon: 0.060190513967918045\n",
      "Average reward for the last 100 iterations: -51.4\n",
      "epsilon: 0.059591578549431055\n",
      "Average reward for the last 100 iterations: -49.48\n",
      "epsilon: 0.05899860293443916\n",
      "Average reward for the last 100 iterations: -53.3\n",
      "epsilon: 0.05841152781895632\n",
      "Average reward for the last 100 iterations: -45.85\n",
      "epsilon: 0.05783029448911036\n",
      "Average reward for the last 100 iterations: -43.87\n",
      "epsilon: 0.057254844815271044\n",
      "Average reward for the last 100 iterations: -38.26\n",
      "epsilon: 0.056685121246236224\n",
      "Average reward for the last 100 iterations: -45.61\n",
      "epsilon: 0.05612106680347639\n",
      "Average reward for the last 100 iterations: -45.57\n",
      "epsilon: 0.055562625075436065\n",
      "Average reward for the last 100 iterations: -43.89\n",
      "epsilon: 0.0550097402118921\n",
      "Average reward for the last 100 iterations: -41.95\n",
      "epsilon: 0.05446235691836792\n",
      "Average reward for the last 100 iterations: -43.94\n",
      "epsilon: 0.05392042045060362\n",
      "Average reward for the last 100 iterations: -43.83\n",
      "epsilon: 0.053383876609080824\n",
      "Average reward for the last 100 iterations: -55.41\n",
      "epsilon: 0.052852671733602266\n",
      "Average reward for the last 100 iterations: -45.71\n",
      "epsilon: 0.052326752697925104\n",
      "Average reward for the last 100 iterations: -53.54\n",
      "epsilon: 0.051806066904447695\n",
      "Average reward for the last 100 iterations: -34.23\n",
      "epsilon: 0.051290562278949396\n",
      "Average reward for the last 100 iterations: -43.83\n",
      "epsilon: 0.05078018726538244\n",
      "Average reward for the last 100 iterations: -30.24\n",
      "epsilon: 0.050274890820715915\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 30000\n",
    "LEARNING_RATE = .9\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .9999\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# starts with an estimate of zero reward for each state.\n",
    "# adapted from ChatGPT\n",
    "Q_table = defaultdict(lambda: 0)\n",
    "\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        action = epsilon_greedy_search(Epsilon=EPSILON, qtable=Q_table, state=obs)\n",
    "\n",
    "        oldObs = obs\n",
    "        obs,reward,done = get_next_step(oldObs, action)\n",
    "\n",
    "        # if done:\n",
    "        #     assert(1==2)\n",
    "        \n",
    "        Q_table[matrix_to_tuple(obs)] = (1-LEARNING_RATE) * Q_table[matrix_to_tuple(obs)] + (LEARNING_RATE) * (reward + DISCOUNT_FACTOR * (max_a_prime(Q_table, obs)))\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if i%100 ==0 and i>0:\n",
    "        print(\"Average reward for the last 100 iterations: \" + str(sum(list(episode_reward_record))/100))\n",
    "        print(\"epsilon: \" + str(EPSILON) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_Q_table(mat):\n",
    "    return Q_table[matrix_to_tuple(mat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924.623115577806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_Q_table(np.array([[1, 3], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924.623115577806"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_Q_table(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(\"../Data_Generation/Data_files/subset_sl2_Z_3s_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_num_steps(cur_matrix):\n",
    "    index = 1\n",
    "    for i in range(50):\n",
    "        if (cur_matrix==identity).all():\n",
    "            return i\n",
    "        outputs = [0] * 4\n",
    "        outputs[0] = Q_table[matrix_to_tuple(cur_matrix@ A)]\n",
    "        outputs[1] = Q_table[matrix_to_tuple(cur_matrix@ B)]\n",
    "        outputs[2] = Q_table[matrix_to_tuple(cur_matrix@ C)]\n",
    "        outputs[3] = Q_table[matrix_to_tuple(cur_matrix@ D)]\n",
    "        index = np.argmax(outputs)\n",
    "        if index==0:\n",
    "            cur_matrix = cur_matrix @ A\n",
    "        elif index==1:\n",
    "            cur_matrix = cur_matrix @ B\n",
    "        elif index==2:\n",
    "            cur_matrix = cur_matrix @ C\n",
    "        elif index==3:\n",
    "            cur_matrix = cur_matrix @ D\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q_learning(cur_row: np.array) -> int:\n",
    "    cur_matrix = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "    return matrix_to_num_steps(cur_matrix)\n",
    "\n",
    "test_df['num_moves_Q_learning_needs'] = test_df.apply(test_Q_learning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2668"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \")\n",
    "sum(test_df['num_moves_Q_learning_needs']!=100)/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All paths from $A$ to $I$ for $A \\in \\Gamma$ that take less than 20 matrix multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Of these, the proportion of times where we learned a path that was < 20 moves: \")\n",
    "# encouraging because all of these were generated as sequences of 30 moves\n",
    "# so we've found significantly faster paths back to the origin for almost all moves that we find a path to the origin \n",
    "sum(test_df['num_moves_Q_learning_needs']<20)/sum(test_df['num_moves_Q_learning_needs']!=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test_df[test_df['num_moves_Q_learning_needs']!=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_5789/2721632581.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['first_move_by_Q_learning'] = filtered_df.apply(first_matrix_to_apply, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def first_matrix_to_apply(cur_row):\n",
    "    outputs = [0, 0, 0, 0]\n",
    "    cur_matrix = np.array([\n",
    "        [int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [int(cur_row['val3']), int(cur_row['val4'])]\n",
    "        ])\n",
    "    outputs[0] = Q_table[matrix_to_tuple(cur_matrix@ A)]\n",
    "    outputs[1] = Q_table[matrix_to_tuple(cur_matrix@ B)]\n",
    "    outputs[2] = Q_table[matrix_to_tuple(cur_matrix@ C)]\n",
    "    outputs[3] = Q_table[matrix_to_tuple(cur_matrix@ D)]\n",
    "    return np.argmax(outputs)\n",
    "\n",
    "filtered_df['first_move_by_Q_learning'] = filtered_df.apply(first_matrix_to_apply, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>num_moves_Q_learning_needs</th>\n",
       "      <th>first_move_by_Q_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28945.0</td>\n",
       "      <td>-8727.0</td>\n",
       "      <td>10713.0</td>\n",
       "      <td>-3230.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-233.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>-8432.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1619.0</td>\n",
       "      <td>9231.0</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>217.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-1383.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>478.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>-458.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>-152.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>415.0</td>\n",
       "      <td>-1293.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-458.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>199.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>-440.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         val1    val2     val3    val4  num_moves_Q_learning_needs  \\\n",
       "4     28945.0 -8727.0  10713.0 -3230.0                          10   \n",
       "7      -233.0  1485.0   1323.0 -8432.0                          10   \n",
       "9         1.0     0.0      6.0     1.0                           2   \n",
       "10    -1619.0  9231.0   -600.0  3421.0                           9   \n",
       "11      217.0   -75.0  -1383.0   478.0                           8   \n",
       "...       ...     ...      ...     ...                         ...   \n",
       "9980    478.0   -75.0   2919.0  -458.0                           9   \n",
       "9986   -152.0   483.0     45.0  -143.0                           6   \n",
       "9989     55.0    -6.0     -9.0     1.0                           5   \n",
       "9991    415.0 -1293.0    147.0  -458.0                           8   \n",
       "9996    199.0   -69.0   1269.0  -440.0                           8   \n",
       "\n",
       "      first_move_by_Q_learning  \n",
       "4                            1  \n",
       "7                            0  \n",
       "9                            3  \n",
       "10                           0  \n",
       "11                           1  \n",
       "...                        ...  \n",
       "9980                         1  \n",
       "9986                         0  \n",
       "9989                         1  \n",
       "9991                         0  \n",
       "9996                         1  \n",
       "\n",
       "[2668 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = int(filtered_df.shape[0] * 0.6)\n",
    "plus_one = bound+1\n",
    "train = filtered_df.iloc[1:bound]\n",
    "test = filtered_df.iloc[plus_one:filtered_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_value(row):\n",
    "    return Q_table[(int(row['val1']), \n",
    "    int(row['val2']), \n",
    "    int(row['val3']),\n",
    "    int(row['val4'])\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../Data_Generation/Data_files/subset3_train_rows_SL2Z_Q_learn.csv\", index=False)\n",
    "test.to_csv(\"../Data_Generation/Data_files/subset3_test_rows_SL2Z_Q_learn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_2_is_identity(test_tuple):\n",
    "    assert len(test_tuple)==4\n",
    "    return (test_tuple[0] % 2 == 1 and \n",
    "            test_tuple[1] % 2 == 0 and \n",
    "            test_tuple[2] % 2 == 0 and \n",
    "            test_tuple[3] % 2 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
