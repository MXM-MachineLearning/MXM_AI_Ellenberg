{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../Data_Generation/Data_files/labeled_points/'\n",
    "base_fp = base_dir + 'sl2_Z_2s_train.csv'\n",
    "test_fp = base_dir + 'subset_test_rows_SL2Z_Q_learn.csv'\n",
    "train_fp = base_dir + 'subset_train_rows_SL2Z_Q_learn.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "$4\\times1\\to$ hidden layers $\\to 4\\times 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DeepQModel, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX_SIZE = 4     # i.e. 2x2\n",
    "NUM_GENERATORS = 4  # Number of generators in group (including inverses)\n",
    "\n",
    "class DeepQAgent:\n",
    "    def __init__(self, learning_rate: float, epsilon: float, epsilon_decay: float, \n",
    "                 min_epsilon: float, discount_factor: float, batch_size: int, memory_capacity: int):\n",
    "        # Initialize main an target models and set weights to be equivalent\n",
    "        self.mainModel = DeepQModel(MATRIX_SIZE, NUM_GENERATORS)\n",
    "        self.targetModel = DeepQModel(MATRIX_SIZE, NUM_GENERATORS)\n",
    "        \n",
    "        # TODO: check if this works\n",
    "        self.copy_main_to_target()\n",
    "\n",
    "        # Initialize Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "        self.batch_size = batch_size\n",
    "        self.memory_capacity = memory_capacity\n",
    "\n",
    "        # Optimization initialization\n",
    "        self.optimizer = optim.Adam(self.mainModel.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Experience Replay Buffers and parameters\n",
    "        self.memory = deque()\n",
    "       \n",
    "    def epsilon_greedy_search(self, state):\n",
    "        if torch.rand(1) <= self.epsilon:\n",
    "            return int(NUM_GENERATORS * torch.rand(1))\n",
    "        x = torch.tensor(state)\n",
    "        return self.mainModel.forward(x).argmax()\n",
    "\n",
    "    def copy_main_to_target(self):\n",
    "        self.targetModel.load_state_dict(self.mainModel.state_dict())\n",
    "\n",
    "    def replay(self):\n",
    "        # Ensure there is enough memory for a full batch\n",
    "        if len(self.memory) <  self.batch_size:\n",
    "            return\n",
    "\n",
    "        # Random sample a batch_size's worth of memory\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        # Vectorizing data\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.int64)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        # Bellman Equation: (Reward + discount_factor * state_prediction)\n",
    "        target_predictions = self.targetModel.forward(next_states).max(dim=1)   # states\n",
    "        bellmans = rewards + self.discount_factor * target_predictions\n",
    "        next_q = self.mainModel.forward(states).max(dim=1)                      # next_states\n",
    "\n",
    "        # Calculate loss and perform optimization step\n",
    "        loss = F.mse_loss(next_q, bellmans)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Perform Epsilon decay for each training step\n",
    "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done: bool):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if len(self.memory) > self.memory_capacity:\n",
    "            self.memory.popleft()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgentTrainer: \n",
    "    def __init__(self, agent: DeepQAgent, batch_size) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.agent = agent\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         val1   val2   val3   val4  num_moves_Q_learning_needs  \\\n",
      "0        29.0   12.0   70.0   29.0                           5   \n",
      "1      1657.0  298.0 -506.0  -91.0                          12   \n",
      "2       -43.0   16.0    8.0   -3.0                           6   \n",
      "3        65.0 -112.0  148.0 -255.0                           8   \n",
      "4      -147.0   86.0   94.0  -55.0                           8   \n",
      "...       ...    ...    ...    ...                         ...   \n",
      "69994  -167.0  304.0 -128.0  233.0                          10   \n",
      "69995    53.0   72.0  304.0  413.0                          10   \n",
      "69996  -331.0 -154.0 -144.0  -67.0                           9   \n",
      "69997   -39.0   28.0 -124.0   89.0                          10   \n",
      "69998   -15.0  -94.0    4.0   25.0                           7   \n",
      "\n",
      "       first_move_by_Q_learning  \n",
      "0                             3  \n",
      "1                             3  \n",
      "2                             1  \n",
      "3                             0  \n",
      "4                             1  \n",
      "...                         ...  \n",
      "69994                         0  \n",
      "69995                         2  \n",
      "69996                         3  \n",
      "69997                         1  \n",
      "69998                         2  \n",
      "\n",
      "[69999 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(base_fp)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
