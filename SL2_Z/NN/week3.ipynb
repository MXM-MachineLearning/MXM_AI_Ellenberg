{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=784, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "max_moves = 30  #how many inverse operations on the final destination\n",
    "goal_position = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "\n",
    "def data_generator(matrix_T, matrix_U, num_of_datapoints):\n",
    "    inverse_T = torch.inverse(matrix_T)\n",
    "    inverse_U = torch.inverse(matrix_U)\n",
    "    data = torch.empty((num_of_datapoints, 5), dtype=torch.float64)\n",
    "    for i in range(num_of_datapoints):\n",
    "        start = goal_position\n",
    "        moves = random.randint(1, max_moves)\n",
    "        coin = 3\n",
    "        for q in range(moves):\n",
    "            coin = random.randint(0, 1)\n",
    "            if coin == 1:\n",
    "                #  print(start, inverse_U, \"=\")\n",
    "                start = torch.matmul(inverse_U, start)\n",
    "            #  print(start)\n",
    "            else:\n",
    "                #  print(start, inverse_T, \"=\")\n",
    "                start = torch.matmul(inverse_T, start)\n",
    "                if q != moves - 1:\n",
    "                    start = torch.matmul(inverse_U, start)\n",
    "            # print(start)\n",
    "        # print(\"done\")\n",
    "        data[i, 0] = start[0][0]\n",
    "        data[i, 1] = start[0][1]\n",
    "        data[i, 2] = start[1][0]\n",
    "        data[i, 3] = start[1][1]\n",
    "        data[i, 4] = coin\n",
    "    return data\n",
    "\n",
    "#https://stackoverflow.com/questions/36158058/torch-save-tensor-to-csv-file#:~:text=For%20simple%20tables%2C%20you%20can,then%20to%20a%20Pandas%20dataframe.&text=You%20can%20first%20convert%20the,table%20as%20a%20csv%20file.\n",
    "\n",
    "matrix_T = torch.tensor([[1, 3], [0, 1]], dtype=torch.float64)\n",
    "matrix_U = torch.tensor([[1, 0], [3, 1]], dtype=torch.float64)\n",
    "\n",
    "data = data_generator(matrix_T, matrix_U, 10000)\n",
    "data_table = data.numpy()\n",
    "\n",
    "x_train = data_table[:, :-1]\n",
    "y_train = data_table[:, -1]\n",
    "\n",
    "# matrix_T = torch.tensor([[0, -1], [1, 0]], dtype=torch.float64)\n",
    "# matrix_U = torch.tensor([[1, 1], [0, 1]], dtype=torch.float64)\n",
    "\n",
    "data = data_generator(matrix_T, matrix_U, 10000)\n",
    "data_table = data.numpy()\n",
    "\n",
    "x_test = data_table[:, :-1]\n",
    "y_test = data_table[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=4, activation = 'sigmoid'))\n",
    "model.add(Dense(64,  activation = 'sigmoid'))\n",
    "model.add(Dense(16, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9615\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.5067e-04 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.6352e-04 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 6.2813e-04 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2667e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4825e-04 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.8620e-04 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3608e-04 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9507e-04 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6102e-04 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3240e-04 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0806e-04 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8723e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6923e-04 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5356e-04 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3983e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2775e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1704e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0751e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.8994e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.1349e-05 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.4459e-05 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.8232e-05 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.2582e-05 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.7444e-05 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2759e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.8474e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4558e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.0960e-05 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7653e-05 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4606e-05 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.1782e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.9179e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6769e-05 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4533e-05 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2457e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0526e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8727e-05 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7050e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5485e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4022e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2654e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1374e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0174e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9050e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7996e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7007e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6077e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5203e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.4380e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3606e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2877e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2191e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1544e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0934e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0358e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.8145e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.3017e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.8173e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.3596e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.9270e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.5180e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.1311e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.7650e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.4187e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.0908e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.7805e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4865e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2081e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.9443e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6944e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4575e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2330e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.0201e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.8182e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6268e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4452e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2729e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1095e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9544e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8072e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6675e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5349e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4089e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2894e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1760e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0682e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9658e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8686e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7763e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6886e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6053e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5262e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.4510e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3795e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x138b5d010>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3415e-06 - accuracy: 1.0000\n",
      "1.3414522754828795e-06\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=100)\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00119146]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(torch.tensor([[1, 0, 6, 1]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5. -12.  -2.   5.]]\n",
      "[[  5. -12.]\n",
      " [ -2.   5.]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "APPLIED U\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "APPLIED U\n",
      "[[   5. -117.   -2.   47.]]\n",
      "[[   5. -117.]\n",
      " [  -2.   47.]]\n"
     ]
    }
   ],
   "source": [
    "# FOLLOW IT THROUGH\n",
    "\n",
    "matrix_T = torch.tensor([[0, -1], [1, 0]], dtype=torch.float64)\n",
    "matrix_U = torch.tensor([[1, 1], [0, 1]], dtype=torch.float64)\n",
    "\n",
    "array = data_generator(matrix_T, matrix_U, 1).numpy()[:, :-1]\n",
    "\n",
    "matrix = array.reshape(2, 2)\n",
    "iterations = 0\n",
    "\n",
    "print(array)\n",
    "print(matrix)\n",
    "\n",
    "def is_target_array(array):\n",
    "    target = np.array([1, 0, 0, 1])\n",
    "    return np.array_equal(array, target)\n",
    "\n",
    "while not is_target_array(array) and iterations <= 20:\n",
    "    inverse_matrix_T = torch.inverse(matrix_T)\n",
    "    inverse_matrix_U = torch.inverse(matrix_U)\n",
    "    iterations = iterations + 1\n",
    "    if model.predict(array) >= 0.5: \n",
    "        matrix = matrix @ inverse_matrix_T.numpy()\n",
    "        print(\"APPLIED T\")\n",
    "    else: \n",
    "        matrix = matrix @ inverse_matrix_U.numpy()\n",
    "        print(\"APPLIED U\")\n",
    "    array = matrix.reshape(1,4)\n",
    "\n",
    "print(array)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
