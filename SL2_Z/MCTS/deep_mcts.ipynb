{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:28:23.047407Z",
     "start_time": "2024-02-28T00:28:03.339254Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nogil=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: RUN https://github.com/colesbury/nogil FOR MULTITHREADED (performance not necessarily better)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "import threading\n",
    "import concurrent\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from mcts_util import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import sys\n",
    "print(f\"nogil={getattr(sys.flags, 'nogil', False)}\")\n",
    "\n",
    "\"\"\"\n",
    "NOTE: RUN https://github.com/colesbury/nogil FOR MULTITHREADED (performance not necessarily better)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_value_fp = 'sl2z_value_fn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e3ddf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:38.334723Z",
     "start_time": "2024-02-28T00:29:38.325718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memory for better batching\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, width) -> None:\n",
    "        self.mem_ = None\n",
    "        self.len_ = 0\n",
    "    def record(self, obs):\n",
    "        if self.len_ == 0:\n",
    "            self.mem_ = obs\n",
    "        else:\n",
    "            self.mem_ = torch.cat((self.mem_, obs), dim=0)\n",
    "        self.len_ += 1\n",
    "    def recall(self, n_samples):\n",
    "        if self.len_ == 0:\n",
    "            return None\n",
    "        des_len = min(n_samples, self.len_)\n",
    "        indices = torch.ones(self.mem_.shape[0]).multinomial(des_len, replacement=False)\n",
    "        return self.mem_[indices]\n",
    "    def size(self):\n",
    "        return self.len_\n",
    "    def clear(self):\n",
    "        self.len_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19bdb93248565c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:39.699250Z",
     "start_time": "2024-02-28T00:29:39.688411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_C = 1 / math.sqrt(2)\n",
    "k_thread_count_limit = 20\n",
    "k_core_limit = 5\n",
    "\n",
    "\n",
    "\n",
    "def train_play(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size=16):\n",
    "    history = Memory(4+1+4)    # [stateX,stateY,value] (probs are sampled probs)\n",
    "    loss_fn = Loss()\n",
    "    tot_loss = 0\n",
    "    for t in range(epochs):\n",
    "        try:\n",
    "            for o in optimizers:\n",
    "                o.zero_grad()\n",
    "            # Repeat the following:\n",
    "            # 1) run the NN on some random initial state\n",
    "            # 2) update the NN based off performance in that game\n",
    "                \n",
    "            # play out some games\n",
    "            k_comp_limit = comp_limit(t / epochs)\n",
    "\n",
    "            # NOTE: ProcessPoolExecutor requires placing called functions/data structs in separate imported file\n",
    "            payload = [(rand_start_state_fn().flatten(), actions, value_fn, k_comp_limit, k_C, k_thread_count_limit, False) for i in range(batch_size)]\n",
    "            for i in iter(payload):\n",
    "                history.record(one_batch(i))\n",
    "\n",
    "            # with concurrent.futures.ProcessPoolExecutor(max_workers=k_core_limit) as executor:\n",
    "            #     for rv in zip(executor.map(one_batch, iter(payload))):\n",
    "            #         history.record(rv[0])\n",
    "\n",
    "            # train NN on games just played\n",
    "            batch = history.recall(batch_size)\n",
    "            batch_states = batch[:,:4]\n",
    "            batch_vsampled = batch[:,4]\n",
    "            # batch_psampled = batch[:,3:]\n",
    "            \n",
    "            loss = loss_fn(value_fn(batch_states).view(batch_vsampled.shape), batch_vsampled)\n",
    "            loss.backward()\n",
    "            tot_loss += loss.item() / batch_size\n",
    "\n",
    "            history.clear()\n",
    "\n",
    "            for o in optimizers:\n",
    "                o.step()\n",
    "\n",
    "\n",
    "            if (t+1) % 10 == 0:\n",
    "                print(\"Epoch:\", t+1,\"\\t\\tLoss:\",tot_loss/10)\n",
    "                tot_loss = 0\n",
    "                torch.save(value_fn.state_dict(), str(t+1) + '_' + trained_value_fp)\n",
    "        except:\n",
    "            t = t-1\n",
    "            save_point = (t+1) - (t+1) % 10\n",
    "            print(f\"Resuming from last save point! (batch {save_point})\")\n",
    "            value_fn.load_state_dict(torch.load(str(save_point) + '_' + trained_value_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e004f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:40.566311Z",
     "start_time": "2024-02-28T00:29:40.556759Z"
    }
   },
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (3.5))\n",
    "k_min_comps = int(k_state_upper_lim ** (3))\n",
    "\n",
    "value_fn_2 = ValueNN(4).to(device)\n",
    "value_optim = optim.SGD(value_fn_2.parameters(), lr=0.00005, momentum=0.9)\n",
    "\n",
    "def gen_start_state():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((2, 2)) * limit + 1).float()\n",
    "\n",
    "def adaptive_comp_limit(frac_epochs):\n",
    "    # linearly decrease computation limit as model becomes better over time\n",
    "    rv = k_comp_limit - (k_comp_limit - k_min_comps) * frac_epochs\n",
    "    return int(rv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41211b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T02:48:18.942268Z",
     "start_time": "2024-02-28T02:48:12.374093Z"
    }
   },
   "outputs": [],
   "source": [
    "train_play(epochs=2, actions=k_mcts_actions, policy_fn=None, value_fn=value_fn_2, \n",
    "           optimizers=[value_optim], rand_start_state_fn=gen_start_state, \n",
    "           comp_limit=adaptive_comp_limit, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c191e6c845a0bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:47:31.912513Z",
     "start_time": "2023-11-06T02:47:31.904073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float).unsqueeze(0)).flatten().to(device)\n",
    "            action_plot[torch.argmax(rv)].append((i.cpu(),j.cpu()))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        if len(action) == 0:\n",
    "            continue\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x, y, policy_fn, actions=k_sl2z_gen, dbs=None):\n",
    "    correct = 0\n",
    "    guess_dist = [0] * len(actions)\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0).to(device)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(file, actions, policy_fn, cases=100, dbs=None):\n",
    "    # test_X, test_Y = get_test_data(data_name)\n",
    "    test_X = file[:,:-1]\n",
    "    test_Y = file[:,-1]\n",
    "    test_X = test_X.to(device)\n",
    "    test_Y.reshape(-1, 1)\n",
    "    test_Y = test_Y.to(device)\n",
    "\n",
    "    acc, guesses = test(x=test_X[:cases], y=test_Y[:cases],\n",
    "                        policy_fn=policy_fn, actions=actions, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n",
    "    return acc, guesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab1560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_fn_2.load_state_dict(torch.load('weights/weights_153465_0/100_sl2z_value_fn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, j: 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_2259/1274071067.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.124\n",
      "Guess Distribution: [354, 448, 578, 620]\n",
      "i, j: 0 10\n",
      "Test Accuracy: 0.3435\n",
      "Guess Distribution: [406, 642, 281, 671]\n",
      "i, j: 0 20\n",
      "Test Accuracy: 0.2185\n",
      "Guess Distribution: [223, 681, 316, 780]\n",
      "i, j: 0 30\n",
      "Test Accuracy: 0.0845\n",
      "Guess Distribution: [163, 660, 529, 648]\n",
      "i, j: 0 40\n",
      "Test Accuracy: 0.4665\n",
      "Guess Distribution: [453, 544, 402, 601]\n",
      "i, j: 0 50\n",
      "Test Accuracy: 0.283\n",
      "Guess Distribution: [472, 694, 190, 644]\n",
      "i, j: 0 60\n",
      "Test Accuracy: 0.217\n",
      "Guess Distribution: [463, 900, 109, 528]\n",
      "i, j: 0 70\n",
      "Test Accuracy: 0.3925\n",
      "Guess Distribution: [566, 747, 241, 446]\n",
      "i, j: 0 80\n",
      "Test Accuracy: 0.279\n",
      "Guess Distribution: [497, 868, 130, 505]\n",
      "i, j: 0 90\n",
      "Test Accuracy: 0.2155\n",
      "Guess Distribution: [527, 850, 181, 442]\n",
      "i, j: 0 100\n",
      "Test Accuracy: 0.1595\n",
      "Guess Distribution: [460, 983, 94, 463]\n",
      "i, j: 1 0\n",
      "Test Accuracy: 0.5005\n",
      "Guess Distribution: [304, 311, 694, 691]\n",
      "i, j: 1 10\n",
      "Test Accuracy: 0.651\n",
      "Guess Distribution: [412, 461, 565, 562]\n",
      "i, j: 1 20\n",
      "Test Accuracy: 0.6765\n",
      "Guess Distribution: [511, 381, 555, 553]\n",
      "i, j: 1 30\n",
      "Test Accuracy: 0.7\n",
      "Guess Distribution: [513, 392, 569, 526]\n",
      "i, j: 1 40\n",
      "Test Accuracy: 0.36\n",
      "Guess Distribution: [290, 808, 406, 496]\n",
      "i, j: 1 50\n",
      "Test Accuracy: 0.342\n",
      "Guess Distribution: [307, 779, 443, 471]\n",
      "i, j: 1 60\n",
      "Test Accuracy: 0.363\n",
      "Guess Distribution: [310, 797, 397, 496]\n",
      "i, j: 1 70\n",
      "Test Accuracy: 0.3785\n",
      "Guess Distribution: [357, 666, 431, 546]\n",
      "i, j: 1 80\n",
      "Test Accuracy: 0.1825\n",
      "Guess Distribution: [452, 571, 405, 572]\n",
      "i, j: 1 90\n",
      "Test Accuracy: 0.111\n",
      "Guess Distribution: [639, 394, 429, 538]\n",
      "i, j: 1 100\n",
      "Test Accuracy: 0.058\n",
      "Guess Distribution: [531, 410, 464, 595]\n",
      "i, j: 2 0\n",
      "Test Accuracy: 0.336\n",
      "Guess Distribution: [1027, 533, 233, 207]\n",
      "i, j: 2 10\n",
      "Test Accuracy: 0.415\n",
      "Guess Distribution: [441, 568, 354, 637]\n",
      "i, j: 2 20\n",
      "Test Accuracy: 0.2535\n",
      "Guess Distribution: [533, 533, 300, 634]\n",
      "i, j: 2 30\n",
      "Test Accuracy: 0.1635\n",
      "Guess Distribution: [891, 542, 433, 134]\n",
      "i, j: 2 40\n",
      "Test Accuracy: 0.202\n",
      "Guess Distribution: [615, 669, 446, 270]\n",
      "i, j: 2 50\n",
      "Test Accuracy: 0.2055\n",
      "Guess Distribution: [504, 605, 518, 373]\n",
      "i, j: 2 60\n",
      "Test Accuracy: 0.178\n",
      "Guess Distribution: [489, 629, 537, 345]\n",
      "i, j: 2 70\n",
      "Test Accuracy: 0.152\n",
      "Guess Distribution: [413, 495, 539, 553]\n",
      "i, j: 2 80\n",
      "Test Accuracy: 0.17\n",
      "Guess Distribution: [646, 605, 405, 344]\n",
      "i, j: 2 90\n",
      "Test Accuracy: 0.076\n",
      "Guess Distribution: [778, 488, 381, 353]\n",
      "i, j: 2 100\n",
      "Test Accuracy: 0.055\n",
      "Guess Distribution: [784, 483, 354, 379]\n",
      "i, j: 3 0\n",
      "Test Accuracy: 0.1455\n",
      "Guess Distribution: [747, 676, 202, 375]\n",
      "i, j: 3 10\n",
      "Test Accuracy: 0.3655\n",
      "Guess Distribution: [517, 453, 480, 550]\n",
      "i, j: 3 20\n",
      "Test Accuracy: 0.113\n",
      "Guess Distribution: [297, 137, 921, 645]\n",
      "i, j: 3 30\n",
      "Test Accuracy: 0.3635\n",
      "Guess Distribution: [476, 449, 631, 444]\n",
      "i, j: 3 40\n",
      "Test Accuracy: 0.268\n",
      "Guess Distribution: [539, 411, 661, 389]\n",
      "i, j: 3 50\n",
      "Test Accuracy: 0.26\n",
      "Guess Distribution: [475, 424, 677, 424]\n",
      "i, j: 3 60\n",
      "Test Accuracy: 0.1845\n",
      "Guess Distribution: [428, 442, 525, 605]\n",
      "i, j: 3 70\n",
      "Test Accuracy: 0.1575\n",
      "Guess Distribution: [621, 436, 417, 526]\n",
      "i, j: 3 80\n",
      "Test Accuracy: 0.1805\n",
      "Guess Distribution: [734, 682, 282, 302]\n",
      "i, j: 3 90\n",
      "Test Accuracy: 0.137\n",
      "Guess Distribution: [740, 769, 202, 289]\n",
      "i, j: 3 100\n",
      "Test Accuracy: 0.1185\n",
      "Guess Distribution: [751, 834, 179, 236]\n",
      "i, j: 4 0\n",
      "Test Accuracy: 0.163\n",
      "Guess Distribution: [750, 602, 477, 171]\n",
      "i, j: 4 10\n",
      "Test Accuracy: 0.305\n",
      "Guess Distribution: [485, 611, 288, 616]\n",
      "i, j: 4 20\n",
      "Test Accuracy: 0.3205\n",
      "Guess Distribution: [418, 627, 326, 629]\n",
      "i, j: 4 30\n",
      "Test Accuracy: 0.3305\n",
      "Guess Distribution: [406, 619, 330, 645]\n",
      "i, j: 4 40\n",
      "Test Accuracy: 0.281\n",
      "Guess Distribution: [300, 695, 277, 728]\n",
      "i, j: 4 50\n",
      "Test Accuracy: 0.3655\n",
      "Guess Distribution: [281, 643, 371, 705]\n",
      "i, j: 4 60\n",
      "Test Accuracy: 0.2805\n",
      "Guess Distribution: [279, 753, 322, 646]\n",
      "i, j: 4 70\n",
      "Test Accuracy: 0.2315\n",
      "Guess Distribution: [417, 564, 595, 424]\n",
      "i, j: 4 80\n",
      "Test Accuracy: 0.252\n",
      "Guess Distribution: [440, 520, 630, 410]\n",
      "i, j: 4 90\n",
      "Test Accuracy: 0.3695\n",
      "Guess Distribution: [276, 555, 441, 728]\n",
      "i, j: 4 100\n",
      "Test Accuracy: 0.303\n",
      "Guess Distribution: [179, 677, 228, 916]\n"
     ]
    }
   ],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "test_file = \"../Data_Generation/Data_files/labeled_points/sl2_Z_test.csv\"\n",
    "\n",
    "db2 = torch.linspace(2, k_dbound_size, k_dbound_size - 1).to(device)\n",
    "two_dbs = [db2, db2]\n",
    "\n",
    "def alt_policy(state, value_fn):\n",
    "    x = [i(state) for i in k_mcts_actions]\n",
    "    x = [value_fn(i) for i in x]\n",
    "    x = torch.tensor(x)\n",
    "    return x\n",
    "\n",
    "import pandas as pd\n",
    "f = pd.read_csv(test_file, header=0, dtype=np.float64)\n",
    "f = torch.tensor(f.drop('num_moves_Q_learning_needs', axis=1).values, dtype=torch.float)\n",
    "\n",
    "def get_fname(a, b):\n",
    "    return 'weights/weights_153465_' + str(a) + '/' + str(b) + '_sl2z_value_fn.pth'\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(0, 101, 10):\n",
    "        print(f\"i, j: {i} {j}\")\n",
    "        value_fn_2.load_state_dict(torch.load(get_fname(i, j)))\n",
    "        run_test(f, k_mcts_actions, policy_fn=lambda a: alt_policy(a, value_fn_2), cases=k_cases, dbs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c81ea1aa8fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
