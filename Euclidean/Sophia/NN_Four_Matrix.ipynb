{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:36:54.337430Z",
     "start_time": "2023-10-03T18:36:54.287546Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Generator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "453098ccfa7c9c3e"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "matrix_a = np.array([[1, 1], [0, 1]])\n",
    "matrix_b = np.array([[1, -1], [0, 1]])\n",
    "matrix_c = np.array([[1, 0], [-1, 1]])\n",
    "matrix_d = np.array([[1, 0], [1, 1]])\n",
    "\n",
    "inverse_a = np.array([[1, -1], [0, 1]])\n",
    "inverse_b = np.array([[1, 1], [0, 1]])\n",
    "inverse_c = np.array([[1, 0], [1, 1]])\n",
    "inverse_d = np.array([[1, 0], [-1, 1]])\n",
    "\n",
    "def data_generator(num_points):\n",
    "    data = []\n",
    "    max_moves = 30\n",
    "    end_position = np.array([[random.randint(1, 11),0]]) \n",
    "    last_move = 5\n",
    "    for i in range(num_points):\n",
    "        current_position = end_position\n",
    "        moves = random.randint(1, max_moves)\n",
    "        for q in range(moves):\n",
    "            coin = random.randint(0,3)\n",
    "            if coin == 0 and last_move != 1: \n",
    "                current_position = current_position @ inverse_a\n",
    "                last_move = 0 \n",
    "            if coin == 1 and last_move != 0: \n",
    "                current_position = current_position @ inverse_b\n",
    "                last_move = 1 \n",
    "            if coin == 2 and last_move != 3: \n",
    "                current_position = current_position @ inverse_c\n",
    "                last_move = 2 \n",
    "            if coin == 3 and last_move != 2: \n",
    "                current_position = current_position @ inverse_d\n",
    "                last_move = 3 \n",
    "        last_move_array = np.array([0,0,0,0])\n",
    "        if last_move == 0: \n",
    "            last_move_array = np.array([1, 0, 0, 0 ])\n",
    "        if last_move == 1: \n",
    "            last_move_array = np.array([0, 1, 0, 0 ])\n",
    "        if last_move == 2: \n",
    "            last_move_array = np.array([0, 0, 1, 0 ])\n",
    "        if last_move == 3: \n",
    "            last_move_array = np.array([0, 0, 0, 1])\n",
    "        current_position = np.append(current_position, last_move_array)\n",
    "        data.append(current_position.tolist())\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:36:54.487063Z",
     "start_time": "2023-10-03T18:36:54.312172Z"
    }
   },
   "id": "ececc1e29c90cb5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn to CSV using Pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "704519aa252b7a7e"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "data_pd = pd.DataFrame(data_generator(200000))\n",
    "data_pd.to_csv(\"generated_pairs.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:01.395352Z",
     "start_time": "2023-10-03T18:36:54.322214Z"
    }
   },
   "id": "1599dfdfd30866bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn CSV file to tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4571c88ff22805"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"generated_pairs.csv\", names=[\"0\",\"1\",\"2\", \"3\", \"4\", \"5\"], delimiter=\",\")\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(data.loc[:, \"0\":\"1\"].values,dtype=torch.float32), # input \n",
    "    torch.tensor(data.loc[:, \"2\":\"5\"].values, dtype = torch.float32) #output \n",
    ")\n",
    "X, Y = dataset[:] #label input and output "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:01.477701Z",
     "start_time": "2023-10-03T18:37:01.399095Z"
    }
   },
   "id": "b79ea49781de68aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6fe5d18b887b"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  0.,   1.],\n        [  7., -16.],\n        [-49., -19.],\n        ...,\n        [ 59.,  50.],\n        [ 14.,  17.],\n        [  7.,  25.]])"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:01.485521Z",
     "start_time": "2023-10-03T18:37:01.481108Z"
    }
   },
   "id": "be690e147372016a"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0.weight, Data Type: torch.float32\n",
      "Layer: 0.bias, Data Type: torch.float32\n",
      "Layer: 2.weight, Data Type: torch.float32\n",
      "Layer: 2.bias, Data Type: torch.float32\n",
      "Layer: 4.weight, Data Type: torch.float32\n",
      "Layer: 4.bias, Data Type: torch.float32\n",
      "Layer: 6.weight, Data Type: torch.float32\n",
      "Layer: 6.bias, Data Type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 128), #first layer 128\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64), #second layer 64\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16), #third layer 16\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,4), #singular output \n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, Data Type: {param.dtype}\")\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() #should this be our loss function too? \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.02) #chose Adam and lr from site "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:01.495711Z",
     "start_time": "2023-10-03T18:37:01.488379Z"
    }
   },
   "id": "9d9cbc81aeca6894"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b972b98a0f7a65a7"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "num_batches = 10 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:01.497727Z",
     "start_time": "2023-10-03T18:37:01.495809Z"
    }
   },
   "id": "d4551966105f346e"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 7.254126994593298e-05\n",
      "Finished epoch 1, latest loss 6.61210050206234e-05\n",
      "Finished epoch 2, latest loss 6.283432388751982e-05\n",
      "Finished epoch 3, latest loss 6.453536727315295e-05\n",
      "Finished epoch 4, latest loss 6.53023038533756e-05\n",
      "Finished epoch 5, latest loss 6.122125741176027e-05\n",
      "Finished epoch 6, latest loss 6.17996627610055e-05\n",
      "Finished epoch 7, latest loss 6.298472890007453e-05\n",
      "Finished epoch 8, latest loss 6.59031928562815e-05\n",
      "Finished epoch 9, latest loss 6.697067332820532e-05\n",
      "Finished epoch 10, latest loss 6.730745874888484e-05\n",
      "Finished epoch 11, latest loss 6.727147918101046e-05\n",
      "Finished epoch 12, latest loss 6.722252553497822e-05\n",
      "Finished epoch 13, latest loss 6.737004569715006e-05\n",
      "Finished epoch 14, latest loss 6.747153282628057e-05\n",
      "Finished epoch 15, latest loss 6.737064293270453e-05\n",
      "Finished epoch 16, latest loss 6.744966816376093e-05\n",
      "Finished epoch 17, latest loss 6.73408848665443e-05\n",
      "Finished epoch 18, latest loss 6.73786007090396e-05\n",
      "Finished epoch 19, latest loss 6.942941581240122e-05\n",
      "Finished epoch 20, latest loss 6.527031449849465e-05\n",
      "Finished epoch 21, latest loss 6.751437106633589e-05\n",
      "Finished epoch 22, latest loss 6.753488092205383e-05\n",
      "Finished epoch 23, latest loss 6.753107220429627e-05\n",
      "Finished epoch 24, latest loss 6.752652141242162e-05\n",
      "Finished epoch 25, latest loss 6.752345655691155e-05\n",
      "Finished epoch 26, latest loss 6.752148484512094e-05\n",
      "Finished epoch 27, latest loss 6.75201359987539e-05\n",
      "Finished epoch 28, latest loss 6.751912034068523e-05\n",
      "Finished epoch 29, latest loss 6.751830614530857e-05\n",
      "Finished epoch 30, latest loss 6.751760460214728e-05\n",
      "Finished epoch 31, latest loss 6.751696445146315e-05\n",
      "Finished epoch 32, latest loss 6.751634814251771e-05\n",
      "Finished epoch 33, latest loss 6.7515727661268e-05\n",
      "Finished epoch 34, latest loss 6.751506903323638e-05\n",
      "Finished epoch 35, latest loss 6.751434126416251e-05\n",
      "Finished epoch 36, latest loss 6.75135044191341e-05\n",
      "Finished epoch 37, latest loss 6.751249412545662e-05\n",
      "Finished epoch 38, latest loss 6.751119117443659e-05\n",
      "Finished epoch 39, latest loss 6.750941496490332e-05\n",
      "Finished epoch 40, latest loss 6.750681144703713e-05\n",
      "Finished epoch 41, latest loss 6.750260576433018e-05\n",
      "Finished epoch 42, latest loss 6.749478150173183e-05\n",
      "Finished epoch 43, latest loss 6.746332649981953e-05\n",
      "Finished epoch 44, latest loss 6.756992529772764e-05\n",
      "Finished epoch 45, latest loss 6.753004224118436e-05\n",
      "Finished epoch 46, latest loss 6.752464327945542e-05\n",
      "Finished epoch 47, latest loss 6.75039605711319e-05\n",
      "Finished epoch 48, latest loss 6.744319870796428e-05\n",
      "Finished epoch 49, latest loss 6.740918489144584e-05\n",
      "Finished epoch 50, latest loss 6.751960611611127e-05\n",
      "Finished epoch 51, latest loss 6.752146100338224e-05\n",
      "Finished epoch 52, latest loss 6.75207326382649e-05\n",
      "Finished epoch 53, latest loss 6.751936352641997e-05\n",
      "Finished epoch 54, latest loss 6.751827455500479e-05\n",
      "Finished epoch 55, latest loss 6.751749612223619e-05\n",
      "Finished epoch 56, latest loss 6.751690544315986e-05\n",
      "Finished epoch 57, latest loss 6.751642085982074e-05\n",
      "Finished epoch 58, latest loss 6.751599051643719e-05\n",
      "Finished epoch 59, latest loss 6.75155863989662e-05\n",
      "Finished epoch 60, latest loss 6.751518049336481e-05\n",
      "Finished epoch 61, latest loss 6.751476266689407e-05\n",
      "Finished epoch 62, latest loss 6.751430907781527e-05\n",
      "Finished epoch 63, latest loss 6.751380959338947e-05\n",
      "Finished epoch 64, latest loss 6.751323977583451e-05\n",
      "Finished epoch 65, latest loss 6.751257637945514e-05\n",
      "Finished epoch 66, latest loss 6.751178721790412e-05\n",
      "Finished epoch 67, latest loss 6.751082520374752e-05\n",
      "Finished epoch 68, latest loss 6.750963848120365e-05\n",
      "Finished epoch 69, latest loss 6.750813585562199e-05\n",
      "Finished epoch 70, latest loss 6.750627262374247e-05\n",
      "Finished epoch 71, latest loss 6.750393374917586e-05\n",
      "Finished epoch 72, latest loss 6.750112996070457e-05\n",
      "Finished epoch 73, latest loss 6.749785529789392e-05\n",
      "Finished epoch 74, latest loss 6.7494025718615e-05\n",
      "Finished epoch 75, latest loss 6.74891363740508e-05\n",
      "Finished epoch 76, latest loss 6.748245234260584e-05\n",
      "Finished epoch 77, latest loss 6.747562228051134e-05\n",
      "Finished epoch 78, latest loss 6.746785941039014e-05\n",
      "Finished epoch 79, latest loss 6.745730169244967e-05\n",
      "Finished epoch 80, latest loss 6.744040743640581e-05\n",
      "Finished epoch 81, latest loss 6.741613356619038e-05\n",
      "Finished epoch 82, latest loss 6.738120839921008e-05\n",
      "Finished epoch 83, latest loss 6.734968723647287e-05\n",
      "Finished epoch 84, latest loss 6.732401206806526e-05\n",
      "Finished epoch 85, latest loss 6.730538094135701e-05\n",
      "Finished epoch 86, latest loss 6.743459005216265e-05\n",
      "Finished epoch 87, latest loss 6.739376882320148e-05\n",
      "Finished epoch 88, latest loss 6.727093201310727e-05\n",
      "Finished epoch 89, latest loss 6.756942164099756e-05\n",
      "Finished epoch 90, latest loss 6.753056616339233e-05\n",
      "Finished epoch 91, latest loss 6.752923579437278e-05\n",
      "Finished epoch 92, latest loss 6.752117847877862e-05\n",
      "Finished epoch 93, latest loss 6.75194457804185e-05\n",
      "Finished epoch 94, latest loss 6.751876748295243e-05\n",
      "Finished epoch 95, latest loss 6.751838661117668e-05\n",
      "Finished epoch 96, latest loss 6.751815236609394e-05\n",
      "Finished epoch 97, latest loss 6.751798487787957e-05\n",
      "Finished epoch 98, latest loss 6.751785672853405e-05\n",
      "Finished epoch 99, latest loss 6.751775182488376e-05\n",
      "Finished epoch 100, latest loss 6.75176648025375e-05\n",
      "Finished epoch 101, latest loss 6.751758850897365e-05\n",
      "Finished epoch 102, latest loss 6.751752294419222e-05\n",
      "Finished epoch 103, latest loss 6.7517462743802e-05\n",
      "Finished epoch 104, latest loss 6.75174132721942e-05\n",
      "Finished epoch 105, latest loss 6.75173655887168e-05\n",
      "Finished epoch 106, latest loss 6.751732565380447e-05\n",
      "Finished epoch 107, latest loss 6.751728631493561e-05\n",
      "Finished epoch 108, latest loss 6.751725234045796e-05\n",
      "Finished epoch 109, latest loss 6.751722015411072e-05\n",
      "Finished epoch 110, latest loss 6.751718975589387e-05\n",
      "Finished epoch 111, latest loss 6.751716472206823e-05\n",
      "Finished epoch 112, latest loss 6.751713611198179e-05\n",
      "Finished epoch 113, latest loss 6.751710988606922e-05\n",
      "Finished epoch 114, latest loss 6.751708604433053e-05\n",
      "Finished epoch 115, latest loss 6.751706339467876e-05\n",
      "Finished epoch 116, latest loss 6.751703955294005e-05\n",
      "Finished epoch 117, latest loss 6.751702167163603e-05\n",
      "Finished epoch 118, latest loss 6.751699961802773e-05\n",
      "Finished epoch 119, latest loss 6.751698233276717e-05\n",
      "Finished epoch 120, latest loss 6.751696147124581e-05\n",
      "Finished epoch 121, latest loss 6.751694120576791e-05\n",
      "Finished epoch 122, latest loss 6.751692332446388e-05\n",
      "Finished epoch 123, latest loss 6.751690723129026e-05\n",
      "Finished epoch 124, latest loss 6.751688517768196e-05\n",
      "Finished epoch 125, latest loss 6.75168696805518e-05\n",
      "Finished epoch 126, latest loss 6.751684762694351e-05\n",
      "Finished epoch 127, latest loss 6.751682974563947e-05\n",
      "Finished epoch 128, latest loss 6.751681067224852e-05\n",
      "Finished epoch 129, latest loss 6.751679219490102e-05\n",
      "Finished epoch 130, latest loss 6.75167707373362e-05\n",
      "Finished epoch 131, latest loss 6.751675047185829e-05\n",
      "Finished epoch 132, latest loss 6.751673080242387e-05\n",
      "Finished epoch 133, latest loss 6.751670934485904e-05\n",
      "Finished epoch 134, latest loss 6.751668669520727e-05\n",
      "Finished epoch 135, latest loss 6.75166604692947e-05\n",
      "Finished epoch 136, latest loss 6.751663424338213e-05\n",
      "Finished epoch 137, latest loss 6.751661159373037e-05\n",
      "Finished epoch 138, latest loss 6.751658238760045e-05\n",
      "Finished epoch 139, latest loss 6.75165502012532e-05\n",
      "Finished epoch 140, latest loss 6.751651622677556e-05\n",
      "Finished epoch 141, latest loss 6.751648284834137e-05\n",
      "Finished epoch 142, latest loss 6.751644350947251e-05\n",
      "Finished epoch 143, latest loss 6.751639940225592e-05\n",
      "Finished epoch 144, latest loss 6.751635469899585e-05\n",
      "Finished epoch 145, latest loss 6.751630582343152e-05\n",
      "Finished epoch 146, latest loss 6.75162509874325e-05\n",
      "Finished epoch 147, latest loss 6.751618423056414e-05\n",
      "Finished epoch 148, latest loss 6.75161115132611e-05\n",
      "Finished epoch 149, latest loss 6.751602925926258e-05\n",
      "Finished epoch 150, latest loss 6.751593329626431e-05\n",
      "Finished epoch 151, latest loss 6.751582362426628e-05\n",
      "Finished epoch 152, latest loss 6.751569368679035e-05\n",
      "Finished epoch 153, latest loss 6.751553752340187e-05\n",
      "Finished epoch 154, latest loss 6.751534798157919e-05\n",
      "Finished epoch 155, latest loss 6.751511314045297e-05\n",
      "Finished epoch 156, latest loss 6.751482048311041e-05\n",
      "Finished epoch 157, latest loss 6.751444080342159e-05\n",
      "Finished epoch 158, latest loss 6.751393535856113e-05\n",
      "Finished epoch 159, latest loss 6.751324812044306e-05\n",
      "Finished epoch 160, latest loss 6.751227120519976e-05\n",
      "Finished epoch 161, latest loss 6.75108401048342e-05\n",
      "Finished epoch 162, latest loss 6.750870030878575e-05\n",
      "Finished epoch 163, latest loss 6.750568432884001e-05\n",
      "Finished epoch 164, latest loss 6.750218376555517e-05\n",
      "Finished epoch 165, latest loss 6.749817596927945e-05\n",
      "Finished epoch 166, latest loss 6.748675160413719e-05\n",
      "Finished epoch 167, latest loss 6.748517924146982e-05\n",
      "Finished epoch 168, latest loss 6.748429292483359e-05\n",
      "Finished epoch 169, latest loss 6.747821208937779e-05\n",
      "Finished epoch 170, latest loss 6.74706840603828e-05\n",
      "Finished epoch 171, latest loss 6.746503356831056e-05\n",
      "Finished epoch 172, latest loss 6.745535203426736e-05\n",
      "Finished epoch 173, latest loss 6.744388177377808e-05\n",
      "Finished epoch 174, latest loss 6.74206867422389e-05\n",
      "Finished epoch 175, latest loss 6.741385727618786e-05\n",
      "Finished epoch 176, latest loss 6.736610346565577e-05\n",
      "Finished epoch 177, latest loss 6.736634545930358e-05\n",
      "Finished epoch 178, latest loss 6.732718123118216e-05\n",
      "Finished epoch 179, latest loss 6.732858431750474e-05\n",
      "Finished epoch 180, latest loss 6.731836038390609e-05\n",
      "Finished epoch 181, latest loss 6.731685597019402e-05\n",
      "Finished epoch 182, latest loss 6.731550056734884e-05\n",
      "Finished epoch 183, latest loss 6.731285115413565e-05\n",
      "Finished epoch 184, latest loss 6.730703257780555e-05\n",
      "Finished epoch 185, latest loss 6.72840151672197e-05\n",
      "Finished epoch 186, latest loss 6.722536210584023e-05\n",
      "Finished epoch 187, latest loss 6.72426819369199e-05\n",
      "Finished epoch 188, latest loss 6.726538821281571e-05\n",
      "Finished epoch 189, latest loss 6.741603343088784e-05\n",
      "Finished epoch 190, latest loss 6.73522883701652e-05\n",
      "Finished epoch 191, latest loss 6.729709176485398e-05\n",
      "Finished epoch 192, latest loss 6.726424798166232e-05\n",
      "Finished epoch 193, latest loss 6.722963037311126e-05\n",
      "Finished epoch 194, latest loss 6.721044373389125e-05\n",
      "Finished epoch 195, latest loss 6.720372811214252e-05\n",
      "Finished epoch 196, latest loss 6.719973283277963e-05\n",
      "Finished epoch 197, latest loss 6.719531197838091e-05\n",
      "Finished epoch 198, latest loss 6.718619370541453e-05\n",
      "Finished epoch 199, latest loss 6.719319781220155e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch = X[i:i+num_batches]\n",
    "        # print(X_batch)\n",
    "        y_pred = model(torch.Tensor(X_batch))\n",
    "        Y_batch = Y[i:i+num_batches]\n",
    "        loss = loss_function(y_pred, torch.Tensor(Y_batch))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Finished epoch {epoch}, latest loss {total_loss / len(data)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:03.441772Z",
     "start_time": "2023-10-03T18:37:01.498972Z"
    }
   },
   "id": "662530c2c251ea82"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "def euclidean_algorithm(pair): \n",
    "    a = pair[0]\n",
    "    b = pair[1]\n",
    "    plt.plot(a.detach(), b.detach(), \"ro\", markersize = 3)\n",
    "    index = 1\n",
    "    old_matrix = np.array([[1, 1], [1, 1]])\n",
    "\n",
    "    \n",
    "    while index < 100: \n",
    "        \n",
    "        index += 1\n",
    "        if a==0 or b==0: \n",
    "            return\n",
    "        pred = float(torch.argmax(model(torch.tensor([[a,b]]))))\n",
    "        print(index , \",\",  pred)\n",
    "        if pred == 0: # if first index has biggest value \n",
    "            if not np.array_equal(old_matrix , matrix_b):\n",
    "                pair = pair @ matrix_a\n",
    "                old_matrix = matrix_a\n",
    "        if pred == 1: # if second index has biggest value\n",
    "            if not np.array_equal(old_matrix , matrix_a):\n",
    "                pair = pair @ matrix_b\n",
    "                old_matrix = matrix_b\n",
    "        if pred == 2: # if third index has biggest value\n",
    "            if not np.array_equal(old_matrix , matrix_d):\n",
    "                pair = pair @ matrix_c\n",
    "                old_matrix = matrix_c\n",
    "        if pred == 3: # if fourth index has biggest value\n",
    "            if not np.array_equal(old_matrix ,matrix_c):\n",
    "                pair = pair @ matrix_d\n",
    "                old_matrix = matrix_d\n",
    "\n",
    "        print(pair)\n",
    "        a = float(pair[0])\n",
    "        b = float(pair[1])\n",
    "        plt.plot(a, b, \"ro\", markersize = 3+index) #from cs544 notes "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:38:41.527190Z",
     "start_time": "2023-10-03T18:38:41.504163Z"
    }
   },
   "id": "eb06504b5439d46d"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 , 3.0\n",
      "tensor([15., 20.], dtype=torch.float64)\n",
      "3 , 1.0\n",
      "tensor([15.,  5.], dtype=torch.float64)\n",
      "4 , 1.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "5 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "6 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "7 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "8 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "9 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "10 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "11 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "12 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "13 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "14 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "15 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "16 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "17 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "18 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "19 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "20 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "21 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "22 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "23 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "24 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "25 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "26 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "27 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "28 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "29 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "30 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "31 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "32 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "33 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "34 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "35 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "36 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "37 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "38 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "39 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "40 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "41 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "42 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "43 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "44 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "45 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "46 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "47 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "48 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "49 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "50 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "51 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "52 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "53 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "54 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "55 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "56 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "57 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "58 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "59 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "60 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "61 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "62 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "63 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "64 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "65 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "66 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "67 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "68 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "69 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "70 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "71 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "72 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "73 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "74 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "75 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "76 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "77 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "78 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "79 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "80 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "81 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "82 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "83 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "84 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "85 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "86 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "87 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "88 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "89 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "90 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "91 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "92 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "93 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "94 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "95 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "96 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "97 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "98 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "99 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "100 , 0.0\n",
      "tensor([ 15., -10.], dtype=torch.float64)\n",
      "None\n",
      "tensor([0., 0., 0., 1.], grad_fn=<SigmoidBackward0>)\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair = torch.tensor([-5,20], dtype=torch.float32)\n",
    "print(euclidean_algorithm(pair))\n",
    "print(model(pair))\n",
    "print(float(torch.argmax(model(pair))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:38:42.255979Z",
     "start_time": "2023-10-03T18:38:41.940612Z"
    }
   },
   "id": "ac95a1a036d81543"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:03.713110Z",
     "start_time": "2023-10-03T18:37:03.710089Z"
    }
   },
   "id": "8606823b77f02140"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T18:37:03.719049Z",
     "start_time": "2023-10-03T18:37:03.714177Z"
    }
   },
   "id": "242f1091467b67ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
