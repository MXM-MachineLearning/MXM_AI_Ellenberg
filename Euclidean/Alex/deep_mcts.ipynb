{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:28:23.047407Z",
     "start_time": "2024-02-28T00:28:03.339254Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nogil=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: RUN https://github.com/colesbury/nogil FOR MULTITHREADED (performance not necessarily better)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "import threading\n",
    "import concurrent\n",
    "\n",
    "import math\n",
    "\n",
    "from util import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import sys\n",
    "print(f\"nogil={getattr(sys.flags, 'nogil', False)}\")\n",
    "\n",
    "\"\"\"\n",
    "NOTE: RUN https://github.com/colesbury/nogil FOR MULTITHREADED (performance not necessarily better)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3ddf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:38.334723Z",
     "start_time": "2024-02-28T00:29:38.325718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memory for better batching\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, width) -> None:\n",
    "        self.mem_ = None\n",
    "        self.len_ = 0\n",
    "    def record(self, obs):\n",
    "        if self.len_ == 0:\n",
    "            self.mem_ = obs\n",
    "        else:\n",
    "            self.mem_ = torch.cat((self.mem_, obs), dim=0)\n",
    "        self.len_ += 1\n",
    "    def recall(self, n_samples):\n",
    "        if self.len_ == 0:\n",
    "            return None\n",
    "        des_len = min(n_samples, self.len_)\n",
    "        indices = torch.ones(self.mem_.shape[0]).multinomial(des_len, replacement=False)\n",
    "        return self.mem_[indices]\n",
    "    def size(self):\n",
    "        return self.len_\n",
    "    def clear(self):\n",
    "        self.len_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float).unsqueeze(0)).flatten().to(device)\n",
    "            action_plot[torch.argmax(rv)].append((i.cpu(),j.cpu()))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        if len(action) == 0:\n",
    "            continue\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()\n",
    "\n",
    "def test(x, y, policy_fn, actions=k_2actions, dbs=None):\n",
    "    correct = 0\n",
    "    guess_dist = [0] * len(actions)\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0).to(device)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(data_name, actions, policy_fn, cases=100, dbs=None):\n",
    "    test_X, test_Y = get_test_data(data_name)\n",
    "    test_X = test_X.to(device)\n",
    "    test_Y.reshape(-1, 1)\n",
    "    test_Y = test_Y.to(device)\n",
    "\n",
    "    acc, guesses = test(x=test_X[:cases], y=test_Y[:cases],\n",
    "                        policy_fn=policy_fn, actions=actions, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n",
    "    return acc, guesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "dual_file = \"test_data/test_simple.csv\"\n",
    "\n",
    "db2 = torch.linspace(2, k_dbound_size, k_dbound_size - 1).to(device)\n",
    "two_dbs = [db2, db2]\n",
    "\n",
    "def alt_policy(state, value_fn):\n",
    "    x = [i(state) for i in k_2actions]\n",
    "    x = [value_fn(i) for i in x]\n",
    "    x = torch.tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19bdb93248565c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:39.699250Z",
     "start_time": "2024-02-28T00:29:39.688411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_C = 1 / math.sqrt(2)\n",
    "# k_C = 0.1\n",
    "k_thread_count_limit = 20\n",
    "k_core_limit = 5\n",
    "\n",
    "# def get_train_data(fname):\n",
    "#     x = np.loadtxt(fname, delimiter=\",\")\n",
    "#     return torch.tensor([x[:,2], x[:,2:]], dtype=torch.float)\n",
    "\n",
    "# def get_nonterm_rwd(mcts):\n",
    "#     return -mcts.max_depth\n",
    "\n",
    "# def get_terminal_rwd(terminal_depth, start):\n",
    "#     return -terminal_depth + torch.linalg.norm(start)\n",
    "\n",
    "def train_sv(epochs, actions, policy_fn, value_fn, optimizers, fname, batch_size=10):\n",
    "    k_mem_width = 4    # statex,statey,action,subtree_value\n",
    "    memory = Memory(k_mem_width)\n",
    "    loss_fn = Loss()\n",
    "    # load data into memory\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            entry = torch.tensor(list(map(int, line.split(','))))\n",
    "            tree = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "            g_nodes = tree.generate(entry[0:2].unsqueeze(0).float(), entry[2:])\n",
    "            for i in range(len(entry) - 2): # go by actions (so we disregard the terminal node)\n",
    "                memory.record(torch.cat((g_nodes[i].state.reshape(1,2), \n",
    "                                         entry[2+i].reshape((1,1)), \n",
    "                                         g_nodes[i].subtree_value.reshape(1,1)), dim=1))\n",
    "    # train off memory\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        batch = memory.recall(batch_size)\n",
    "        v_out = value_fn(batch[:,:2])\n",
    "        p_out = policy_fn(batch[:,:2])\n",
    "\n",
    "        # one-hot encode actions; e.g. convert 3 -> (0,0,0,1)\n",
    "        action_indices = batch[:,2:-1].to(torch.int64)\n",
    "        p_target = oh_encode(action_indices, len(actions))\n",
    "        # p_target = torch.zeros(action_indices.shape[0],len(actions))\n",
    "        # p_target.scatter_(1, action_indices,1)\n",
    "\n",
    "        v_target = batch[:,-1]\n",
    "\n",
    "        loss = loss_fn(v_out.view(v_target.shape), v_target, p_out.view(p_target.shape), p_target)\n",
    "        loss.backward()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "    \n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "\n",
    "\n",
    "def train_play(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size=16):\n",
    "    history = Memory(3+4)    # [stateX,stateY,value] (probs are sampled probs)\n",
    "    loss_fn = Loss()\n",
    "    tot_loss = 0\n",
    "    for t in range(epochs):\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        # Repeat the following:\n",
    "        # 1) run the NN on some random initial state\n",
    "        # 2) update the NN based off performance in that game\n",
    "            \n",
    "        # play out some games\n",
    "        k_comp_limit = comp_limit(t / epochs)\n",
    "\n",
    "        # NOTE: ProcessPoolExecutor requires placing called functions/data structs in separate imported file\n",
    "        payload = [(rand_start_state_fn(), actions, value_fn, k_comp_limit, k_C, k_thread_count_limit) for i in range(batch_size)]\n",
    "\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=k_core_limit) as executor:\n",
    "            for rv in zip(executor.map(one_batch, iter(payload))):\n",
    "                history.record(rv[0])\n",
    "        # for p in payload:\n",
    "        #     history.record(one_batch(p))\n",
    "\n",
    "        # train NN on games just played\n",
    "        batch = history.recall(batch_size)\n",
    "        batch_states = batch[:,:2]\n",
    "        batch_vsampled = batch[:,2]\n",
    "\n",
    "        loss = loss_fn(value_fn(batch_states).view(batch_vsampled.shape), batch_vsampled)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item() / batch_size\n",
    "\n",
    "        history.clear()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "\n",
    "\n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",tot_loss/10)\n",
    "            tot_loss = 0\n",
    "            run_test(dual_file, k_2actions, policy_fn=lambda a: alt_policy(a, value_fn), cases=k_cases, dbs=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e004f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:40.566311Z",
     "start_time": "2024-02-28T00:29:40.556759Z"
    }
   },
   "outputs": [],
   "source": [
    "k_state_upper_lim = 10 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (2))\n",
    "k_min_comps = int(k_state_upper_lim ** (1.5))\n",
    "\n",
    "value_fn_2 = ValueNN(2).to(device)\n",
    "value_optim = optim.SGD(value_fn_2.parameters(), lr=0.00005, momentum=0.9)\n",
    "\n",
    "def gen_start_state_2a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((1, 2)) * limit + 1).float()\n",
    "\n",
    "def adaptive_comp_limit(frac_epochs):\n",
    "    # linearly decrease computation limit as model becomes better over time\n",
    "    rv = k_comp_limit - (k_comp_limit - k_min_comps) * frac_epochs\n",
    "    return int(rv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41211b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T02:48:18.942268Z",
     "start_time": "2024-02-28T02:48:12.374093Z"
    }
   },
   "outputs": [],
   "source": [
    "train_play(epochs=150, actions=k_2actions, policy_fn=None, value_fn=value_fn_2, \n",
    "           optimizers=[value_optim], rand_start_state_fn=gen_start_state_2a, \n",
    "           comp_limit=adaptive_comp_limit, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    torch.save(value_fn_2.state_dict(), \"trained_weights/deep_mcts_2_v_weights.pth\")\n",
    "    # torch.save(policy_fn_2.state_dict(), \"trained_weights/deep_mcts_2_p_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (7/2))\n",
    "value_fn_4 = ValueNN(2).to(device)\n",
    "policy_fn_4 = PolicyNN(2,len(k_4actions)).to(device)\n",
    "value_optim_4 = optim.Adam(value_fn_4.parameters(), lr=0.00005)\n",
    "policy_optim_4 = optim.Adam(policy_fn_4.parameters(), lr=0.000005)\n",
    "\n",
    "def gen_start_state_4a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round( (torch.rand((1, 2)) - 0.5) * 2 * limit).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 2.1033401489257812\n",
      "Epoch: 20 \t\tLoss: 1.556889295578003\n",
      "Epoch: 30 \t\tLoss: 1.3582837581634521\n",
      "Epoch: 40 \t\tLoss: 1.4088467359542847\n",
      "Epoch: 50 \t\tLoss: 1.436020016670227\n",
      "Epoch: 60 \t\tLoss: 1.379128336906433\n",
      "Epoch: 70 \t\tLoss: 1.4841262102127075\n",
      "Epoch: 80 \t\tLoss: 1.3614771366119385\n",
      "Epoch: 90 \t\tLoss: 1.3785827159881592\n",
      "Epoch: 100 \t\tLoss: 1.3600499629974365\n",
      "Epoch: 110 \t\tLoss: 1.389901041984558\n",
      "Epoch: 120 \t\tLoss: 1.383531928062439\n",
      "Epoch: 130 \t\tLoss: 1.3663393259048462\n",
      "Epoch: 140 \t\tLoss: 1.3774583339691162\n",
      "Epoch: 150 \t\tLoss: 1.2760998010635376\n",
      "Epoch: 160 \t\tLoss: 1.3536250591278076\n",
      "Epoch: 170 \t\tLoss: 1.3584808111190796\n",
      "Epoch: 180 \t\tLoss: 1.3749842643737793\n",
      "Epoch: 190 \t\tLoss: 1.3323438167572021\n",
      "Epoch: 200 \t\tLoss: 1.3520457744598389\n",
      "Epoch: 210 \t\tLoss: 1.310624599456787\n",
      "Epoch: 220 \t\tLoss: 1.3285794258117676\n",
      "Epoch: 230 \t\tLoss: 1.3432512283325195\n",
      "Epoch: 240 \t\tLoss: 1.3051739931106567\n",
      "Epoch: 250 \t\tLoss: 1.3170291185379028\n"
     ]
    }
   ],
   "source": [
    "train_sv(250, k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4,policy_optim_4], fname='train_data/train_mcts.csv', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e933c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_policy_fp = \"start_weights/deep_mcts_4_p_weights.pth\"\n",
    "init_value_fp = \"start_weights/deep_mcts_4_v_weights.pth\"\n",
    "trained_policy_fp = \"trained_weights/deep_mcts_4_p_weights_f.pth\"\n",
    "trained_value_fp = \"trained_weights/deep_mcts_4_v_weights_f.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    torch.save(value_fn_4.state_dict(), init_value_fp)\n",
    "    torch.save(policy_fn_4.state_dict(), init_policy_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_play(epochs=100, actions=k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4, policy_optim_4], rand_start_state_fn=gen_start_state_4a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained weights\n",
    "\n",
    "\n",
    "# value_fn_4.load_state_dict(torch.load(trained_value_fp))\n",
    "# policy_fn_4.load_state_dict(torch.load(trained_policy_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de80856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test rollout (not good metric at the moment)\n",
    "def rollout(start, actions, value_fn, comp_limit, k_C, k_thread_count_limit, nogil):\n",
    "    mcts = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "\n",
    "    value = mcts.value_fn(start).flatten().to(device)\n",
    "\n",
    "    start_node = Node(None, start, len(actions), value, 0)\n",
    "\n",
    "    mcts.run(start_node, comp_limit=comp_limit, max_threads=k_thread_count_limit, nogil=nogil)\n",
    "    # choose best action\n",
    "    best = 0\n",
    "    for i in range(len(start_node.children)):\n",
    "        if start_node.children[i] is None:\n",
    "            continue\n",
    "        if start_node.children[i].subtree_value > start_node.children[best].subtree_value:\n",
    "            best = i\n",
    "    return torch.tensor(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(dual_file, k_2actions, policy_fn=lambda a: alt_policy(a, value_fn_2), cases=k_cases, dbs=two_dbs)\n",
    "# ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7c4b36c7d9707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.261\n",
      "Guess Distribution: [1000, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_8108/450618715.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "quad_file = \"test_data/four_directions_cleaner_test.csv\"     # thanks, donald\n",
    "\n",
    "k_cases = 1000\n",
    "\n",
    "k_dbound_size = 200\n",
    "\n",
    "db4 = torch.linspace(-k_dbound_size/2, k_dbound_size/2, k_dbound_size+1).to(device)\n",
    "quad_dbs = [db4, db4]\n",
    "run_test(quad_file, k_4actions, policy_fn=lambda a: torch.argmax(value_fn_4(a)), cases=k_cases)\n",
    "            \n",
    "# run_test(quad_file, k_4actions, policy_fn=lambda a: oh_encode(torch.tensor(determine_action(a.flatten())).view((1,1)),4), cases=k_cases, dbs=quad_dbs)\n",
    "# # 8% accuracy on Donald test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,200, 10):\n",
    "    epoch = i + 1\n",
    "    value_fn_4.load_state_dict(torch.load(trained_value_fp + \"_\" + str(epoch)))\n",
    "    acc, guesses = run_test(quad_file, k_4actions, policy_fn=lambda a: alt_policy(a, value_fn_4), cases=k_cases, dbs=quad_dbs)\n",
    "    print(\"Epoch {epoch} accuracy: \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c81ea1aa8fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
