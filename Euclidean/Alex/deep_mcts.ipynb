{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:45:00.232700Z",
     "start_time": "2023-11-06T02:45:00.218140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "\n",
    "import math\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d12017b9641b3200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:45:00.243783Z",
     "start_time": "2023-11-06T02:45:00.230649Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def terminal(state, k_eps=1e-4):\n",
    "    for i in state.flatten():\n",
    "        if abs(i) <= k_eps:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, parent, state, n_children, value, depth=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.visits = 0\n",
    "        self.depth = depth\n",
    "        self.children = [None] * n_children\n",
    "        self.is_terminal = terminal(self.state)\n",
    "        self.value = value\n",
    "        self.subtree_value = torch.zeros(1)\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"State: \" + str(self.state) + \"; Value: \" + str(self.value)\n",
    "                + \"; Subtree Value: \" + str(self.subtree_value) + \"; Visits:\", str(self.visits))\n",
    "\n",
    "    def is_leaf(self):\n",
    "        for i in self.state:\n",
    "            if i is not None:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8031c754a4dbbeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:56.728064Z",
     "start_time": "2023-11-06T02:48:56.722471Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, actions, C, weight, value_fn):\n",
    "        self.actions = actions\n",
    "        self.k_C = C\n",
    "        self.k_weight = weight\n",
    "        self.value_fn = value_fn\n",
    "        self.max_depth = 0\n",
    "        self.terminal = None    # None if no terminal state found; terminal Node if found\n",
    "        self.root = None\n",
    "\n",
    "    def pick_child(self, node):\n",
    "        # UCT\n",
    "        t = []\n",
    "        for i in node.children:\n",
    "            if i is None:\n",
    "                continue\n",
    "            t.append(UCT_fn(i, self.k_C))\n",
    "\n",
    "        t = torch.tensor(t)\n",
    "\n",
    "        rvs = torch.squeeze(torch.argwhere(t == torch.max(t)), axis=1)\n",
    "        if len(rvs) == 0:\n",
    "            return random.randint(0, len(node.children)-1)\n",
    "        return int(random.choice(rvs))\n",
    "\n",
    "    def default_search(self, node):\n",
    "        \"\"\"\n",
    "        If node is fully explored (neither child is None), return True\n",
    "        Otherwise, initialize value of a random unexplored next state\n",
    "\n",
    "        :param node: node to search from\n",
    "        :return: if fully explored, True. Else, value of the random unexplored next state\n",
    "        \"\"\"\n",
    "        possible = []\n",
    "        for i in range(len(node.children)):\n",
    "            if node.children[i] is None:\n",
    "                possible.append(i)\n",
    "        if len(possible) == 0:\n",
    "            return True\n",
    "\n",
    "        i = random.choice(possible)\n",
    "        # if unexplored or non-terminal, get value\n",
    "        state = torch.tensor(self.actions[i](node.state.flatten()), dtype=torch.float)\n",
    "        state = state.reshape(node.state.shape)\n",
    "        # child_val = self.value_fn(state) - node.depth - 1  # give penalty -1 for each additional step taken\n",
    "        child_val = self.value_fn(state)\n",
    "        child_val = child_val.flatten()[0]\n",
    "        node.children[i] = Node(node, state, len(self.actions), value=child_val, depth=node.depth+1)\n",
    "\n",
    "        # if new Node is terminal, take it as the tree's terminal if it takes less time to reach than current terminal\n",
    "        # if node.children[i].is_terminal:\n",
    "        #     # if terminal, add reward of ||start_vec||_2^2\n",
    "        #     node.children[i].value += torch.linalg.vector_norm(torch.square(self.root.state)).item()\n",
    "        #     if self.terminal is None or node.children[i].depth < self.terminal.depth:\n",
    "        #         self.terminal = node.children[i]\n",
    "\n",
    "        if node.children[i].depth > self.max_depth:\n",
    "            self.max_depth = node.children[i].depth\n",
    "        return node.children[i]\n",
    "\n",
    "    def tree_policy(self, node, computations):\n",
    "        while node.is_terminal is False:\n",
    "            explored = self.default_search(node)\n",
    "            if explored is not True:\n",
    "                return explored, computations + 1\n",
    "            node = node.children[self.pick_child(node)]\n",
    "            # node = random.choice(node.children)\n",
    "        return node, computations + 1\n",
    "\n",
    "    def mean_prop(self, node):\n",
    "        \"\"\"\n",
    "        Backprop up from a leaf, where subtree_value is the average of a node's rewards and its subtree's rewards\n",
    "\n",
    "        :param node: of subtree\n",
    "        \"\"\"\n",
    "        node.subtree_value = torch.zeros(1)\n",
    "        node.subtree_value += node.value\n",
    "        valid_children = 0\n",
    "        if not node.is_leaf():\n",
    "            for i in node.children:\n",
    "                if i is None:\n",
    "                    continue\n",
    "                node.subtree_value += self.k_weight * i.subtree_value\n",
    "                valid_children += 1\n",
    "        node.subtree_value /= valid_children + 1\n",
    "        node.visits += 1\n",
    "        if node.parent is None:\n",
    "            return\n",
    "        self.mean_prop(node.parent)\n",
    "\n",
    "    def run(self, root, comp_limit=10):\n",
    "        \"\"\"\n",
    "        Shoutout \"A Survey of MCTS Methods\"\n",
    "        :param root: the current state\n",
    "        :param comp_limit: max number of possible future scenarios to compute (carries over)\n",
    "        :return: index corresponding to best action\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        if self.root.is_terminal:\n",
    "            return True\n",
    "        comps = 0\n",
    "        while comps < comp_limit:\n",
    "            node, comps = self.tree_policy(self.root, comps)\n",
    "            self.mean_prop(node)\n",
    "\n",
    "        rv = self.pick_child(self.root)\n",
    "        \n",
    "        if False:\n",
    "            print(\"root state:\", root.state)\n",
    "            print(\"child states: \",end=\"\")\n",
    "            for child in root.children:\n",
    "                print(child.state, end=\",\")\n",
    "            print()\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "438fdf1c04168299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.v_loss_fn = torch.nn.MSELoss()\n",
    "        self.p_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, v_out, v_target, p_out, p_target):\n",
    "        \"\"\"\n",
    "        Loss function designed to reward successful game completion while taking the least amount of steps possible\n",
    "        Adapted from:\n",
    "            - \"Mastering the game of Go without human knowledge\" (Silver et al)\n",
    "            - \"Discovering faster matrix multiplication algorithms with reinforcement learning\" (Fawzi et al)\n",
    "\n",
    "        :param v_out: the value outputed for the state by NN\n",
    "        :param p_out: the policy outputed for the state by NN\n",
    "        :param v_target: target value output\n",
    "        :return: total loss\n",
    "        \"\"\"\n",
    "        loss = self.v_loss_fn(v_out, v_target)\n",
    "        loss += self.p_loss_fn(p_out, p_target)\n",
    "        return loss\n",
    "\n",
    "\n",
    "        \n",
    "class ValueNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        self.value_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.stack(x).flatten()\n",
    "        # value = self.value_activation(x[0:1]).unsqueeze(0)\n",
    "        value = x[0:1].reshape((1,1))\n",
    "        return value\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, n_actions),\n",
    "        )\n",
    "        self.policy_activation = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.policy_activation(self.stack(x).flatten())\n",
    "        # value = self.value_activation(x[0:1]).unsqueeze(0)\n",
    "        policy = torch.clamp(x.unsqueeze(0),min=1e-8,max=1-(1e-8))\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f19bdb93248565c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "k_C = 1 / math.sqrt(2)\n",
    "\n",
    "loss_fn = Loss()\n",
    "\n",
    "def train(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit):\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        # Repeat the following:\n",
    "        # 1) run the NN on some random initial state\n",
    "        # 2) update the NN based off performance in that game\n",
    "        mcts = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "        start = rand_start_state_fn()\n",
    "\n",
    "        value = mcts.value_fn(start).flatten()\n",
    "        policy = policy_fn(start).flatten()\n",
    "\n",
    "        start_node = Node(None, start, len(actions), value, 0)\n",
    "\n",
    "        # play out a game\n",
    "        mcts.run(start_node, comp_limit=comp_limit)\n",
    "\n",
    "        # get attributes of game just played\n",
    "        v_out = start_node.subtree_value\n",
    "        v_target = -mcts.max_depth\n",
    "        if mcts.terminal is not None:\n",
    "            v_target = -mcts.terminal.depth + torch.linalg.norm(start)\n",
    "\n",
    "        visits = []\n",
    "        for i in start_node.children:\n",
    "            if i is None:\n",
    "                visits.append(0)\n",
    "            else:\n",
    "                visits.append(i.visits)\n",
    "        visits = torch.tensor(visits, dtype=torch.float)\n",
    "        p_sampled = visits / torch.sum(visits)\n",
    "        \n",
    "        loss = loss_fn(v_out, torch.tensor(v_target,dtype=v_out.dtype), policy.flatten(), p_sampled.flatten())\n",
    "        loss.backward()\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "\n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 65.8193130493164\n",
      "Epoch: 20 \t\tLoss: 42.127017974853516\n",
      "Epoch: 30 \t\tLoss: 59.532718658447266\n",
      "Epoch: 40 \t\tLoss: 48.38131332397461\n",
      "Epoch: 50 \t\tLoss: 29.40606689453125\n",
      "Epoch: 60 \t\tLoss: 44.74832534790039\n",
      "Epoch: 70 \t\tLoss: 24.35161590576172\n",
      "Epoch: 80 \t\tLoss: 25.03790855407715\n",
      "Epoch: 90 \t\tLoss: 3.6419973373413086\n",
      "Epoch: 100 \t\tLoss: 5.68751859664917\n"
     ]
    }
   ],
   "source": [
    "k_comp_limit = int(k_state_upper_lim ** (3/2))\n",
    "k_2actions = (a_subtract, a_swap)\n",
    "value_fn_2 = ValueNN()\n",
    "policy_fn_2 = PolicyNN(len(k_actions))\n",
    "value_optim = optim.Adam(value_fn_2.parameters(), lr=0.0001)\n",
    "policy_optim = optim.Adam(policy_fn_2.parameters(), lr=0.0001)\n",
    "k_state_upper_lim = 30 # arbitrary\n",
    "\n",
    "def gen_start_state_2a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((1, 2)) * limit + 1).float()\n",
    "\n",
    "train(epochs=100, actions=k_2actions, policy_fn=policy_fn_2, value_fn=value_fn_2, optimizers=[value_optim, policy_optim], rand_start_state_fn=gen_start_state_2a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(value_fn.state_dict(), \"deep_mcts_v_weights.pth\")\n",
    "    torch.save(policy_fn.state_dict(), \"deep_mcts_p_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c191e6c845a0bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:47:31.912513Z",
     "start_time": "2023-11-06T02:47:31.904073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, comp_limit, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float).reshape(1,len(actions)))\n",
    "            action_plot[torch.argmax(rv)].append((i,j))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x, y, C, policy_fn, weight=1., comp_limit=10, actions=(a_subtract, a_swap), zero_index=False, dbs=None):\n",
    "    correct = 0\n",
    "    mcts = MCTS(actions, C, weight, value_fn)\n",
    "    guess_dist = [0] * len(actions)\n",
    "    if zero_index:\n",
    "        y = y - np.ones(len(y))\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, comp_limit, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(data_name, actions, C, policy_fn, cases=100, lookahead=100, weight=1., zero_index=False, dbs=None):\n",
    "    test_X, test_Y = get_data(data_name)\n",
    "    test_Y.reshape(-1, 1)\n",
    "\n",
    "    acc, guesses = test(test_X[:cases], test_Y[:cases],\n",
    "                        C, policy_fn, weight, comp_limit=lookahead, actions=actions, zero_index=zero_index, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_2763/1594351740.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9905\n",
      "Guess Distribution: [1039, 961]\n"
     ]
    }
   ],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "dual_file = \"test_data/test_simple.csv\"\n",
    "\n",
    "db2 = np.linspace(2, k_dbound_size, k_dbound_size - 1)\n",
    "two_dbs =[db2, db2]\n",
    "\n",
    "run_test(dual_file, [a_subtract, a_swap], C=k_C, policy_fn=policy_fn, cases=k_cases, lookahead=10, dbs=two_dbs)\n",
    "# ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7c4b36c7d9707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quad_file = \"../Donald/four_step_euclidean/four_directions_cleaner_test.csv\"     # thanks, donald\n",
    "\n",
    "# k_C = 1 / math.sqrt(2)  # satisfies Hoeffding Ineq (Kocsis and Szepesvari)\n",
    "# k_cases = 10\n",
    "\n",
    "# k_dbound_size = 100\n",
    "\n",
    "# db4 = np.linspace(-k_dbound_size/2, k_dbound_size/2, k_dbound_size+1)\n",
    "# quad_dbs = [db4, db4]\n",
    "# run_test(quad_file, [a_plsy, a_suby, a_plsx, a_subx], k_C, k_cases, lookahead=100, zero_index=False)\n",
    "# # 8% accuracy on Donald test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6aeaf873defc84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T02:45:00.363403Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
