{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:45:00.232700Z",
     "start_time": "2023-11-06T02:45:00.218140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "\n",
    "import math\n",
    "\n",
    "from util import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d75afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, n_children, value, depth=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.visits = 0\n",
    "        self.depth = depth\n",
    "        self.children = [None] * n_children\n",
    "        self.is_terminal = terminal(self.state)\n",
    "        self.value = value\n",
    "        self.subtree_value = torch.zeros(1).to(device)\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"State: \" + str(self.state) + \"; Value: \" + str(self.value)\n",
    "                + \"; Subtree Value: \" + str(self.subtree_value) + \"; Visits:\", str(self.visits))\n",
    "\n",
    "    def is_leaf(self):\n",
    "        for i in self.state:\n",
    "            if i is not None:\n",
    "                return False\n",
    "        return True\n",
    "class MCTS:\n",
    "    def __init__(self, actions, C, weight, value_fn):\n",
    "        self.actions = actions\n",
    "        self.k_C = C\n",
    "        self.k_weight = weight\n",
    "        self.value_fn = value_fn\n",
    "        self.max_depth = 0\n",
    "        self.terminal = None    # None if no terminal state found; terminal Node if found\n",
    "        self.root = None\n",
    "\n",
    "    def pick_child(self, node):\n",
    "        # UCT\n",
    "        t = []\n",
    "        for i in node.children:\n",
    "            if i is None:\n",
    "                continue\n",
    "            t.append(UCT_fn(i, self.k_C))\n",
    "\n",
    "        t = torch.tensor(t)\n",
    "\n",
    "        rvs = torch.squeeze(torch.argwhere(t == torch.max(t)), axis=1)\n",
    "        if len(rvs) == 0:\n",
    "            return random.randint(0, len(node.children)-1)\n",
    "        return int(random.choice(rvs))\n",
    "\n",
    "    def default_search(self, node):\n",
    "        \"\"\"\n",
    "        If node is fully explored (neither child is None), return True\n",
    "        Otherwise, initialize value of a random unexplored next state\n",
    "\n",
    "        :param node: node to search from\n",
    "        :return: if fully explored, True. Else, value of the random unexplored next state\n",
    "        \"\"\"\n",
    "        possible = []\n",
    "        for i in range(len(node.children)):\n",
    "            if node.children[i] is None:\n",
    "                possible.append(i)\n",
    "        if len(possible) == 0:\n",
    "            return True\n",
    "\n",
    "        i = random.choice(possible)\n",
    "        # if unexplored or non-terminal, get value\n",
    "        state = self.actions[i](node.state.flatten()).float().to(device)\n",
    "        state = state.reshape(node.state.shape)\n",
    "        # child_val = self.value_fn(state) - node.depth - 1  # give penalty -1 for each additional step taken\n",
    "        child_val = self.value_fn(state)\n",
    "        child_val = child_val.flatten()[0]\n",
    "        node.children[i] = Node(node, state, len(self.actions), value=child_val, depth=node.depth+1)\n",
    "\n",
    "        # if new Node is terminal, take it as the tree's terminal if it takes less time to reach than current terminal\n",
    "        # if node.children[i].is_terminal:\n",
    "        #     # if terminal, add reward of ||start_vec||_2^2\n",
    "        #     node.children[i].value += torch.linalg.vector_norm(torch.square(self.root.state)).item()\n",
    "        #     if self.terminal is None or node.children[i].depth < self.terminal.depth:\n",
    "        #         self.terminal = node.children[i]\n",
    "\n",
    "        if node.children[i].depth > self.max_depth:\n",
    "            self.max_depth = node.children[i].depth\n",
    "        return node.children[i]\n",
    "\n",
    "    def tree_policy(self, node, computations):\n",
    "        while node.is_terminal is False:\n",
    "            explored = self.default_search(node)\n",
    "            if explored is not True:\n",
    "                return explored, computations + 1\n",
    "            node = node.children[self.pick_child(node)]\n",
    "            # node = random.choice(node.children)\n",
    "        return node, computations + 1\n",
    "\n",
    "    def mean_prop(self, node):\n",
    "        \"\"\"\n",
    "        Backprop up from a leaf, where subtree_value is the average of a node's rewards and its subtree's rewards\n",
    "\n",
    "        :param node: of subtree\n",
    "        \"\"\"\n",
    "        node.subtree_value = torch.zeros(1).to(device)\n",
    "        node.subtree_value += node.value\n",
    "        valid_children = 0\n",
    "        if not node.is_leaf():\n",
    "            for i in node.children:\n",
    "                if i is None:\n",
    "                    continue\n",
    "                node.subtree_value += self.k_weight * i.subtree_value\n",
    "                valid_children += 1\n",
    "        node.subtree_value /= valid_children + 1\n",
    "        node.visits += 1\n",
    "        if node.parent is None:\n",
    "            return\n",
    "        self.mean_prop(node.parent)\n",
    "\n",
    "    def run(self, root, comp_limit=10):\n",
    "        \"\"\"\n",
    "        Shoutout \"A Survey of MCTS Methods\"\n",
    "        :param root: the current state\n",
    "        :param comp_limit: max number of possible future scenarios to compute (carries over)\n",
    "        :return: index corresponding to best action\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        if self.root.is_terminal:\n",
    "            return True\n",
    "        comps = 0\n",
    "        while comps < comp_limit:\n",
    "            node, comps = self.tree_policy(self.root, comps)\n",
    "            self.mean_prop(node)\n",
    "\n",
    "        rv = self.pick_child(self.root)\n",
    "\n",
    "        if False:\n",
    "            print(\"root state:\", root.state)\n",
    "            print(\"child states: \",end=\"\")\n",
    "            for child in root.children:\n",
    "                print(child.state, end=\",\")\n",
    "            print()\n",
    "        return rv\n",
    "    \n",
    "    def generate(self, init_state, actions):\n",
    "        self.root = Node(None, init_state, n_children=len(self.actions), value=self.value_fn(init_state), depth=0)\n",
    "        curr = self.root\n",
    "        r_nodes = []\n",
    "        for i in actions:\n",
    "            newstate = self.actions[i](curr.state)\n",
    "            n = Node(parent=curr,\n",
    "                     state=newstate,\n",
    "                     n_children=len(self.actions),\n",
    "                     value=self.value_fn(newstate),\n",
    "                     depth=curr.depth + 1)\n",
    "            curr.children[i] = n\n",
    "            curr = n            \n",
    "            r_nodes.append(n)\n",
    "        return r_nodes\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438fdf1c04168299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.v_loss_fn = torch.nn.MSELoss()\n",
    "        self.p_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, v_out, v_target, p_out, p_target):\n",
    "        \"\"\"\n",
    "        Loss function designed to reward successful game completion while taking the least amount of steps possible\n",
    "        Adapted from:\n",
    "            - \"Mastering the game of Go without human knowledge\" (Silver et al)\n",
    "            - \"Discovering faster matrix multiplication algorithms with reinforcement learning\" (Fawzi et al)\n",
    "\n",
    "        :param v_out: the value outputed for the state by NN\n",
    "        :param p_out: the policy outputed for the state by NN\n",
    "        :param v_target: target value output\n",
    "        :return: total loss\n",
    "        \"\"\"\n",
    "        loss = self.v_loss_fn(v_out, v_target)\n",
    "        loss += self.p_loss_fn(p_out, p_target).sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ValueNN(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(ValueNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        self.value_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "#        x = self.flatten(x)\n",
    "#        x = self.stack(x).flatten()\n",
    "#        value = x[0:1].reshape((1,1))\n",
    "#        return value\n",
    "        return self.stack(x)\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    def __init__(self, state_size, n_actions):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, n_actions),\n",
    "        )\n",
    "        self.policy_activation = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.policy_activation(self.stack(x))#.flatten())\n",
    "        policy = torch.clamp(x,min=1e-8,max=1-(1e-8))\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e3ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory for better batching\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, width) -> None:\n",
    "        self.mem_ = torch.empty((0,width)).to(device)\n",
    "        self.len_ = 0\n",
    "    def record(self, obs):\n",
    "        self.mem_ = torch.cat((self.mem_, obs), dim=0)\n",
    "        self.len_ += 1\n",
    "    def recall(self, n_samples):\n",
    "        if self.len_ == 0:\n",
    "            return None\n",
    "        des_len = min(n_samples, self.len_)\n",
    "        indices = torch.ones(self.mem_.shape[0]).multinomial(des_len, replacement=False)\n",
    "        return self.mem_[indices]\n",
    "    def size(self):\n",
    "        return self.len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19bdb93248565c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "k_C = 1 / math.sqrt(2)\n",
    "\n",
    "def get_train_data(fname):\n",
    "    x = np.loadtxt(fname, delimiter=\",\")\n",
    "    return torch.tensor([x[:,2], x[:,2:]], dtype=torch.float)\n",
    "\n",
    "def get_nonterm_rwd(mcts):\n",
    "    return -mcts.max_depth\n",
    "\n",
    "def get_terminal_rwd(terminal_depth, start):\n",
    "    return -terminal_depth + torch.linalg.norm(start)\n",
    "\n",
    "def train_sv(epochs, actions, policy_fn, value_fn, optimizers, fname, batch_size=10):\n",
    "    k_mem_width = 4    # statex,statey,action,subtree_value\n",
    "    memory = Memory(k_mem_width)\n",
    "    loss_fn = Loss()\n",
    "    # load data into memory\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            entry = torch.tensor(list(map(int, line.split(','))))\n",
    "            tree = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "            g_nodes = tree.generate(entry[0:2].unsqueeze(0).float(), entry[2:])\n",
    "            for i in range(len(entry) - 2): # go by actions (so we disregard the terminal node)\n",
    "                memory.record(torch.cat((g_nodes[i].state.reshape(1,2), \n",
    "                                         entry[2+i].reshape((1,1)), \n",
    "                                         g_nodes[i].subtree_value.reshape(1,1)), dim=1))\n",
    "    # train off memory\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        batch = memory.recall(batch_size)\n",
    "        v_out = value_fn(batch[:,:2])\n",
    "        p_out = policy_fn(batch[:,:2])\n",
    "\n",
    "        # one-hot encode actions; e.g. convert 3 -> (0,0,0,1)\n",
    "        action_indices = batch[:,2:-1].to(torch.int64)\n",
    "        p_target = oh_encode(action_indices, len(actions))\n",
    "        # p_target = torch.zeros(action_indices.shape[0],len(actions))\n",
    "        # p_target.scatter_(1, action_indices,1)\n",
    "\n",
    "        v_target = batch[:,-1]\n",
    "\n",
    "        loss = loss_fn(v_out.view(v_target.shape), v_target, p_out.view(p_target.shape), p_target)\n",
    "        loss.backward()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "    \n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "\n",
    "\n",
    "def train_play(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size=16):\n",
    "    history = Memory(2+len(actions))    # [stateX,stateY,pr1,pr2,...pr(len(actions))] (probs are sampled probs)\n",
    "    loss_fn = Loss()\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        # Repeat the following:\n",
    "        # 1) run the NN on some random initial state\n",
    "        # 2) update the NN based off performance in that game\n",
    "        mcts = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "        start = rand_start_state_fn().to(device)\n",
    "\n",
    "        value = mcts.value_fn(start).flatten().to(device)\n",
    "        policy = policy_fn(start).flatten().to(device)\n",
    "\n",
    "        start_node = Node(None, start, len(actions), value, 0)\n",
    "\n",
    "        # play out a game\n",
    "        mcts.run(start_node, comp_limit=comp_limit)\n",
    "\n",
    "\n",
    "        # get attributes of game just played\n",
    "        v_out = start_node.subtree_value.to(device)\n",
    "        v_target = get_nonterm_rwd(mcts)\n",
    "        if mcts.terminal is not None:\n",
    "            v_target = get_terminal_rwd(mcts.terminal.depth, start)\n",
    "        v_target = torch.tensor(v_target,dtype=v_out.dtype).to(device)\n",
    "\n",
    "\n",
    "        visits = []\n",
    "        for i in start_node.children:\n",
    "            if i is None:\n",
    "                visits.append(0)\n",
    "            else:\n",
    "                visits.append(i.visits)\n",
    "        visits = torch.tensor(visits, dtype=torch.float).to(device)\n",
    "        p_sampled = visits / torch.sum(visits)\n",
    "\n",
    "        curr_batch_entry = torch.cat((start,p_sampled.flatten().unsqueeze(0)),dim=1)\n",
    "        hist = history.recall(batch_size)\n",
    "        batch = curr_batch_entry\n",
    "        if hist is not None:\n",
    "            batch = torch.cat((hist, batch),dim=0)\n",
    "        batch_states = batch[:,:2]\n",
    "        batch_psampled = batch[:,2:]\n",
    "\n",
    "        # v_loss = v_loss_fn(v_out, torch.tensor(v_target,dtype=v_out.dtype))\n",
    "        # p_loss = p_loss_fn(policy_fn(batch_states), batch_psampled)\n",
    "        loss = loss_fn(v_out, v_target,\n",
    "                       policy_fn(batch_states).reshape(batch_psampled.shape), batch_psampled)\n",
    "        loss.backward()\n",
    "        # v_loss.backward()\n",
    "        # p_loss.backward()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "\n",
    "        history.record(curr_batch_entry)\n",
    "\n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "            # if torch.isnan(p_loss):\n",
    "            #     print(\"value\",v_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e004f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (3/2))\n",
    "value_fn_2 = ValueNN(2).to(device)\n",
    "policy_fn_2 = PolicyNN(2,len(k_2actions)).to(device)\n",
    "value_optim = optim.Adam(value_fn_2.parameters(), lr=0.00005)\n",
    "policy_optim = optim.Adam(policy_fn_2.parameters(), lr=0.00005)\n",
    "\n",
    "def gen_start_state_2a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((1, 2)) * limit + 1).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41211b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 83.53762817382812\n",
      "Epoch: 20 \t\tLoss: 58.634559631347656\n",
      "Epoch: 30 \t\tLoss: 73.7419662475586\n",
      "Epoch: 40 \t\tLoss: 82.62555694580078\n",
      "Epoch: 50 \t\tLoss: 30.83740997314453\n",
      "Epoch: 60 \t\tLoss: 82.79553985595703\n",
      "Epoch: 70 \t\tLoss: 76.37242889404297\n",
      "Epoch: 80 \t\tLoss: 78.2113265991211\n",
      "Epoch: 90 \t\tLoss: 85.37519836425781\n",
      "Epoch: 100 \t\tLoss: 61.07470703125\n",
      "Epoch: 110 \t\tLoss: 86.727294921875\n",
      "Epoch: 120 \t\tLoss: 43.60294723510742\n",
      "Epoch: 130 \t\tLoss: 62.046077728271484\n",
      "Epoch: 140 \t\tLoss: 128.45828247070312\n",
      "Epoch: 150 \t\tLoss: 121.83206939697266\n",
      "Epoch: 160 \t\tLoss: 35.638004302978516\n",
      "Epoch: 170 \t\tLoss: 49.17754364013672\n",
      "Epoch: 180 \t\tLoss: 1.2331846952438354\n",
      "Epoch: 190 \t\tLoss: 47.58385467529297\n",
      "Epoch: 200 \t\tLoss: 27.664323806762695\n",
      "Epoch: 210 \t\tLoss: 54.58678436279297\n",
      "Epoch: 220 \t\tLoss: 22.225751876831055\n",
      "Epoch: 230 \t\tLoss: 89.01606750488281\n",
      "Epoch: 240 \t\tLoss: 14.566844940185547\n",
      "Epoch: 250 \t\tLoss: 43.948638916015625\n",
      "Epoch: 260 \t\tLoss: 2.603121280670166\n",
      "Epoch: 270 \t\tLoss: 5.078288555145264\n",
      "Epoch: 280 \t\tLoss: 0.8829746246337891\n",
      "Epoch: 290 \t\tLoss: 40.31616973876953\n",
      "Epoch: 300 \t\tLoss: 50.25827407836914\n",
      "Epoch: 310 \t\tLoss: 0.45188677310943604\n",
      "Epoch: 320 \t\tLoss: 98.04529571533203\n",
      "Epoch: 330 \t\tLoss: 23.302133560180664\n",
      "Epoch: 340 \t\tLoss: 4.920897483825684\n",
      "Epoch: 350 \t\tLoss: 6.561527252197266\n",
      "Epoch: 360 \t\tLoss: 3.574305772781372\n",
      "Epoch: 370 \t\tLoss: 17.871822357177734\n",
      "Epoch: 380 \t\tLoss: 113.68455505371094\n",
      "Epoch: 390 \t\tLoss: 133.583740234375\n",
      "Epoch: 400 \t\tLoss: 1.9430406093597412\n",
      "Epoch: 410 \t\tLoss: 41.87359619140625\n",
      "Epoch: 420 \t\tLoss: 44.6723747253418\n",
      "Epoch: 430 \t\tLoss: 1.1543248891830444\n",
      "Epoch: 440 \t\tLoss: 25.217449188232422\n",
      "Epoch: 450 \t\tLoss: 7.588505744934082\n",
      "Epoch: 460 \t\tLoss: 67.64983367919922\n",
      "Epoch: 470 \t\tLoss: 2.940678596496582\n",
      "Epoch: 480 \t\tLoss: 96.66887664794922\n",
      "Epoch: 490 \t\tLoss: 32.58888244628906\n",
      "Epoch: 500 \t\tLoss: 10.046506881713867\n"
     ]
    }
   ],
   "source": [
    "# synthetic data\n",
    "train_play(epochs=500, actions=k_2actions, policy_fn=policy_fn_2, value_fn=value_fn_2, optimizers=[value_optim, policy_optim], rand_start_state_fn=gen_start_state_2a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df2ff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(value_fn_2.state_dict(), \"trained_weights/deep_mcts_2_v_weights.pth\")\n",
    "    torch.save(policy_fn_2.state_dict(), \"trained_weights/deep_mcts_2_p_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f7b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (7/2))\n",
    "value_fn_4 = ValueNN(2).to(device)\n",
    "policy_fn_4 = PolicyNN(2,len(k_4actions)).to(device)\n",
    "value_optim_4 = optim.Adam(value_fn_4.parameters(), lr=0.00005)\n",
    "policy_optim_4 = optim.Adam(policy_fn_4.parameters(), lr=0.000005)\n",
    "\n",
    "def gen_start_state_4a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round( (torch.rand((1, 2)) - 0.5) * 2 * limit).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2b8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 2.1033401489257812\n",
      "Epoch: 20 \t\tLoss: 1.556889295578003\n",
      "Epoch: 30 \t\tLoss: 1.3582837581634521\n",
      "Epoch: 40 \t\tLoss: 1.4088467359542847\n",
      "Epoch: 50 \t\tLoss: 1.436020016670227\n",
      "Epoch: 60 \t\tLoss: 1.379128336906433\n",
      "Epoch: 70 \t\tLoss: 1.4841262102127075\n",
      "Epoch: 80 \t\tLoss: 1.3614771366119385\n",
      "Epoch: 90 \t\tLoss: 1.3785827159881592\n",
      "Epoch: 100 \t\tLoss: 1.3600499629974365\n",
      "Epoch: 110 \t\tLoss: 1.389901041984558\n",
      "Epoch: 120 \t\tLoss: 1.383531928062439\n",
      "Epoch: 130 \t\tLoss: 1.3663393259048462\n",
      "Epoch: 140 \t\tLoss: 1.3774583339691162\n",
      "Epoch: 150 \t\tLoss: 1.2760998010635376\n",
      "Epoch: 160 \t\tLoss: 1.3536250591278076\n",
      "Epoch: 170 \t\tLoss: 1.3584808111190796\n",
      "Epoch: 180 \t\tLoss: 1.3749842643737793\n",
      "Epoch: 190 \t\tLoss: 1.3323438167572021\n",
      "Epoch: 200 \t\tLoss: 1.3520457744598389\n",
      "Epoch: 210 \t\tLoss: 1.310624599456787\n",
      "Epoch: 220 \t\tLoss: 1.3285794258117676\n",
      "Epoch: 230 \t\tLoss: 1.3432512283325195\n",
      "Epoch: 240 \t\tLoss: 1.3051739931106567\n",
      "Epoch: 250 \t\tLoss: 1.3170291185379028\n"
     ]
    }
   ],
   "source": [
    "train_sv(250, k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4,policy_optim_4], fname='train_data/train_mcts.csv', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e933c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_policy_fp = \"start_weights/deep_mcts_4_p_weights.pth\"\n",
    "init_value_fp = \"start_weights/deep_mcts_4_v_weights.pth\"\n",
    "trained_policy_fp = \"trained_weights/deep_mcts_4_p_weights_f.pth\"\n",
    "trained_value_fp = \"trained_weights/deep_mcts_4_v_weights_f.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    torch.save(value_fn_4.state_dict(), init_value_fp)\n",
    "    torch.save(policy_fn_4.state_dict(), init_policy_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6fc7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_3944/2326664682.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.967\n",
      "Guess Distribution: [1086, 914]\n"
     ]
    }
   ],
   "source": [
    "train_play(epochs=100, actions=k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4, policy_optim_4], rand_start_state_fn=gen_start_state_4a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcbd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained weights\n",
    "\n",
    "\n",
    "# value_fn_4.load_state_dict(torch.load(trained_value_fp))\n",
    "# policy_fn_4.load_state_dict(torch.load(trained_policy_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c191e6c845a0bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:47:31.912513Z",
     "start_time": "2023-11-06T02:47:31.904073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float)).reshape(1,len(actions)).to(device)\n",
    "            action_plot[torch.argmax(rv)].append((i.cpu(),j.cpu()))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x, y, policy_fn, actions=k_2actions, dbs=None):\n",
    "    correct = 0\n",
    "    guess_dist = [0] * len(actions)\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0).to(device)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(data_name, actions, policy_fn, cases=100, dbs=None):\n",
    "    test_X, test_Y = get_test_data(data_name)\n",
    "    test_X = test_X.to(device)\n",
    "    test_Y.reshape(-1, 1)\n",
    "    test_Y = test_Y.to(device)\n",
    "\n",
    "    acc, guesses = test(x=test_X[:cases], y=test_Y[:cases],\n",
    "                        policy_fn=policy_fn, actions=actions, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_8778/3537842439.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9275\n",
      "Guess Distribution: [1165, 835]\n"
     ]
    }
   ],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "dual_file = \"test_data/test_simple.csv\"\n",
    "\n",
    "db2 = torch.linspace(2, k_dbound_size, k_dbound_size - 1).to(device)\n",
    "two_dbs = [db2, db2]\n",
    "\n",
    "run_test(dual_file, k_2actions, policy_fn=policy_fn_2, cases=k_cases, dbs=two_dbs)\n",
    "# ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb7c4b36c7d9707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.261\n",
      "Guess Distribution: [1000, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_8108/450618715.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "quad_file = \"test_data/four_directions_cleaner_test.csv\"     # thanks, donald\n",
    "\n",
    "k_cases = 1000\n",
    "\n",
    "k_dbound_size = 200\n",
    "\n",
    "db4 = torch.linspace(-k_dbound_size/2, k_dbound_size/2, k_dbound_size+1).to(device)\n",
    "quad_dbs = [db4, db4]\n",
    "run_test(quad_file, k_4actions, policy_fn=policy_fn_4, cases=k_cases)\n",
    "            \n",
    "# run_test(quad_file, k_4actions, policy_fn=lambda a: oh_encode(torch.tensor(determine_action(a.flatten())).view((1,1)),4), cases=k_cases, dbs=quad_dbs)\n",
    "# # 8% accuracy on Donald test csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
