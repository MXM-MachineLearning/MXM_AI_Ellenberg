{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:45:00.232700Z",
     "start_time": "2023-11-06T02:45:00.218140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "\n",
    "import math\n",
    "\n",
    "from util import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12017b9641b3200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:45:00.243783Z",
     "start_time": "2023-11-06T02:45:00.230649Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def terminal(state, k_eps=1e-4):\n",
    "    for i in state.flatten():\n",
    "        if abs(i) <= k_eps:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, parent, state, n_children, value, depth=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.visits = 0\n",
    "        self.depth = depth\n",
    "        self.children = [None] * n_children\n",
    "        self.is_terminal = terminal(self.state)\n",
    "        self.value = value\n",
    "        self.subtree_value = torch.zeros(1).to(device)\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"State: \" + str(self.state) + \"; Value: \" + str(self.value)\n",
    "                + \"; Subtree Value: \" + str(self.subtree_value) + \"; Visits:\", str(self.visits))\n",
    "\n",
    "    def is_leaf(self):\n",
    "        for i in self.state:\n",
    "            if i is not None:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8031c754a4dbbeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:56.728064Z",
     "start_time": "2023-11-06T02:48:56.722471Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, actions, C, weight, value_fn):\n",
    "        self.actions = actions\n",
    "        self.k_C = C\n",
    "        self.k_weight = weight\n",
    "        self.value_fn = value_fn\n",
    "        self.max_depth = 0\n",
    "        self.terminal = None    # None if no terminal state found; terminal Node if found\n",
    "        self.root = None\n",
    "\n",
    "    def pick_child(self, node):\n",
    "        # UCT\n",
    "        t = []\n",
    "        for i in node.children:\n",
    "            if i is None:\n",
    "                continue\n",
    "            t.append(UCT_fn(i, self.k_C))\n",
    "\n",
    "        t = torch.tensor(t)\n",
    "\n",
    "        rvs = torch.squeeze(torch.argwhere(t == torch.max(t)), axis=1)\n",
    "        if len(rvs) == 0:\n",
    "            return random.randint(0, len(node.children)-1)\n",
    "        return int(random.choice(rvs))\n",
    "\n",
    "    def default_search(self, node):\n",
    "        \"\"\"\n",
    "        If node is fully explored (neither child is None), return True\n",
    "        Otherwise, initialize value of a random unexplored next state\n",
    "\n",
    "        :param node: node to search from\n",
    "        :return: if fully explored, True. Else, value of the random unexplored next state\n",
    "        \"\"\"\n",
    "        possible = []\n",
    "        for i in range(len(node.children)):\n",
    "            if node.children[i] is None:\n",
    "                possible.append(i)\n",
    "        if len(possible) == 0:\n",
    "            return True\n",
    "\n",
    "        i = random.choice(possible)\n",
    "        # if unexplored or non-terminal, get value\n",
    "        state = torch.tensor(self.actions[i](node.state.flatten(),device=node.state.device), dtype=torch.float).to(device)\n",
    "        state = state.reshape(node.state.shape)\n",
    "        # child_val = self.value_fn(state) - node.depth - 1  # give penalty -1 for each additional step taken\n",
    "        child_val = self.value_fn(state)\n",
    "        child_val = child_val.flatten()[0]\n",
    "        node.children[i] = Node(node, state, len(self.actions), value=child_val, depth=node.depth+1)\n",
    "\n",
    "        # if new Node is terminal, take it as the tree's terminal if it takes less time to reach than current terminal\n",
    "        # if node.children[i].is_terminal:\n",
    "        #     # if terminal, add reward of ||start_vec||_2^2\n",
    "        #     node.children[i].value += torch.linalg.vector_norm(torch.square(self.root.state)).item()\n",
    "        #     if self.terminal is None or node.children[i].depth < self.terminal.depth:\n",
    "        #         self.terminal = node.children[i]\n",
    "\n",
    "        if node.children[i].depth > self.max_depth:\n",
    "            self.max_depth = node.children[i].depth\n",
    "        return node.children[i]\n",
    "\n",
    "    def tree_policy(self, node, computations):\n",
    "        while node.is_terminal is False:\n",
    "            explored = self.default_search(node)\n",
    "            if explored is not True:\n",
    "                return explored, computations + 1\n",
    "            node = node.children[self.pick_child(node)]\n",
    "            # node = random.choice(node.children)\n",
    "        return node, computations + 1\n",
    "\n",
    "    def mean_prop(self, node):\n",
    "        \"\"\"\n",
    "        Backprop up from a leaf, where subtree_value is the average of a node's rewards and its subtree's rewards\n",
    "\n",
    "        :param node: of subtree\n",
    "        \"\"\"\n",
    "        node.subtree_value = torch.zeros(1).to(device)\n",
    "        node.subtree_value += node.value\n",
    "        valid_children = 0\n",
    "        if not node.is_leaf():\n",
    "            for i in node.children:\n",
    "                if i is None:\n",
    "                    continue\n",
    "                node.subtree_value += self.k_weight * i.subtree_value\n",
    "                valid_children += 1\n",
    "        node.subtree_value /= valid_children + 1\n",
    "        node.visits += 1\n",
    "        if node.parent is None:\n",
    "            return\n",
    "        self.mean_prop(node.parent)\n",
    "\n",
    "    def run(self, root, comp_limit=10):\n",
    "        \"\"\"\n",
    "        Shoutout \"A Survey of MCTS Methods\"\n",
    "        :param root: the current state\n",
    "        :param comp_limit: max number of possible future scenarios to compute (carries over)\n",
    "        :return: index corresponding to best action\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        if self.root.is_terminal:\n",
    "            return True\n",
    "        comps = 0\n",
    "        while comps < comp_limit:\n",
    "            node, comps = self.tree_policy(self.root, comps)\n",
    "            self.mean_prop(node)\n",
    "\n",
    "        rv = self.pick_child(self.root)\n",
    "\n",
    "        if False:\n",
    "            print(\"root state:\", root.state)\n",
    "            print(\"child states: \",end=\"\")\n",
    "            for child in root.children:\n",
    "                print(child.state, end=\",\")\n",
    "            print()\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "438fdf1c04168299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.v_loss_fn = torch.nn.MSELoss()\n",
    "        self.p_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, v_out, v_target, p_out, p_target):\n",
    "        \"\"\"\n",
    "        Loss function designed to reward successful game completion while taking the least amount of steps possible\n",
    "        Adapted from:\n",
    "            - \"Mastering the game of Go without human knowledge\" (Silver et al)\n",
    "            - \"Discovering faster matrix multiplication algorithms with reinforcement learning\" (Fawzi et al)\n",
    "\n",
    "        :param v_out: the value outputed for the state by NN\n",
    "        :param p_out: the policy outputed for the state by NN\n",
    "        :param v_target: target value output\n",
    "        :return: total loss\n",
    "        \"\"\"\n",
    "        loss = self.v_loss_fn(v_out, v_target)\n",
    "        loss += self.p_loss_fn(p_out, p_target).sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ValueNN(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(ValueNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        self.value_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.stack(x).flatten()\n",
    "        value = x[0:1].reshape((1,1))\n",
    "        return value\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    def __init__(self, state_size, n_actions):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, n_actions),\n",
    "        )\n",
    "        self.policy_activation = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.policy_activation(self.stack(x))#.flatten())\n",
    "        policy = torch.clamp(x.unsqueeze(0),min=1e-8,max=1-(1e-8))\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory for better batching\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, width) -> None:\n",
    "        self.mem_ = torch.empty((0,width)).to(device)\n",
    "        self.len_ = 0\n",
    "    def record(self, obs):\n",
    "        self.mem_ = torch.cat((self.mem_, obs), dim=0)\n",
    "        self.len_ += 1\n",
    "    def recall(self, n_samples):\n",
    "        if self.len_ == 0:\n",
    "            return None\n",
    "        des_len = min(n_samples, self.len_)\n",
    "        indices = torch.ones(self.mem_.shape[0]).multinomial(des_len, replacement=False)\n",
    "        return self.mem_[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f19bdb93248565c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "k_C = 1 / math.sqrt(2)\n",
    "\n",
    "\n",
    "def train(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size=10):\n",
    "    history = Memory(2+len(actions))    # [stateX,stateY,pr1,pr2,...pr(len(actions))] (probs are sampled probs)\n",
    "    loss_fn = Loss()\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        # Repeat the following:\n",
    "        # 1) run the NN on some random initial state\n",
    "        # 2) update the NN based off performance in that game\n",
    "        mcts = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "        start = rand_start_state_fn().to(device)\n",
    "\n",
    "        value = mcts.value_fn(start).flatten().to(device)\n",
    "        policy = policy_fn(start).flatten().to(device)\n",
    "\n",
    "        start_node = Node(None, start, len(actions), value, 0)\n",
    "\n",
    "        # play out a game\n",
    "        mcts.run(start_node, comp_limit=comp_limit)\n",
    "\n",
    "\n",
    "        # get attributes of game just played\n",
    "        v_out = start_node.subtree_value.to(device)\n",
    "        v_target = -mcts.max_depth\n",
    "        if mcts.terminal is not None:\n",
    "            v_target = -mcts.terminal.depth + torch.linalg.norm(start)\n",
    "        v_target = torch.tensor(v_target,dtype=v_out.dtype).to(device)\n",
    "\n",
    "\n",
    "        visits = []\n",
    "        for i in start_node.children:\n",
    "            if i is None:\n",
    "                visits.append(0)\n",
    "            else:\n",
    "                visits.append(i.visits)\n",
    "        visits = torch.tensor(visits, dtype=torch.float).to(device)\n",
    "        p_sampled = visits / torch.sum(visits)\n",
    "\n",
    "        curr_batch_entry = torch.cat((start,p_sampled.flatten().unsqueeze(0)),dim=1)\n",
    "        hist = history.recall(batch_size)\n",
    "        batch = curr_batch_entry\n",
    "        if hist is not None:\n",
    "            batch = torch.cat((hist, batch),dim=0)\n",
    "        batch_states = batch[:,:2]\n",
    "        batch_psampled = batch[:,2:]\n",
    "\n",
    "        # v_loss = v_loss_fn(v_out, torch.tensor(v_target,dtype=v_out.dtype))\n",
    "        # p_loss = p_loss_fn(policy_fn(batch_states), batch_psampled)\n",
    "        loss = loss_fn(v_out, v_target,\n",
    "                       policy_fn(batch_states).reshape(batch_psampled.shape), batch_psampled)\n",
    "        loss.backward()\n",
    "        # v_loss.backward()\n",
    "        # p_loss.backward()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "\n",
    "        history.record(curr_batch_entry)\n",
    "\n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "            # if torch.isnan(p_loss):\n",
    "            #     print(\"value\",v_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (3/2))\n",
    "k_2actions = (a_subtract, a_swap)\n",
    "value_fn_2 = ValueNN(2).to(device)\n",
    "policy_fn_2 = PolicyNN(2,len(k_2actions)).to(device)\n",
    "value_optim = optim.Adam(value_fn_2.parameters(), lr=0.00005)\n",
    "policy_optim = optim.Adam(policy_fn_2.parameters(), lr=0.00005)\n",
    "\n",
    "def gen_start_state_2a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((1, 2)) * limit + 1).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 83.53762817382812\n",
      "Epoch: 20 \t\tLoss: 58.634559631347656\n",
      "Epoch: 30 \t\tLoss: 73.7419662475586\n",
      "Epoch: 40 \t\tLoss: 82.62555694580078\n",
      "Epoch: 50 \t\tLoss: 30.83740997314453\n",
      "Epoch: 60 \t\tLoss: 82.79553985595703\n",
      "Epoch: 70 \t\tLoss: 76.37242889404297\n",
      "Epoch: 80 \t\tLoss: 78.2113265991211\n",
      "Epoch: 90 \t\tLoss: 85.37519836425781\n",
      "Epoch: 100 \t\tLoss: 61.07470703125\n",
      "Epoch: 110 \t\tLoss: 86.727294921875\n",
      "Epoch: 120 \t\tLoss: 43.60294723510742\n",
      "Epoch: 130 \t\tLoss: 62.046077728271484\n",
      "Epoch: 140 \t\tLoss: 128.45828247070312\n",
      "Epoch: 150 \t\tLoss: 121.83206939697266\n",
      "Epoch: 160 \t\tLoss: 35.638004302978516\n",
      "Epoch: 170 \t\tLoss: 49.17754364013672\n",
      "Epoch: 180 \t\tLoss: 1.2331846952438354\n",
      "Epoch: 190 \t\tLoss: 47.58385467529297\n",
      "Epoch: 200 \t\tLoss: 27.664323806762695\n",
      "Epoch: 210 \t\tLoss: 54.58678436279297\n",
      "Epoch: 220 \t\tLoss: 22.225751876831055\n",
      "Epoch: 230 \t\tLoss: 89.01606750488281\n",
      "Epoch: 240 \t\tLoss: 14.566844940185547\n",
      "Epoch: 250 \t\tLoss: 43.948638916015625\n",
      "Epoch: 260 \t\tLoss: 2.603121280670166\n",
      "Epoch: 270 \t\tLoss: 5.078288555145264\n",
      "Epoch: 280 \t\tLoss: 0.8829746246337891\n",
      "Epoch: 290 \t\tLoss: 40.31616973876953\n",
      "Epoch: 300 \t\tLoss: 50.25827407836914\n",
      "Epoch: 310 \t\tLoss: 0.45188677310943604\n",
      "Epoch: 320 \t\tLoss: 98.04529571533203\n",
      "Epoch: 330 \t\tLoss: 23.302133560180664\n",
      "Epoch: 340 \t\tLoss: 4.920897483825684\n",
      "Epoch: 350 \t\tLoss: 6.561527252197266\n",
      "Epoch: 360 \t\tLoss: 3.574305772781372\n",
      "Epoch: 370 \t\tLoss: 17.871822357177734\n",
      "Epoch: 380 \t\tLoss: 113.68455505371094\n",
      "Epoch: 390 \t\tLoss: 133.583740234375\n",
      "Epoch: 400 \t\tLoss: 1.9430406093597412\n",
      "Epoch: 410 \t\tLoss: 41.87359619140625\n",
      "Epoch: 420 \t\tLoss: 44.6723747253418\n",
      "Epoch: 430 \t\tLoss: 1.1543248891830444\n",
      "Epoch: 440 \t\tLoss: 25.217449188232422\n",
      "Epoch: 450 \t\tLoss: 7.588505744934082\n",
      "Epoch: 460 \t\tLoss: 67.64983367919922\n",
      "Epoch: 470 \t\tLoss: 2.940678596496582\n",
      "Epoch: 480 \t\tLoss: 96.66887664794922\n",
      "Epoch: 490 \t\tLoss: 32.58888244628906\n",
      "Epoch: 500 \t\tLoss: 10.046506881713867\n"
     ]
    }
   ],
   "source": [
    "# synthetic data\n",
    "train(epochs=500, actions=k_2actions, policy_fn=policy_fn_2, value_fn=value_fn_2, optimizers=[value_optim, policy_optim], rand_start_state_fn=gen_start_state_2a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(value_fn_2.state_dict(), \"deep_mcts_2_v_weights.pth\")\n",
    "    torch.save(policy_fn_2.state_dict(), \"deep_mcts_2_p_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (7/2))\n",
    "k_4actions = (a_plsy, a_suby, a_plsx, a_subx)\n",
    "value_fn_4 = ValueNN(2).to(device)\n",
    "policy_fn_4 = PolicyNN(2,len(k_4actions)).to(device)\n",
    "value_optim_4 = optim.Adam(value_fn_4.parameters(), lr=0.00005)\n",
    "policy_optim_4 = optim.Adam(policy_fn_4.parameters(), lr=0.000005)\n",
    "\n",
    "def gen_start_state_4a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round( (torch.rand((1, 2)) - 0.5) * 2 * limit).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_3944/1085129231.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(self.actions[i](node.state.flatten()), dtype=torch.float)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, actions\u001b[39m=\u001b[39;49mk_4actions, policy_fn\u001b[39m=\u001b[39;49mpolicy_fn_4, value_fn\u001b[39m=\u001b[39;49mvalue_fn_4, optimizers\u001b[39m=\u001b[39;49m[value_optim_4, policy_optim_4], rand_start_state_fn\u001b[39m=\u001b[39;49mgen_start_state_4a, comp_limit\u001b[39m=\u001b[39;49mk_comp_limit)\n",
      "\u001b[1;32m/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m start_node \u001b[39m=\u001b[39m Node(\u001b[39mNone\u001b[39;00m, start, \u001b[39mlen\u001b[39m(actions), value, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# play out a game\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m mcts\u001b[39m.\u001b[39;49mrun(start_node, comp_limit\u001b[39m=\u001b[39;49mcomp_limit)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# get attributes of game just played\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m v_out \u001b[39m=\u001b[39m start_node\u001b[39m.\u001b[39msubtree_value\n",
      "\u001b[1;32m/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m comps \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mwhile\u001b[39;00m comps \u001b[39m<\u001b[39m comp_limit:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     node, comps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_policy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, comps)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_prop(node)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m rv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpick_child(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot)\n",
      "\u001b[1;32m/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mif\u001b[39;00m explored \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m explored, computations \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     node \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mchildren[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpick_child(node)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# node = random.choice(node.children)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mreturn\u001b[39;00m node, computations \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rvs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(node\u001b[39m.\u001b[39mchildren)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ayun/CODE/MXM/MXM-AI-Fall-2023/Euclidean/Alex/deep_mcts.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39;49m(random\u001b[39m.\u001b[39;49mchoice(rvs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=100, actions=k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4, policy_optim_4], rand_start_state_fn=gen_start_state_4a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c191e6c845a0bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:47:31.912513Z",
     "start_time": "2023-11-06T02:47:31.904073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float).reshape(1,len(actions)).to(device))\n",
    "            action_plot[torch.argmax(rv)].append((i.cpu(),j.cpu()))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x, y, policy_fn, actions=(a_subtract, a_swap), dbs=None):\n",
    "    correct = 0\n",
    "    guess_dist = [0] * len(actions)\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0).to(device)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(data_name, actions, policy_fn, cases=100, dbs=None):\n",
    "    test_X, test_Y = get_data(data_name)\n",
    "    test_X = test_X.to(device)\n",
    "    test_Y.reshape(-1, 1)\n",
    "    test_Y = test_Y.to(device)\n",
    "\n",
    "    acc, guesses = test(x=test_X[:cases], y=test_Y[:cases],\n",
    "                        policy_fn=policy_fn, actions=actions, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_3944/2326664682.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.967\n",
      "Guess Distribution: [1086, 914]\n"
     ]
    }
   ],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "dual_file = \"test_data/test_simple.csv\"\n",
    "\n",
    "db2 = torch.linspace(2, k_dbound_size, k_dbound_size - 1).to(device)\n",
    "two_dbs = [db2, db2]\n",
    "\n",
    "run_test(dual_file, k_2actions, policy_fn=policy_fn_2, cases=k_cases, dbs=two_dbs)\n",
    "# ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6bb7c4b36c7d9707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_4253/2326664682.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.279\n",
      "Guess Distribution: [0, 180, 75, 745]\n"
     ]
    }
   ],
   "source": [
    "quad_file = \"../Donald/four_step_euclidean/four_directions_cleaner_test.csv\"     # thanks, donald\n",
    "\n",
    "k_cases = 1000\n",
    "\n",
    "k_dbound_size = 100\n",
    "\n",
    "db4 = torch.linspace(-k_dbound_size/2, k_dbound_size/2, k_dbound_size+1).to(device)\n",
    "quad_dbs = [db4, db4]\n",
    "run_test(quad_file, k_4actions, policy_fn=policy_fn_4, cases=k_cases)\n",
    "# # 8% accuracy on Donald test csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
