{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:28:23.047407Z",
     "start_time": "2024-02-28T00:28:03.339254Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "import threading\n",
    "import concurrent\n",
    "\n",
    "import math\n",
    "\n",
    "from util import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603bf730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nogil=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: RUN WITH NOGIL https://github.com/colesbury/nogil FOR MUCH BETTER PERFORMANCE\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"nogil={getattr(sys.flags, 'nogil', False)}\")\n",
    "\n",
    "\"\"\"\n",
    "NOTE: RUN WITH NOGIL https://github.com/colesbury/nogil FOR MUCH BETTER PERFORMANCE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d75afc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:36.547536Z",
     "start_time": "2024-02-28T00:29:36.538039Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, n_children, value, depth=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.visits = 0\n",
    "        self.depth = depth\n",
    "        self.children = [None] * n_children\n",
    "        self.is_terminal = terminal(self.state)\n",
    "        self.value = value\n",
    "        self.subtree_value = torch.zeros(1).to(device)\n",
    "\n",
    "        # for more on virtual loss/shared tree search, see \"Parallel MCTS\" by Chaslot et al. \n",
    "        # https://dke.maastrichtuniversity.nl/m.winands/documents/multithreadedMCTS2.pdf\n",
    "        self.active_threads = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"State: \" + str(self.state) + \"; Value: \" + str(self.value)\n",
    "                + \"; Subtree Value: \" + str(self.subtree_value) + \"; Visits:\", str(self.visits))\n",
    "\n",
    "    def is_leaf(self):\n",
    "        for i in self.state:\n",
    "            if i is not None:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "# override the one in util.py\n",
    "def UCT_fn(child, C):\n",
    "    if child.visits == 0:\n",
    "        return math.inf\n",
    "    return child.subtree_value + 2 * C * math.sqrt(2 * math.log2(child.parent.visits) / child.visits) - child.active_threads\n",
    "    \n",
    "class MCTS:\n",
    "    def __init__(self, actions, C, weight, value_fn):\n",
    "        self.actions = actions\n",
    "        self.k_C = C\n",
    "        self.k_weight = weight\n",
    "        self.value_fn = value_fn\n",
    "        self.max_depth = 0\n",
    "        self.terminal = None    # None if no terminal state found; terminal Node if found\n",
    "        self.root = None\n",
    "        self.propagation_lock = threading.Lock()\n",
    "\n",
    "    def pick_child(self, node):\n",
    "        # UCT\n",
    "        t = []\n",
    "        for i in node.children:\n",
    "            if i is None:\n",
    "                continue\n",
    "            t.append(UCT_fn(i, self.k_C))\n",
    "\n",
    "        if len(t) == 0:\n",
    "            return random.randint(0, len(node.children)-1)\n",
    "        \n",
    "        t = torch.tensor(t)\n",
    "\n",
    "        rvs = torch.squeeze(torch.argwhere(t == torch.max(t)), axis=1)\n",
    "        return int(random.choice(rvs))\n",
    "\n",
    "    def default_search(self, node):\n",
    "        \"\"\"\n",
    "        If node is fully explored (neither child is None), return True\n",
    "        Otherwise, initialize value of a random unexplored next state\n",
    "\n",
    "        :param node: node to search from\n",
    "        :return: if fully explored, True. Else, value of the random unexplored next state\n",
    "        \"\"\"\n",
    "        possible = []\n",
    "        for i in range(len(node.children)):\n",
    "            if node.children[i] is None:\n",
    "                possible.append(i)\n",
    "        if len(possible) == 0:\n",
    "            return True\n",
    "\n",
    "        i = random.choice(possible)\n",
    "        # if unexplored or non-terminal, get value\n",
    "        state = self.actions[i](node.state.flatten()).float().to(device)\n",
    "        state = state.reshape(node.state.shape)\n",
    "        # child_val = self.value_fn(state) - node.depth - 1  # give penalty -1 for each additional step taken\n",
    "        child_val = self.value_fn(state)\n",
    "        child_val = child_val.flatten()[0]\n",
    "\n",
    "        with node.lock:\n",
    "            node.children[i] = Node(node, state, len(self.actions), value=child_val, depth=node.depth+1)\n",
    "\n",
    "        # if new Node is terminal, take it as the tree's terminal if it takes less time to reach than current terminal\n",
    "        # if node.children[i].is_terminal:\n",
    "        #     # if terminal, add reward of ||start_vec||_2^2\n",
    "        #     node.children[i].value += torch.linalg.vector_norm(torch.square(self.root.state)).item()\n",
    "        #     if self.terminal is None or node.children[i].depth < self.terminal.depth:\n",
    "        #         self.terminal = node.children[i]\n",
    "\n",
    "        with self.propagation_lock:\n",
    "            if node.children[i].depth > self.max_depth:\n",
    "                self.max_depth = node.children[i].depth\n",
    "        return node.children[i]\n",
    "\n",
    "    def tree_policy(self, node):\n",
    "        prev = None\n",
    "        while node.is_terminal is False:\n",
    "            # add some virtual loss to the node for each thread that's exploring (released after back propagating)\n",
    "            with node.lock:\n",
    "                node.active_threads += 1\n",
    "\n",
    "            explored = self.default_search(node)\n",
    "            if explored is not True:\n",
    "                return explored\n",
    "            node = node.children[self.pick_child(node)]\n",
    "            prev = node\n",
    "            # node = random.choice(node.children)\n",
    "        return prev\n",
    "\n",
    "    def mean_prop(self, node):\n",
    "        \"\"\"\n",
    "        Backprop up from a leaf, where subtree_value is the average of a node's rewards and its subtree's rewards\n",
    "\n",
    "        :param node: of subtree\n",
    "        \"\"\"\n",
    "        with node.lock:\n",
    "            node.subtree_value = torch.zeros(1).to(device)\n",
    "            node.subtree_value += node.value\n",
    "            valid_children = 0\n",
    "            if not node.is_leaf():\n",
    "                for i in node.children:\n",
    "                    if i is None:\n",
    "                        continue\n",
    "                    node.subtree_value += self.k_weight * i.subtree_value\n",
    "                    valid_children += 1\n",
    "            node.subtree_value /= valid_children + 1\n",
    "            node.visits += 1\n",
    "\n",
    "            # remove virtual loss from node after thread done exploring its subtree\n",
    "            node.active_threads -= 1\n",
    "\n",
    "            if node.parent is None:\n",
    "                return\n",
    "        self.mean_prop(node.parent)\n",
    "\n",
    "    def explore_once(self, number):\n",
    "        node = self.tree_policy(self.root)\n",
    "        with self.propagation_lock:\n",
    "            self.mean_prop(node)\n",
    "        return number\n",
    "\n",
    "    def run(self, root, comp_limit=10, max_threads=5):\n",
    "        \"\"\"\n",
    "        Shoutout \"A Survey of MCTS Methods\"\n",
    "        :param root: the current state\n",
    "        :param comp_limit: max number of possible future scenarios to compute (carries over)\n",
    "        :return: index corresponding to best action\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        if self.root.is_terminal:\n",
    "            return True\n",
    "\n",
    "        # spawn new thread for each computation\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            executor.map(self.explore_once, range(comp_limit))\n",
    "\n",
    "        rv = self.pick_child(self.root)\n",
    "\n",
    "        if False:\n",
    "            print(\"root state:\", root.state)\n",
    "            print(\"child states: \",end=\"\")\n",
    "            for child in root.children:\n",
    "                print(child.state, end=\",\")\n",
    "            print()\n",
    "        return rv\n",
    "    \n",
    "    def generate(self, init_state, actions):\n",
    "        self.root = Node(None, init_state, n_children=len(self.actions), value=self.value_fn(init_state), depth=0)\n",
    "        curr = self.root\n",
    "        r_nodes = []\n",
    "        for i in actions:\n",
    "            newstate = self.actions[i](curr.state)\n",
    "            n = Node(parent=curr,\n",
    "                     state=newstate,\n",
    "                     n_children=len(self.actions),\n",
    "                     value=self.value_fn(newstate),\n",
    "                     depth=curr.depth + 1)\n",
    "            curr.children[i] = n\n",
    "            curr = n            \n",
    "            r_nodes.append(n)\n",
    "        return r_nodes\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438fdf1c04168299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:37.378811Z",
     "start_time": "2024-02-28T00:29:37.370384Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.v_loss_fn = torch.nn.MSELoss()\n",
    "        self.p_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, v_out, v_target, p_out, p_target):\n",
    "        \"\"\"\n",
    "        Loss function designed to reward successful game completion while taking the least amount of steps possible\n",
    "        Adapted from:\n",
    "            - \"Mastering the game of Go without human knowledge\" (Silver et al)\n",
    "            - \"Discovering faster matrix multiplication algorithms with reinforcement learning\" (Fawzi et al)\n",
    "\n",
    "        :param v_out: the value outputed for the state by NN\n",
    "        :param p_out: the policy outputed for the state by NN\n",
    "        :param v_target: target value output\n",
    "        :return: total loss\n",
    "        \"\"\"\n",
    "        loss = self.v_loss_fn(v_out, v_target)\n",
    "        loss += self.p_loss_fn(p_out, p_target).sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ValueNN(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(ValueNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        self.value_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "#        x = self.flatten(x)\n",
    "#        x = self.stack(x).flatten()\n",
    "#        value = x[0:1].reshape((1,1))\n",
    "#        return value\n",
    "        return self.stack(x)\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    def __init__(self, state_size, n_actions):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, n_actions),\n",
    "        )\n",
    "        self.policy_activation = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.policy_activation(self.stack(x))#.flatten())\n",
    "        policy = torch.clamp(x,min=1e-8,max=1-(1e-7))\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e3ddf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:38.334723Z",
     "start_time": "2024-02-28T00:29:38.325718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memory for better batching\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, width) -> None:\n",
    "        self.mem_ = torch.empty((0,width)).to(device)\n",
    "        self.len_ = 0\n",
    "    def record(self, obs):\n",
    "        self.mem_ = torch.cat((self.mem_, obs), dim=0)\n",
    "        self.len_ += 1\n",
    "    def recall(self, n_samples):\n",
    "        if self.len_ == 0:\n",
    "            return None\n",
    "        des_len = min(n_samples, self.len_)\n",
    "        indices = torch.ones(self.mem_.shape[0]).multinomial(des_len, replacement=False)\n",
    "        return self.mem_[indices]\n",
    "    def size(self):\n",
    "        return self.len_\n",
    "    def clear(self):\n",
    "        self.mem_ = torch.empty(self.mem_.shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19bdb93248565c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:39.699250Z",
     "start_time": "2024-02-28T00:29:39.688411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "k_C = 1 / math.sqrt(2)\n",
    "k_thread_count_limit = 20\n",
    "\n",
    "def get_train_data(fname):\n",
    "    x = np.loadtxt(fname, delimiter=\",\")\n",
    "    return torch.tensor([x[:,2], x[:,2:]], dtype=torch.float)\n",
    "\n",
    "def get_nonterm_rwd(mcts):\n",
    "    return -mcts.max_depth\n",
    "\n",
    "def get_terminal_rwd(terminal_depth, start):\n",
    "    return -terminal_depth + torch.linalg.norm(start)\n",
    "\n",
    "def train_sv(epochs, actions, policy_fn, value_fn, optimizers, fname, batch_size=10):\n",
    "    k_mem_width = 4    # statex,statey,action,subtree_value\n",
    "    memory = Memory(k_mem_width)\n",
    "    loss_fn = Loss()\n",
    "    # load data into memory\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            entry = torch.tensor(list(map(int, line.split(','))))\n",
    "            tree = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "            g_nodes = tree.generate(entry[0:2].unsqueeze(0).float(), entry[2:])\n",
    "            for i in range(len(entry) - 2): # go by actions (so we disregard the terminal node)\n",
    "                memory.record(torch.cat((g_nodes[i].state.reshape(1,2), \n",
    "                                         entry[2+i].reshape((1,1)), \n",
    "                                         g_nodes[i].subtree_value.reshape(1,1)), dim=1))\n",
    "    # train off memory\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        batch = memory.recall(batch_size)\n",
    "        v_out = value_fn(batch[:,:2])\n",
    "        p_out = policy_fn(batch[:,:2])\n",
    "\n",
    "        # one-hot encode actions; e.g. convert 3 -> (0,0,0,1)\n",
    "        action_indices = batch[:,2:-1].to(torch.int64)\n",
    "        p_target = oh_encode(action_indices, len(actions))\n",
    "        # p_target = torch.zeros(action_indices.shape[0],len(actions))\n",
    "        # p_target.scatter_(1, action_indices,1)\n",
    "\n",
    "        v_target = batch[:,-1]\n",
    "\n",
    "        loss = loss_fn(v_out.view(v_target.shape), v_target, p_out.view(p_target.shape), p_target)\n",
    "        loss.backward()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "    \n",
    "        if (t+1) % 10 == 0:\n",
    "            print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "\n",
    "\n",
    "def train_play(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size=16):\n",
    "    history = Memory(2+len(actions))    # [stateX,stateY,pr1,pr2,...pr(len(actions))] (probs are sampled probs)\n",
    "    loss_fn = Loss()\n",
    "    for t in range(epochs):\n",
    "        for o in optimizers:\n",
    "            o.zero_grad()\n",
    "        # Repeat the following:\n",
    "        # 1) run the NN on some random initial state\n",
    "        # 2) update the NN based off performance in that game\n",
    "            \n",
    "        # play out some games\n",
    "        k_comp_limit = comp_limit(t / epochs)\n",
    "        for game in range(batch_size):\n",
    "            mcts = MCTS(actions, C=k_C, weight=1, value_fn=value_fn)\n",
    "            start = rand_start_state_fn().to(device)\n",
    "\n",
    "            value = mcts.value_fn(start).flatten().to(device)\n",
    "            policy = policy_fn(start).flatten().to(device)\n",
    "\n",
    "            start_node = Node(None, start, len(actions), value, 0)\n",
    "\n",
    "            mcts.run(start_node, comp_limit=k_comp_limit, max_threads=k_thread_count_limit)\n",
    "\n",
    "\n",
    "            # get attributes of game just played\n",
    "            v_out = start_node.subtree_value.to(device)\n",
    "            v_target = get_nonterm_rwd(mcts)\n",
    "            if mcts.terminal is not None:\n",
    "                v_target = get_terminal_rwd(mcts.terminal.depth, start)\n",
    "            v_target = torch.tensor(v_target,dtype=v_out.dtype).to(device)\n",
    "\n",
    "\n",
    "            visits = []\n",
    "            for i in start_node.children:\n",
    "                if i is None:\n",
    "                    visits.append(0)\n",
    "                else:\n",
    "                    visits.append(i.visits)\n",
    "            visits = torch.tensor(visits, dtype=torch.float).to(device)\n",
    "            p_sampled = visits / torch.sum(visits)\n",
    "\n",
    "            curr_batch_entry = torch.cat((start,p_sampled.flatten().unsqueeze(0)),dim=1)\n",
    "            history.record(curr_batch_entry)\n",
    "\n",
    "        # train NN on games just played\n",
    "        batch = history.recall(batch_size)\n",
    "        batch_states = batch[:,:2]\n",
    "        batch_psampled = batch[:,2:]\n",
    "        \n",
    "        loss = loss_fn(v_out, v_target,\n",
    "                       policy_fn(batch_states).reshape(batch_psampled.shape), batch_psampled)\n",
    "        loss.backward()\n",
    "\n",
    "        history.clear()\n",
    "\n",
    "        for o in optimizers:\n",
    "            o.step()\n",
    "\n",
    "\n",
    "        # if (t+1) % 10 == 0:\n",
    "        print(\"Epoch:\", t+1,\"\\t\\tLoss:\",loss.item())\n",
    "            # if torch.isnan(p_loss):\n",
    "            #     print(\"value\",v_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e004f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T00:29:40.566311Z",
     "start_time": "2024-02-28T00:29:40.556759Z"
    }
   },
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (3/2))\n",
    "k_min_comps = int(k_state_upper_lim ** (1.1))\n",
    "\n",
    "value_fn_2 = ValueNN(2).to(device)\n",
    "policy_fn_2 = PolicyNN(2,len(k_2actions)).to(device)\n",
    "value_optim = optim.Adam(value_fn_2.parameters(), lr=0.00005)\n",
    "policy_optim = optim.Adam(policy_fn_2.parameters(), lr=0.000005)\n",
    "\n",
    "def gen_start_state_2a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round(torch.rand((1, 2)) * limit + 1).float()\n",
    "\n",
    "def adaptive_comp_limit(frac_epochs):\n",
    "    # linearly decrease computation limit as model becomes better over time\n",
    "    rv = k_comp_limit - (k_comp_limit - k_min_comps) * frac_epochs\n",
    "    return int(rv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41211b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T02:48:18.942268Z",
     "start_time": "2024-02-28T02:48:12.374093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayun/.pyenv/versions/nogil-3.9.10-1/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t\tLoss: 49.64299011230469\n",
      "Epoch: 2 \t\tLoss: 48.96635055541992\n",
      "Epoch: 3 \t\tLoss: 48.46635437011719\n",
      "Epoch: 4 \t\tLoss: 47.07497024536133\n",
      "Epoch: 5 \t\tLoss: 47.68707275390625\n",
      "Epoch: 6 \t\tLoss: 48.95708465576172\n",
      "Epoch: 7 \t\tLoss: 61.734134674072266\n",
      "Epoch: 8 \t\tLoss: 58.00735855102539\n",
      "Epoch: 9 \t\tLoss: 59.25767517089844\n",
      "Epoch: 10 \t\tLoss: 45.85573196411133\n",
      "Epoch: 11 \t\tLoss: 44.15620040893555\n",
      "Epoch: 12 \t\tLoss: 43.886173248291016\n",
      "Epoch: 13 \t\tLoss: 60.103912353515625\n",
      "Epoch: 14 \t\tLoss: 41.85918426513672\n",
      "Epoch: 15 \t\tLoss: 46.56689453125\n",
      "Epoch: 16 \t\tLoss: 55.11103820800781\n",
      "Epoch: 17 \t\tLoss: 52.91510009765625\n",
      "Epoch: 18 \t\tLoss: 41.62240982055664\n",
      "Epoch: 19 \t\tLoss: 59.58417510986328\n",
      "Epoch: 20 \t\tLoss: 58.63788986206055\n",
      "Epoch: 21 \t\tLoss: 43.06944274902344\n",
      "Epoch: 22 \t\tLoss: 55.042354583740234\n",
      "Epoch: 23 \t\tLoss: 48.13758850097656\n",
      "Epoch: 24 \t\tLoss: 38.12171173095703\n",
      "Epoch: 25 \t\tLoss: 40.35714340209961\n",
      "Epoch: 26 \t\tLoss: 39.0184326171875\n",
      "Epoch: 27 \t\tLoss: 58.08982849121094\n",
      "Epoch: 28 \t\tLoss: 36.72500991821289\n",
      "Epoch: 29 \t\tLoss: 46.864933013916016\n",
      "Epoch: 30 \t\tLoss: 37.38310623168945\n",
      "Epoch: 31 \t\tLoss: 38.72101593017578\n",
      "Epoch: 32 \t\tLoss: 55.1484260559082\n",
      "Epoch: 33 \t\tLoss: 38.79916763305664\n",
      "Epoch: 34 \t\tLoss: 54.0600471496582\n",
      "Epoch: 35 \t\tLoss: -0.35917460918426514\n",
      "Epoch: 36 \t\tLoss: 44.70682144165039\n",
      "Epoch: 37 \t\tLoss: 47.74397659301758\n",
      "Epoch: 38 \t\tLoss: 43.042789459228516\n",
      "Epoch: 39 \t\tLoss: -5.459637095570513e+27\n",
      "Epoch: 40 \t\tLoss: 47.983524322509766\n",
      "Epoch: 41 \t\tLoss: 44.10798263549805\n",
      "Epoch: 42 \t\tLoss: 33.2801513671875\n",
      "Epoch: 43 \t\tLoss: 36.611534118652344\n",
      "Epoch: 44 \t\tLoss: 47.27546310424805\n",
      "Epoch: 45 \t\tLoss: 35.4338493347168\n",
      "Epoch: 46 \t\tLoss: 47.42512130737305\n",
      "Epoch: 47 \t\tLoss: 51.79990768432617\n",
      "Epoch: 48 \t\tLoss: 45.2761116027832\n",
      "Epoch: 49 \t\tLoss: -4.623123948948751e+30\n",
      "Epoch: 50 \t\tLoss: -1.007120564513164e+28\n",
      "Epoch: 51 \t\tLoss: 32.88935852050781\n",
      "Epoch: 52 \t\tLoss: 45.683685302734375\n",
      "Epoch: 53 \t\tLoss: -3.490672413571465e+35\n",
      "Epoch: 54 \t\tLoss: -3.272078228382024e+17\n",
      "Epoch: 55 \t\tLoss: 39.5705680847168\n",
      "Epoch: 56 \t\tLoss: 38.06694793701172\n",
      "Epoch: 57 \t\tLoss: -2.5978507795528627e+21\n",
      "Epoch: 58 \t\tLoss: 35.213401794433594\n",
      "Epoch: 59 \t\tLoss: 40.42478561401367\n",
      "Epoch: 60 \t\tLoss: 35.738529205322266\n",
      "Epoch: 61 \t\tLoss: 44.90142059326172\n",
      "Epoch: 62 \t\tLoss: 26.30010986328125\n",
      "Epoch: 63 \t\tLoss: 30.6998233795166\n",
      "Epoch: 64 \t\tLoss: -1.6399413735944823e+25\n",
      "Epoch: 65 \t\tLoss: 41.761863708496094\n",
      "Epoch: 66 \t\tLoss: 2.074025869369507\n",
      "Epoch: 67 \t\tLoss: 43.47184371948242\n",
      "Epoch: 68 \t\tLoss: nan\n",
      "Epoch: 69 \t\tLoss: nan\n",
      "Epoch: 70 \t\tLoss: nan\n",
      "Epoch: 71 \t\tLoss: nan\n",
      "Epoch: 72 \t\tLoss: nan\n",
      "Epoch: 73 \t\tLoss: nan\n",
      "Epoch: 74 \t\tLoss: nan\n",
      "Epoch: 75 \t\tLoss: nan\n",
      "Epoch: 76 \t\tLoss: nan\n",
      "Epoch: 77 \t\tLoss: nan\n",
      "Epoch: 78 \t\tLoss: nan\n",
      "Epoch: 79 \t\tLoss: nan\n",
      "Epoch: 80 \t\tLoss: nan\n",
      "Epoch: 81 \t\tLoss: nan\n",
      "Epoch: 82 \t\tLoss: nan\n",
      "Epoch: 83 \t\tLoss: nan\n",
      "Epoch: 84 \t\tLoss: nan\n",
      "Epoch: 85 \t\tLoss: nan\n",
      "Epoch: 86 \t\tLoss: nan\n",
      "Epoch: 87 \t\tLoss: nan\n",
      "Epoch: 88 \t\tLoss: nan\n",
      "Epoch: 89 \t\tLoss: nan\n",
      "Epoch: 90 \t\tLoss: nan\n",
      "Epoch: 91 \t\tLoss: nan\n",
      "Epoch: 92 \t\tLoss: nan\n",
      "Epoch: 93 \t\tLoss: nan\n",
      "Epoch: 94 \t\tLoss: nan\n",
      "Epoch: 95 \t\tLoss: nan\n",
      "Epoch: 96 \t\tLoss: nan\n",
      "Epoch: 97 \t\tLoss: nan\n",
      "Epoch: 98 \t\tLoss: nan\n",
      "Epoch: 99 \t\tLoss: nan\n",
      "Epoch: 100 \t\tLoss: nan\n",
      "Epoch: 101 \t\tLoss: nan\n",
      "Epoch: 102 \t\tLoss: nan\n",
      "Epoch: 103 \t\tLoss: nan\n",
      "Epoch: 104 \t\tLoss: nan\n",
      "Epoch: 105 \t\tLoss: nan\n",
      "Epoch: 106 \t\tLoss: nan\n",
      "Epoch: 107 \t\tLoss: nan\n",
      "Epoch: 108 \t\tLoss: nan\n",
      "Epoch: 109 \t\tLoss: nan\n",
      "Epoch: 110 \t\tLoss: nan\n",
      "Epoch: 111 \t\tLoss: nan\n",
      "Epoch: 112 \t\tLoss: nan\n",
      "Epoch: 113 \t\tLoss: nan\n",
      "Epoch: 114 \t\tLoss: nan\n",
      "Epoch: 115 \t\tLoss: nan\n",
      "Epoch: 116 \t\tLoss: nan\n",
      "Epoch: 117 \t\tLoss: nan\n",
      "Epoch: 118 \t\tLoss: nan\n",
      "Epoch: 119 \t\tLoss: nan\n",
      "Epoch: 120 \t\tLoss: nan\n",
      "Epoch: 121 \t\tLoss: nan\n",
      "Epoch: 122 \t\tLoss: nan\n",
      "Epoch: 123 \t\tLoss: nan\n",
      "Epoch: 124 \t\tLoss: nan\n",
      "Epoch: 125 \t\tLoss: nan\n",
      "Epoch: 126 \t\tLoss: nan\n",
      "Epoch: 127 \t\tLoss: nan\n",
      "Epoch: 128 \t\tLoss: nan\n",
      "Epoch: 129 \t\tLoss: nan\n",
      "Epoch: 130 \t\tLoss: nan\n",
      "Epoch: 131 \t\tLoss: nan\n",
      "Epoch: 132 \t\tLoss: nan\n",
      "Epoch: 133 \t\tLoss: nan\n",
      "Epoch: 134 \t\tLoss: nan\n",
      "Epoch: 135 \t\tLoss: nan\n",
      "Epoch: 136 \t\tLoss: nan\n",
      "Epoch: 137 \t\tLoss: nan\n",
      "Epoch: 138 \t\tLoss: nan\n",
      "Epoch: 139 \t\tLoss: nan\n",
      "Epoch: 140 \t\tLoss: nan\n",
      "Epoch: 141 \t\tLoss: nan\n",
      "Epoch: 142 \t\tLoss: nan\n",
      "Epoch: 143 \t\tLoss: nan\n",
      "Epoch: 144 \t\tLoss: nan\n",
      "Epoch: 145 \t\tLoss: nan\n",
      "Epoch: 146 \t\tLoss: nan\n",
      "Epoch: 147 \t\tLoss: nan\n",
      "Epoch: 148 \t\tLoss: nan\n",
      "Epoch: 149 \t\tLoss: nan\n",
      "Epoch: 150 \t\tLoss: nan\n",
      "Epoch: 151 \t\tLoss: nan\n",
      "Epoch: 152 \t\tLoss: nan\n",
      "Epoch: 153 \t\tLoss: nan\n",
      "Epoch: 154 \t\tLoss: nan\n",
      "Epoch: 155 \t\tLoss: nan\n",
      "Epoch: 156 \t\tLoss: nan\n",
      "Epoch: 157 \t\tLoss: nan\n",
      "Epoch: 158 \t\tLoss: nan\n",
      "Epoch: 159 \t\tLoss: nan\n",
      "Epoch: 160 \t\tLoss: nan\n",
      "Epoch: 161 \t\tLoss: nan\n",
      "Epoch: 162 \t\tLoss: nan\n",
      "Epoch: 163 \t\tLoss: nan\n",
      "Epoch: 164 \t\tLoss: nan\n",
      "Epoch: 165 \t\tLoss: nan\n",
      "Epoch: 166 \t\tLoss: nan\n",
      "Epoch: 167 \t\tLoss: nan\n",
      "Epoch: 168 \t\tLoss: nan\n",
      "Epoch: 169 \t\tLoss: nan\n",
      "Epoch: 170 \t\tLoss: nan\n",
      "Epoch: 171 \t\tLoss: nan\n",
      "Epoch: 172 \t\tLoss: nan\n",
      "Epoch: 173 \t\tLoss: nan\n",
      "Epoch: 174 \t\tLoss: nan\n",
      "Epoch: 175 \t\tLoss: nan\n",
      "Epoch: 176 \t\tLoss: nan\n",
      "Epoch: 177 \t\tLoss: nan\n",
      "Epoch: 178 \t\tLoss: nan\n",
      "Epoch: 179 \t\tLoss: nan\n",
      "Epoch: 180 \t\tLoss: nan\n",
      "Epoch: 181 \t\tLoss: nan\n",
      "Epoch: 182 \t\tLoss: nan\n",
      "Epoch: 183 \t\tLoss: nan\n",
      "Epoch: 184 \t\tLoss: nan\n",
      "Epoch: 185 \t\tLoss: nan\n",
      "Epoch: 186 \t\tLoss: nan\n",
      "Epoch: 187 \t\tLoss: nan\n",
      "Epoch: 188 \t\tLoss: nan\n",
      "Epoch: 189 \t\tLoss: nan\n",
      "Epoch: 190 \t\tLoss: nan\n",
      "Epoch: 191 \t\tLoss: nan\n",
      "Epoch: 192 \t\tLoss: nan\n",
      "Epoch: 193 \t\tLoss: nan\n",
      "Epoch: 194 \t\tLoss: nan\n",
      "Epoch: 195 \t\tLoss: nan\n",
      "Epoch: 196 \t\tLoss: nan\n",
      "Epoch: 197 \t\tLoss: nan\n",
      "Epoch: 198 \t\tLoss: nan\n",
      "Epoch: 199 \t\tLoss: nan\n",
      "Epoch: 200 \t\tLoss: nan\n",
      "Epoch: 201 \t\tLoss: nan\n",
      "Epoch: 202 \t\tLoss: nan\n",
      "Epoch: 203 \t\tLoss: nan\n",
      "Epoch: 204 \t\tLoss: nan\n",
      "Epoch: 205 \t\tLoss: nan\n",
      "Epoch: 206 \t\tLoss: nan\n",
      "Epoch: 207 \t\tLoss: nan\n",
      "Epoch: 208 \t\tLoss: nan\n",
      "Epoch: 209 \t\tLoss: nan\n",
      "Epoch: 210 \t\tLoss: nan\n",
      "Epoch: 211 \t\tLoss: nan\n",
      "Epoch: 212 \t\tLoss: nan\n",
      "Epoch: 213 \t\tLoss: nan\n",
      "Epoch: 214 \t\tLoss: nan\n",
      "Epoch: 215 \t\tLoss: nan\n",
      "Epoch: 216 \t\tLoss: nan\n",
      "Epoch: 217 \t\tLoss: nan\n",
      "Epoch: 218 \t\tLoss: nan\n",
      "Epoch: 219 \t\tLoss: nan\n",
      "Epoch: 220 \t\tLoss: nan\n",
      "Epoch: 221 \t\tLoss: nan\n",
      "Epoch: 222 \t\tLoss: nan\n",
      "Epoch: 223 \t\tLoss: nan\n",
      "Epoch: 224 \t\tLoss: nan\n",
      "Epoch: 225 \t\tLoss: nan\n",
      "Epoch: 226 \t\tLoss: nan\n",
      "Epoch: 227 \t\tLoss: nan\n",
      "Epoch: 228 \t\tLoss: nan\n",
      "Epoch: 229 \t\tLoss: nan\n",
      "Epoch: 230 \t\tLoss: nan\n",
      "Epoch: 231 \t\tLoss: nan\n",
      "Epoch: 232 \t\tLoss: nan\n",
      "Epoch: 233 \t\tLoss: nan\n",
      "Epoch: 234 \t\tLoss: nan\n",
      "Epoch: 235 \t\tLoss: nan\n",
      "Epoch: 236 \t\tLoss: nan\n",
      "Epoch: 237 \t\tLoss: nan\n",
      "Epoch: 238 \t\tLoss: nan\n",
      "Epoch: 239 \t\tLoss: nan\n",
      "Epoch: 240 \t\tLoss: nan\n",
      "Epoch: 241 \t\tLoss: nan\n",
      "Epoch: 242 \t\tLoss: nan\n",
      "Epoch: 243 \t\tLoss: nan\n",
      "Epoch: 244 \t\tLoss: nan\n",
      "Epoch: 245 \t\tLoss: nan\n",
      "Epoch: 246 \t\tLoss: nan\n",
      "Epoch: 247 \t\tLoss: nan\n",
      "Epoch: 248 \t\tLoss: nan\n",
      "Epoch: 249 \t\tLoss: nan\n",
      "Epoch: 250 \t\tLoss: nan\n",
      "Epoch: 251 \t\tLoss: nan\n",
      "Epoch: 252 \t\tLoss: nan\n",
      "Epoch: 253 \t\tLoss: nan\n",
      "Epoch: 254 \t\tLoss: nan\n",
      "Epoch: 255 \t\tLoss: nan\n",
      "Epoch: 256 \t\tLoss: nan\n",
      "Epoch: 257 \t\tLoss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# synthetic data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_play(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, actions\u001b[38;5;241m=\u001b[39mk_2actions, policy_fn\u001b[38;5;241m=\u001b[39mpolicy_fn_2, value_fn\u001b[38;5;241m=\u001b[39mvalue_fn_2, \n\u001b[1;32m      3\u001b[0m            optimizers\u001b[38;5;241m=\u001b[39m[value_optim, policy_optim], rand_start_state_fn\u001b[38;5;241m=\u001b[39mgen_start_state_2a, comp_limit\u001b[38;5;241m=\u001b[39madaptive_comp_limit)\n",
      "Cell \u001b[0;32mIn[6], line 77\u001b[0m, in \u001b[0;36mtrain_play\u001b[0;34m(epochs, actions, policy_fn, value_fn, optimizers, rand_start_state_fn, comp_limit, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m policy \u001b[38;5;241m=\u001b[39m policy_fn(start)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m start_node \u001b[38;5;241m=\u001b[39m Node(\u001b[38;5;28;01mNone\u001b[39;00m, start, \u001b[38;5;28mlen\u001b[39m(actions), value, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m mcts\u001b[38;5;241m.\u001b[39mrun(start_node, comp_limit\u001b[38;5;241m=\u001b[39mk_comp_limit, max_threads\u001b[38;5;241m=\u001b[39mk_thread_count_limit)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# get attributes of game just played\u001b[39;00m\n\u001b[1;32m     81\u001b[0m v_out \u001b[38;5;241m=\u001b[39m start_node\u001b[38;5;241m.\u001b[39msubtree_value\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[3], line 159\u001b[0m, in \u001b[0;36mMCTS.run\u001b[0;34m(self, root, comp_limit, max_threads)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# spawn new thread for each computation\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_threads) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 159\u001b[0m     executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplore_once, \u001b[38;5;28mrange\u001b[39m(comp_limit))\n\u001b[1;32m    161\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpick_child(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/nogil-3.9.10-1/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/nogil-3.9.10-1/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/.pyenv/versions/nogil-3.9.10-1/lib/python3.9/threading.py:989\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# historically negative timeout values behave like 0.\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# synthetic data\n",
    "train_play(epochs=500, actions=k_2actions, policy_fn=policy_fn_2, value_fn=value_fn_2, \n",
    "           optimizers=[value_optim, policy_optim], rand_start_state_fn=gen_start_state_2a, comp_limit=adaptive_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df2ff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(value_fn_2.state_dict(), \"trained_weights/deep_mcts_2_v_weights.pth\")\n",
    "    torch.save(policy_fn_2.state_dict(), \"trained_weights/deep_mcts_2_p_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f7b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_state_upper_lim = 30 # arbitrary\n",
    "k_comp_limit = int(k_state_upper_lim ** (7/2))\n",
    "value_fn_4 = ValueNN(2).to(device)\n",
    "policy_fn_4 = PolicyNN(2,len(k_4actions)).to(device)\n",
    "value_optim_4 = optim.Adam(value_fn_4.parameters(), lr=0.00005)\n",
    "policy_optim_4 = optim.Adam(policy_fn_4.parameters(), lr=0.000005)\n",
    "\n",
    "def gen_start_state_4a():\n",
    "    limit = k_state_upper_lim\n",
    "    return torch.round( (torch.rand((1, 2)) - 0.5) * 2 * limit).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2b8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t\tLoss: 2.1033401489257812\n",
      "Epoch: 20 \t\tLoss: 1.556889295578003\n",
      "Epoch: 30 \t\tLoss: 1.3582837581634521\n",
      "Epoch: 40 \t\tLoss: 1.4088467359542847\n",
      "Epoch: 50 \t\tLoss: 1.436020016670227\n",
      "Epoch: 60 \t\tLoss: 1.379128336906433\n",
      "Epoch: 70 \t\tLoss: 1.4841262102127075\n",
      "Epoch: 80 \t\tLoss: 1.3614771366119385\n",
      "Epoch: 90 \t\tLoss: 1.3785827159881592\n",
      "Epoch: 100 \t\tLoss: 1.3600499629974365\n",
      "Epoch: 110 \t\tLoss: 1.389901041984558\n",
      "Epoch: 120 \t\tLoss: 1.383531928062439\n",
      "Epoch: 130 \t\tLoss: 1.3663393259048462\n",
      "Epoch: 140 \t\tLoss: 1.3774583339691162\n",
      "Epoch: 150 \t\tLoss: 1.2760998010635376\n",
      "Epoch: 160 \t\tLoss: 1.3536250591278076\n",
      "Epoch: 170 \t\tLoss: 1.3584808111190796\n",
      "Epoch: 180 \t\tLoss: 1.3749842643737793\n",
      "Epoch: 190 \t\tLoss: 1.3323438167572021\n",
      "Epoch: 200 \t\tLoss: 1.3520457744598389\n",
      "Epoch: 210 \t\tLoss: 1.310624599456787\n",
      "Epoch: 220 \t\tLoss: 1.3285794258117676\n",
      "Epoch: 230 \t\tLoss: 1.3432512283325195\n",
      "Epoch: 240 \t\tLoss: 1.3051739931106567\n",
      "Epoch: 250 \t\tLoss: 1.3170291185379028\n"
     ]
    }
   ],
   "source": [
    "train_sv(250, k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4,policy_optim_4], fname='train_data/train_mcts.csv', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e933c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_policy_fp = \"start_weights/deep_mcts_4_p_weights.pth\"\n",
    "init_value_fp = \"start_weights/deep_mcts_4_v_weights.pth\"\n",
    "trained_policy_fp = \"trained_weights/deep_mcts_4_p_weights_f.pth\"\n",
    "trained_value_fp = \"trained_weights/deep_mcts_4_v_weights_f.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    torch.save(value_fn_4.state_dict(), init_value_fp)\n",
    "    torch.save(policy_fn_4.state_dict(), init_policy_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6fc7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_3944/2326664682.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.967\n",
      "Guess Distribution: [1086, 914]\n"
     ]
    }
   ],
   "source": [
    "train_play(epochs=100, actions=k_4actions, policy_fn=policy_fn_4, value_fn=value_fn_4, optimizers=[value_optim_4, policy_optim_4], rand_start_state_fn=gen_start_state_4a, comp_limit=k_comp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcbd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained weights\n",
    "\n",
    "\n",
    "# value_fn_4.load_state_dict(torch.load(trained_value_fp))\n",
    "# policy_fn_4.load_state_dict(torch.load(trained_policy_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c191e6c845a0bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:47:31.912513Z",
     "start_time": "2023-11-06T02:47:31.904073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test_data(fname):\n",
    "    x = torch.tensor(np.loadtxt(fname, delimiter=\",\"), dtype=torch.float)\n",
    "    return x[:,:-1], x[:,-1]\n",
    "\n",
    "def plot_db(policy_fn, actions, ranges):\n",
    "    X = ranges[0]\n",
    "    Y = ranges[1]\n",
    "    action_plot = []\n",
    "    for i in actions:\n",
    "        action_plot.append([])\n",
    "    for i in X:\n",
    "        for j in Y:\n",
    "            rv = policy_fn(torch.tensor([i,j],dtype=torch.float).unsqueeze(0)).flatten().to(device)\n",
    "            action_plot[torch.argmax(rv)].append((i.cpu(),j.cpu()))\n",
    "    for i in range(len(action_plot)):\n",
    "        action = np.array(action_plot[i])\n",
    "        plt.scatter(action[:,0], action[:,1], color=(\"C\"+str(i)), label=action)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1368c1aa3c071299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:48:10.179905Z",
     "start_time": "2023-11-06T02:48:10.175988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x, y, policy_fn, actions=k_2actions, dbs=None):\n",
    "    correct = 0\n",
    "    guess_dist = [0] * len(actions)\n",
    "    for i in range(len(x)):\n",
    "        state = torch.tensor(x[i]).unsqueeze(0).to(device)\n",
    "        rv = policy_fn(state).flatten()                      # take the move distribution given by NN\n",
    "\n",
    "        # todo pick one way to select\n",
    "        # rv = rv.multinomial(num_samples=1, replacement=True)    # sample from the move distribution\n",
    "        rv = torch.argmax(rv)\n",
    "\n",
    "        if rv == y[i]:\n",
    "            correct += 1\n",
    "        guess_dist[rv] += 1\n",
    "    # todo fix\n",
    "    if dbs is not None:\n",
    "        # graphing decision boundary\n",
    "        plot_db(policy_fn, actions, ranges=dbs)\n",
    "    return correct / len(x), guess_dist\n",
    "\n",
    "\n",
    "def run_test(data_name, actions, policy_fn, cases=100, dbs=None):\n",
    "    test_X, test_Y = get_test_data(data_name)\n",
    "    test_X = test_X.to(device)\n",
    "    test_Y.reshape(-1, 1)\n",
    "    test_Y = test_Y.to(device)\n",
    "\n",
    "    acc, guesses = test(x=test_X[:cases], y=test_Y[:cases],\n",
    "                        policy_fn=policy_fn, actions=actions, dbs=dbs)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Guess Distribution:\", guesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caa3d0f193cdda2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_14595/450618715.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4895\n",
      "Guess Distribution: [1, 1999]\n"
     ]
    }
   ],
   "source": [
    "k_cases = 2000\n",
    "k_dbound_size = 100\n",
    "\n",
    "dual_file = \"test_data/test_simple.csv\"\n",
    "\n",
    "db2 = torch.linspace(2, k_dbound_size, k_dbound_size - 1).to(device)\n",
    "two_dbs = [db2, db2]\n",
    "\n",
    "run_test(dual_file, k_2actions, policy_fn=policy_fn_2, cases=k_cases, dbs=two_dbs)\n",
    "# ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77fce074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_fn_2(gen_start_state_2a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb7c4b36c7d9707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.261\n",
      "Guess Distribution: [1000, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/gxb6q8zj21dff090q066td740000gn/T/ipykernel_8108/450618715.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(x[i]).unsqueeze(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "quad_file = \"test_data/four_directions_cleaner_test.csv\"     # thanks, donald\n",
    "\n",
    "k_cases = 1000\n",
    "\n",
    "k_dbound_size = 200\n",
    "\n",
    "db4 = torch.linspace(-k_dbound_size/2, k_dbound_size/2, k_dbound_size+1).to(device)\n",
    "quad_dbs = [db4, db4]\n",
    "run_test(quad_file, k_4actions, policy_fn=lambda a: torch.argmax(value_fn_4(a)), cases=k_cases)\n",
    "            \n",
    "# run_test(quad_file, k_4actions, policy_fn=lambda a: oh_encode(torch.tensor(determine_action(a.flatten())).view((1,1)),4), cases=k_cases, dbs=quad_dbs)\n",
    "# # 8% accuracy on Donald test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c81ea1aa8fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
