{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:05.061044Z",
     "start_time": "2023-09-22T01:34:04.997802Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#data_generator\n",
    "matrix_T = torch.tensor([[0, 1], [1, 0]], dtype=torch.float64)\n",
    "matrix_U = torch.tensor([[1, -1], [0, 1]], dtype=torch.float64)\n",
    "\n",
    "inverse_T = torch.inverse(matrix_T)\n",
    "inverse_U = torch.inverse(matrix_U)\n",
    "\n",
    "max_moves = 30  #how many inverse operations on the final destination\n",
    "goal_position = torch.tensor([[1], [0]], dtype=torch.float64)\n",
    "\n",
    "\n",
    "def data_generator(num_of_datapoints):\n",
    "    data = torch.empty((num_of_datapoints, 3), dtype=torch.float64)\n",
    "    for i in range(num_of_datapoints):\n",
    "        start = goal_position\n",
    "        moves = random.randint(1, max_moves)\n",
    "        coin = 3\n",
    "        for q in range(moves):\n",
    "            coin = random.randint(0, 1)\n",
    "            if coin == 1:\n",
    "                #  print(start, inverse_U, \"=\")\n",
    "                start = torch.matmul(inverse_U, start)\n",
    "            #  print(start)\n",
    "            else:\n",
    "                #  print(start, inverse_T, \"=\")\n",
    "                start = torch.matmul(inverse_T, start)\n",
    "                if q != moves - 1:\n",
    "                    start = torch.matmul(inverse_U, start)\n",
    "            # print(start)\n",
    "        # print(\"done\")\n",
    "        data[i, 0] = start[0]\n",
    "        data[i, 1] = start[1]\n",
    "        data[i, 2] = coin\n",
    "    return data\n",
    "\n",
    "#https://stackoverflow.com/questions/36158058/torch-save-tensor-to-csv-file#:~:text=For%20simple%20tables%2C%20you%20can,then%20to%20a%20Pandas%20dataframe.&text=You%20can%20first%20convert%20the,table%20as%20a%20csv%20file.\n",
    "data = data_generator(20000)\n",
    "data_table = data.numpy()\n",
    "df = pd.DataFrame(data_table)\n",
    "df.to_csv(\"generated_pairs.csv\", index = False) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.624595Z",
     "start_time": "2023-09-22T01:34:05.015478Z"
    }
   },
   "id": "1346d52537c24612"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.632110Z",
     "start_time": "2023-09-22T01:34:06.625329Z"
    }
   },
   "id": "8f208516537858f3"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "#https://stackoverflow.com/questions/12336234/read-csv-file-to-numpy-array-first-row-as-strings-rest-as-float\n",
    "#https://www.w3schools.com/python/numpy/numpy_array_join.asp#:~:text=Joining%20Arrays%20Using%20Stack%20Functions&text=We%20can%20concatenate%20two%201,it%20is%20taken%20as%200.\n",
    "\n",
    "#make tensors from csv file\n",
    "\n",
    "#from cs544 notes \n",
    "data = pd.read_csv(\"generated_pairs.csv\", names=[\"0\",\"1\",\"2\"], delimiter=\",\")\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(data.loc[:, \"0\":\"1\"].values), # input \n",
    "    torch.tensor(data.loc[:, [\"2\"]].values) #output \n",
    ")\n",
    "X, Y = dataset[:] #label input and output \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.642059Z",
     "start_time": "2023-09-22T01:34:06.629881Z"
    }
   },
   "id": "d43704376b86b083"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.654048Z",
     "start_time": "2023-09-22T01:34:06.643619Z"
    }
   },
   "id": "b677c06c3dfca538"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "#making the model \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 128), #first layer 128\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64), #second layer 64\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16), #third layer 16\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,1), #singular output \n",
    "    nn.Sigmoid()\n",
    ")\n",
    "#print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.654694Z",
     "start_time": "2023-09-22T01:34:06.648506Z"
    }
   },
   "id": "440f35f13e70e8dd"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "#prep for training \n",
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "#prep for training \n",
    "loss_function = nn.BCELoss() #should this be our loss function too? \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001) #chose Adam and lr from site \n",
    "\n",
    "#split training and testing data \n",
    "train, test = torch.utils.data.random_split(dataset, [0.75, 0.25]) #from cs544 class notes \n",
    "X_train, Y_train = train[:]\n",
    "X_train = torch.Tensor.numpy(X_train)\n",
    "Y_train = torch.Tensor.numpy(Y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.663578Z",
     "start_time": "2023-09-22T01:34:06.654915Z"
    }
   },
   "id": "498991db8aae3dd7"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "batch_s = 10 #batch size \n",
    "epoch_s = 100 #epoch size \n",
    "dl = torch.utils.data.DataLoader(train, batch_size = batch_s, shuffle = True) #from cs544 notes \n",
    "dl_test = torch.utils.data.DataLoader(test, batch_size = batch_s, shuffle = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:06.671348Z",
     "start_time": "2023-09-22T01:34:06.665641Z"
    }
   },
   "id": "aa6b1da1a02ead25"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.0\n",
      "Finished epoch 1, latest loss 0.0\n",
      "Finished epoch 2, latest loss 0.0\n",
      "Finished epoch 3, latest loss 0.0\n",
      "Finished epoch 4, latest loss 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m Y_batch \u001B[38;5;241m=\u001B[39m Y_train[i:i\u001B[38;5;241m+\u001B[39mbatch_s]\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# print(Y_batch)\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mY_batch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:619\u001B[0m, in \u001B[0;36mBCELoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 619\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/functional.py:3098\u001B[0m, in \u001B[0;36mbinary_cross_entropy\u001B[0;34m(input, target, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   3095\u001B[0m     new_size \u001B[38;5;241m=\u001B[39m _infer_size(target\u001B[38;5;241m.\u001B[39msize(), weight\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m   3096\u001B[0m     weight \u001B[38;5;241m=\u001B[39m weight\u001B[38;5;241m.\u001B[39mexpand(new_size)\n\u001B[0;32m-> 3098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction_enum\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "for epoch in range(epoch_s):\n",
    "    for i in range(0, len(X_train), batch_s):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch = X_train[i:i+batch_s]\n",
    "        # print(X_batch)\n",
    "        y_pred = model(torch.Tensor(X_batch))\n",
    "        Y_batch = Y_train[i:i+batch_s]\n",
    "        # print(Y_batch)\n",
    "        loss = loss_function(y_pred, torch.Tensor(Y_batch))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:34:14.264522Z",
     "start_time": "2023-09-22T01:34:06.672074Z"
    }
   },
   "id": "28b6554053a36fd1"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def euclidean_algorithm(given_pair): \n",
    "    # a = pair[0,0]\n",
    "    # print(a)\n",
    "    # b = pair[0,1]\n",
    "    # print(b)\n",
    "    a = given_pair[0]\n",
    "    b = given_pair[1]\n",
    "    i = 0 #indexing for circle size \n",
    "    plt.plot(a.detach(), b.detach(), \"bo\", markersize = 3 + i)\n",
    "    while a != 0 or b != 0: \n",
    "        pred = model(torch.tensor([[a,b]]))\n",
    "        if abs(1-pred) < abs(pred): # if prediciton is closer to 1 \n",
    "            pair = torch.matmul(pair, matrix_U)\n",
    "        else: \n",
    "            pair = torch.matmul(pair, matrix_T)\n",
    "        a = pair[0,0]\n",
    "        b = pair[0,1]\n",
    "        i = i + 1 \n",
    "        plt.plot(a.detach(), b.detach(), \"ro\", markersize = 3+i) #from cs544 notes \n",
    "    if a == 0: \n",
    "        return b\n",
    "    else: \n",
    "        return a "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:39:13.063491Z",
     "start_time": "2023-09-22T01:39:13.055080Z"
    }
   },
   "id": "5c09eeef1adade01"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m pair \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m7\u001B[39m,\u001B[38;5;241m4\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43meuclidean_algorithm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpair\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[42], line 11\u001B[0m, in \u001B[0;36meuclidean_algorithm\u001B[0;34m(given_pair)\u001B[0m\n\u001B[1;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(a\u001B[38;5;241m.\u001B[39mdetach(), b\u001B[38;5;241m.\u001B[39mdetach(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbo\u001B[39m\u001B[38;5;124m\"\u001B[39m, markersize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;241m+\u001B[39m i)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m a \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m b \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m: \n\u001B[0;32m---> 11\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43mb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mpred) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mabs\u001B[39m(pred): \u001B[38;5;66;03m# if prediciton is closer to 1 \u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/MXM_practice/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 must have the same dtype"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAru0lEQVR4nO3de3BUZZ7/8U8nkU4kSRsw5kYEA0jkEm7RTCv8qJJoRCYLs4yrMWMQGR1dxkIZRaKBwHjprCALLIqIMl6ADeoItdZgMpgyuo4xQCAzCF4A0YRclVrSEIZGk/P7g7KdHhKkc30S3q+qp6Cf/p7T3+dUoD91+uS0zbIsSwAAAAYL6O4GAAAAfgqBBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgvKDubqAjNDc3q7q6WmFhYbLZbN3dDgAAOA+WZen48eOKjY1VQMC5z6H0isBSXV2t+Pj47m4DAAC0QWVlpQYMGHDOml4RWMLCwiSdWXB4eHg3dwMAAM6H2+1WfHy89338XHpFYPnhY6Dw8HACCwAAPcz5XM7BRbcAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHjtCix5eXmy2Wx64IEHWq1Zt26dJk6cqIiICEVERCg1NVU7duzwqbEsS4sWLVJMTIxCQkKUmpqqAwcOtKc1AADQi7Q5sOzcuVNr165VUlLSOeuKi4uVkZGh9957TyUlJYqPj9eNN96oqqoqb83TTz+tVatW6fnnn1dpaan69u2rtLQ0nTp1qq3tAQCAXqRNgeXEiRPKzMzUunXrFBERcc7ajRs36t///d81ZswYJSYm6sUXX1Rzc7OKiooknTm7smLFCuXk5GjatGlKSkrSq6++qurqam3durUt7QEAgF6mTYFlzpw5mjp1qlJTU/3e9uTJk/ruu+/Ur18/SdLhw4dVW1vrsy+Hw6GUlBSVlJS0uA+PxyO32+0zAABA7+X3tzXn5+dr9+7d2rlzZ5te8JFHHlFsbKw3oNTW1kqSoqKifOqioqK8z/0zl8ulJUuWtOn1AQBAz+PXGZbKykrNnTtXGzduVHBwsN8vlpeXp/z8fG3ZsqVN2/8gOztbDQ0N3lFZWdnmfQEAAPP5dYalrKxM9fX1GjdunHeuqalJH3zwgVavXi2Px6PAwMAWt122bJny8vL07rvv+lyoGx0dLUmqq6tTTEyMd76urk5jxoxpcV92u112u92f1gEAQA/m1xmWyZMna+/evSovL/eO5ORkZWZmqry8vNWw8vTTT+vxxx9XQUGBkpOTfZ674oorFB0d7b0IV5LcbrdKS0vldDrbsCQAANDb+HWGJSwsTCNHjvSZ69u3r/r37++dz8rKUlxcnFwulyTpP/7jP7Ro0SJt2rRJgwYN8l6XEhoaqtDQUO99XJ544gkNHTpUV1xxhRYuXKjY2FhNnz69A5YIAAB6Or8vuv0pFRUVCgj48cTNmjVrdPr0af3yl7/0qcvNzdXixYslSfPnz1djY6PuueceHTt2TBMmTFBBQUG7rnMBAAC9h82yLKu7m2gvt9sth8OhhoYGhYeHd3c7AADgPPjz/s13CQEAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjNeuwJKXlyebzaYHHnig1Zp9+/ZpxowZGjRokGw2m1asWHFWzeLFi2Wz2XxGYmJie1oDAAC9SFBbN9y5c6fWrl2rpKSkc9adPHlSCQkJuuWWW/Tggw+2WjdixAi9++67PzYW1ObWAABAL9OmMywnTpxQZmam1q1bp4iIiHPWXn311Vq6dKluu+022e32VuuCgoIUHR3tHZdeemlbWgMAAL1QmwLLnDlzNHXqVKWmpnZYIwcOHFBsbKwSEhKUmZmpioqKVms9Ho/cbrfPAAAAvZffgSU/P1+7d++Wy+XqsCZSUlL08ssvq6CgQGvWrNHhw4c1ceJEHT9+vMV6l8slh8PhHfHx8R3WCwAAMI9fgaWyslJz587Vxo0bFRwc3GFNTJkyRbfccouSkpKUlpambdu26dixY3r99ddbrM/OzlZDQ4N3VFZWdlgvAADAPH5d2VpWVqb6+nqNGzfOO9fU1KQPPvhAq1evlsfjUWBgYLubuuSSS3TllVfq4MGDLT5vt9vPeT0MAADoXfwKLJMnT9bevXt95mbNmqXExEQ98sgjHRJWpDMX9R46dEh33HFHh+wPAAD0bH4FlrCwMI0cOdJnrm/fvurfv793PisrS3Fxcd5rXE6fPq39+/d7/15VVaXy8nKFhoZqyJAhkqSHHnpI6enpGjhwoKqrq5Wbm6vAwEBlZGS0e4EAAKDn6/CbnVRUVCgg4MdLY6qrqzV27Fjv42XLlmnZsmWaNGmSiouLJUlHjhxRRkaGjh49qsjISE2YMEEff/yxIiMjO7o9AADQA9ksy7K6u4n2crvdcjgcamhoUHh4eHe3AwAAzoM/7998lxAAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHjtCix5eXmy2Wx64IEHWq3Zt2+fZsyYoUGDBslms2nFihUt1j377LMaNGiQgoODlZKSoh07drSnNQAA0Iu0ObDs3LlTa9euVVJS0jnrTp48qYSEBOXl5Sk6OrrFms2bN2vevHnKzc3V7t27NXr0aKWlpam+vr6t7QEAgF6kTYHlxIkTyszM1Lp16xQREXHO2quvvlpLly7VbbfdJrvd3mLN8uXLdffdd2vWrFkaPny4nn/+eV188cVav359W9oDAAC9TJsCy5w5czR16lSlpqa2u4HTp0+rrKzMZ18BAQFKTU1VSUlJi9t4PB653W6fAQAAei+/A0t+fr52794tl8vVIQ18++23ampqUlRUlM98VFSUamtrW9zG5XLJ4XB4R3x8fIf0AgAAzORXYKmsrNTcuXO1ceNGBQcHd1ZPPyk7O1sNDQ3eUVlZ2W29AACAzhfkT3FZWZnq6+s1btw471xTU5M++OADrV69Wh6PR4GBgX41cOmllyowMFB1dXU+83V1da1epGu321u9HgYAAPQ+fp1hmTx5svbu3avy8nLvSE5OVmZmpsrLy/0OK5LUp08fjR8/XkVFRd655uZmFRUVyel0+r0/AADQ+/h1hiUsLEwjR470mevbt6/69+/vnc/KylJcXJz3GpfTp09r//793r9XVVWpvLxcoaGhGjJkiCRp3rx5mjlzppKTk3XNNddoxYoVamxs1KxZs9q9QAAA0PP5FVjOR0VFhQICfjxxU11drbFjx3ofL1u2TMuWLdOkSZNUXFwsSbr11lv1zTffaNGiRaqtrdWYMWNUUFBw1oW4AADgwmSzLMvq7ibay+12y+FwqKGhQeHh4d3dDgAAOA/+vH/zXUIAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOO1K7Dk5eXJZrPpgQceOGfdG2+8ocTERAUHB2vUqFHatm2bz/N33nmnbDabz7jpppva0xoAAOhF2hxYdu7cqbVr1yopKemcdR999JEyMjI0e/Zs7dmzR9OnT9f06dP1ySef+NTddNNNqqmp8Y7//u//bmtrAACgl2lTYDlx4oQyMzO1bt06RUREnLN25cqVuummm/Twww/rqquu0uOPP65x48Zp9erVPnV2u13R0dHe8VP7BQAAF442BZY5c+Zo6tSpSk1N/cnakpKSs+rS0tJUUlLiM1dcXKzLLrtMw4YN03333aejR4+2uk+PxyO32+0zAABA7xXk7wb5+fnavXu3du7ceV71tbW1ioqK8pmLiopSbW2t9/FNN92kf/3Xf9UVV1yhQ4cO6dFHH9WUKVNUUlKiwMDAs/bpcrm0ZMkSf1sHAAA9lF+BpbKyUnPnztX27dsVHBzcYU3cdttt3r+PGjVKSUlJGjx4sIqLizV58uSz6rOzszVv3jzvY7fbrfj4+A7rBwAAmMWvj4TKyspUX1+vcePGKSgoSEFBQXr//fe1atUqBQUFqamp6axtoqOjVVdX5zNXV1en6OjoVl8nISFBl156qQ4ePNji83a7XeHh4T4DAAD0Xn4FlsmTJ2vv3r0qLy/3juTkZGVmZqq8vLzFj2+cTqeKiop85rZv3y6n09nq6xw5ckRHjx5VTEyMP+0BAIBeyq+PhMLCwjRy5Eifub59+6p///7e+aysLMXFxcnlckmS5s6dq0mTJumZZ57R1KlTlZ+fr127dumFF16QdOY3jpYsWaIZM2YoOjpahw4d0vz58zVkyBClpaV1xBoBAEAP1+F3uq2oqFBNTY338bXXXqtNmzbphRde0OjRo/Xmm29q69at3oATGBiov/3tb/qXf/kXXXnllZo9e7bGjx+v//3f/5Xdbu/o9gAAQA9ksyzL6u4m2svtdsvhcKihoYHrWQAA6CH8ef/mu4QAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMZrV2DJy8uTzWbTAw88cM66N954Q4mJiQoODtaoUaO0bds2n+cty9KiRYsUExOjkJAQpaam6sCBA+1pDQAA9CJtDiw7d+7U2rVrlZSUdM66jz76SBkZGZo9e7b27Nmj6dOna/r06frkk0+8NU8//bRWrVql559/XqWlperbt6/S0tJ06tSptrYHoJc4ckR6770zfwK4cLUpsJw4cUKZmZlat26dIiIizlm7cuVK3XTTTXr44Yd11VVX6fHHH9e4ceO0evVqSWfOrqxYsUI5OTmaNm2akpKS9Oqrr6q6ulpbt25tS3sAeomXXpIGDpSuv/7Mny+91N0dAegubQosc+bM0dSpU5WamvqTtSUlJWfVpaWlqaSkRJJ0+PBh1dbW+tQ4HA6lpKR4a/6Zx+OR2+32GQB6lyNHpHvukZqbzzxubpZ+8xvOtAAXKr8DS35+vnbv3i2Xy3Ve9bW1tYqKivKZi4qKUm1trff5H+Zaq/lnLpdLDofDO+Lj4/1dBgDDHTjwY1j5QVOTdPBg9/QDoHv5FVgqKys1d+5cbdy4UcHBwZ3V00/Kzs5WQ0ODd1RWVnZbLwA6x9ChUsA//Q8VGCgNGdI9/QDoXn4FlrKyMtXX12vcuHEKCgpSUFCQ3n//fa1atUpBQUFqamo6a5vo6GjV1dX5zNXV1Sk6Otr7/A9zrdX8M7vdrvDwcJ8BoHcZMEB64YUzIUU68+fatWfmAVx4/AoskydP1t69e1VeXu4dycnJyszMVHl5uQJ/+J/lHzidThUVFfnMbd++XU6nU5J0xRVXKDo62qfG7XartLTUWwPgwjR7tvTVV2d+S+irr848BnBhCvKnOCwsTCNHjvSZ69u3r/r37++dz8rKUlxcnPcal7lz52rSpEl65plnNHXqVOXn52vXrl164YUXJMl7H5cnnnhCQ4cO1RVXXKGFCxcqNjZW06dP74AlAujJBgzgrAoAPwPL+aioqFDAP3zwfO2112rTpk3KycnRo48+qqFDh2rr1q0+wWf+/PlqbGzUPffco2PHjmnChAkqKCjo1utkAACAOWyWZVnd3UR7ud1uORwONTQ0cD0LAAA9hD/v33yXEAAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeH4FljVr1igpKUnh4eEKDw+X0+nUO++802r9d999p9///vcaPHiwgoODNXr0aBUUFPjULF68WDabzWckJia2bTUAAKBXCvKneMCAAcrLy9PQoUNlWZZeeeUVTZs2TXv27NGIESPOqs/JydGGDRu0bt06JSYmqrCwUL/4xS/00UcfaezYsd66ESNG6N133/2xqSC/2gIAAL2czbIsqz076Nevn5YuXarZs2ef9VxsbKwee+wxzZkzxzs3Y8YMhYSEaMOGDZLOnGHZunWrysvL29yD2+2Ww+FQQ0ODwsPD27wfAADQdfx5/27zNSxNTU3Kz89XY2OjnE5nizUej0fBwcE+cyEhIfrwww995g4cOKDY2FglJCQoMzNTFRUV53xtj8cjt9vtMwAAQO/ld2DZu3evQkNDZbfbde+992rLli0aPnx4i7VpaWlavny5Dhw4oObmZm3fvl1vvfWWampqvDUpKSl6+eWXVVBQoDVr1ujw4cOaOHGijh8/3moPLpdLDofDO+Lj4/1dBgAA6EH8/kjo9OnTqqioUENDg9588029+OKLev/991sMLd98843uvvtuvf3227LZbBo8eLBSU1O1fv16/f3vf29x/8eOHdPAgQO1fPnyFj9mks6cYfF4PN7Hbrdb8fHxfCQEAEAP0qkfCfXp00dDhgzR+PHj5XK5NHr0aK1cubLF2sjISG3dulWNjY36+uuv9dlnnyk0NFQJCQmt7v+SSy7RlVdeqYMHD7ZaY7fbvb+p9MMAAAC9V7vvw9Lc3OxztqMlwcHBiouL0/fff68//vGPmjZtWqu1J06c0KFDhxQTE9Pe1gAAQC/h1+8PZ2dna8qUKbr88st1/Phxbdq0ScXFxSosLJQkZWVlKS4uTi6XS5JUWlqqqqoqjRkzRlVVVVq8eLGam5s1f/587z4feughpaena+DAgaqurlZubq4CAwOVkZHRgcsEAAA9mV+Bpb6+XllZWaqpqZHD4VBSUpIKCwt1ww03SJIqKioUEPDjSZtTp04pJydHX375pUJDQ3XzzTfrtdde0yWXXOKtOXLkiDIyMnT06FFFRkZqwoQJ+vjjjxUZGdkxKwQAAD1eu+/DYgLuwwIAQM/TJfdhAQAA6CoEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4/kVWNasWaOkpCSFh4crPDxcTqdT77zzTqv13333nX7/+99r8ODBCg4O1ujRo1VQUHBW3bPPPqtBgwYpODhYKSkp2rFjh/8rAQAAvZZfgWXAgAHKy8tTWVmZdu3apeuvv17Tpk3Tvn37WqzPycnR2rVr9V//9V/av3+/7r33Xv3iF7/Qnj17vDWbN2/WvHnzlJubq927d2v06NFKS0tTfX19+1YGAAB6DZtlWVZ7dtCvXz8tXbpUs2fPPuu52NhYPfbYY5ozZ453bsaMGQoJCdGGDRskSSkpKbr66qu1evVqSVJzc7Pi4+N1//33a8GCBefVg9vtlsPhUENDg8LDw9uzHAAA0EX8ef9u8zUsTU1Nys/PV2Njo5xOZ4s1Ho9HwcHBPnMhISH68MMPJUmnT59WWVmZUlNTf2woIECpqakqKSlp9bU9Ho/cbrfPAAAAvZffgWXv3r0KDQ2V3W7Xvffeqy1btmj48OEt1qalpWn58uU6cOCAmpubtX37dr311luqqamRJH377bdqampSVFSUz3ZRUVGqra1ttQeXyyWHw+Ed8fHx/i4DAAD0IH4HlmHDhqm8vFylpaW67777NHPmTO3fv7/F2pUrV2ro0KFKTExUnz599Nvf/lazZs1SQED7fjkpOztbDQ0N3lFZWdmu/QEAALP5nRz69OmjIUOGaPz48XK5XBo9erRWrlzZYm1kZKS2bt2qxsZGff311/rss88UGhqqhIQESdKll16qwMBA1dXV+WxXV1en6OjoVnuw2+3e31T6YQAAgN6r3fdhaW5ulsfjOWdNcHCw4uLi9P333+uPf/yjpk2bJulM+Bk/fryKiop89ldUVNTqdTEAAODCE+RPcXZ2tqZMmaLLL79cx48f16ZNm1RcXKzCwkJJUlZWluLi4uRyuSRJpaWlqqqq0pgxY1RVVaXFixerublZ8+fP9+5z3rx5mjlzppKTk3XNNddoxYoVamxs1KxZszpwmQAAoCfzK7DU19crKytLNTU1cjgcSkpKUmFhoW644QZJUkVFhc/1KadOnVJOTo6+/PJLhYaG6uabb9Zrr72mSy65xFtz66236ptvvtGiRYtUW1urMWPGqKCg4KwLcQEAwIWr3fdhMQH3YQEAoOfpkvuwAAAAdBUCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8fwKLGvWrFFSUpLCw8MVHh4up9Opd95555zbrFixQsOGDVNISIji4+P14IMP6tSpU97nFy9eLJvN5jMSExPbthoAANArBflTPGDAAOXl5Wno0KGyLEuvvPKKpk2bpj179mjEiBFn1W/atEkLFizQ+vXrde211+qLL77QnXfeKZvNpuXLl3vrRowYoXfffffHpoL8agsAAPRyfiWD9PR0n8dPPvmk1qxZo48//rjFwPLRRx/puuuu0+233y5JGjRokDIyMlRaWurbRFCQoqOj/e0dAABcINp8DUtTU5Py8/PV2Ngop9PZYs21116rsrIy7dixQ5L05Zdfatu2bbr55pt96g4cOKDY2FglJCQoMzNTFRUV53xtj8cjt9vtMwAAQO/l92cve/fuldPp1KlTpxQaGqotW7Zo+PDhLdbefvvt+vbbbzVhwgRZlqXvv/9e9957rx599FFvTUpKil5++WUNGzZMNTU1WrJkiSZOnKhPPvlEYWFhLe7X5XJpyZIl/rYOAAB6KJtlWZY/G5w+fVoVFRVqaGjQm2++qRdffFHvv/9+i6GluLhYt912m5544gmlpKTo4MGDmjt3ru6++24tXLiwxf0fO3ZMAwcO1PLlyzV79uwWazwejzwej/ex2+1WfHy8GhoaFB4e7s9yAABAN3G73XI4HOf1/u13YPlnqampGjx4sNauXXvWcxMnTtTPfvYzLV261Du3YcMG3XPPPTpx4oQCAlr+ROrqq69WamqqXC7XefXgz4IBAIAZ/Hn/bvd9WJqbm33OdvyjkydPnhVKAgMDJUmt5aQTJ07o0KFDiomJaW9rAACgl/DrGpbs7GxNmTJFl19+uY4fP65NmzapuLhYhYWFkqSsrCzFxcV5z4ykp6dr+fLlGjt2rPcjoYULFyo9Pd0bXB566CGlp6dr4MCBqq6uVm5urgIDA5WRkdHBSwUAAD2VX4Glvr5eWVlZqqmpkcPhUFJSkgoLC3XDDTdIkioqKnzOqOTk5MhmsyknJ0dVVVWKjIxUenq6nnzySW/NkSNHlJGRoaNHjyoyMlITJkzQxx9/rMjIyA5aIgAA6OnafQ2LCbiGBQCAnqdLr2EBAADobAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADj+RVY1qxZo6SkJIWHhys8PFxOp1PvvPPOObdZsWKFhg0bppCQEMXHx+vBBx/UqVOnfGqeffZZDRo0SMHBwUpJSdGOHTv8XwkAAOi1/AosAwYMUF5ensrKyrRr1y5df/31mjZtmvbt29di/aZNm7RgwQLl5ubq008/1UsvvaTNmzfr0Ucf9dZs3rxZ8+bNU25urnbv3q3Ro0crLS1N9fX17VsZAADoNWyWZVnt2UG/fv20dOlSzZ49+6znfvvb3+rTTz9VUVGRd+53v/udSktL9eGHH0qSUlJSdPXVV2v16tWSpObmZsXHx+v+++/XggULzqsHt9sth8OhhoYGhYeHt2c5AACgi/jz/t3ma1iampqUn5+vxsZGOZ3OFmuuvfZalZWVeT/i+fLLL7Vt2zbdfPPNkqTTp0+rrKxMqampPzYUEKDU1FSVlJS0+toej0dut9tnAACA3ivI3w327t0rp9OpU6dOKTQ0VFu2bNHw4cNbrL399tv17bffasKECbIsS99//73uvfde70dC3377rZqamhQVFeWzXVRUlD777LNWe3C5XFqyZIm/rQMAgB7K7zMsw4YNU3l5uUpLS3Xfffdp5syZ2r9/f4u1xcXFeuqpp/Tcc89p9+7deuutt/SnP/1Jjz/+eLuazs7OVkNDg3dUVla2a38AAMBsfp9h6dOnj4YMGSJJGj9+vHbu3KmVK1dq7dq1Z9UuXLhQd9xxh379619LkkaNGqXGxkbdc889euyxx3TppZcqMDBQdXV1PtvV1dUpOjq61R7sdrvsdru/rQMAgB6q3fdhaW5ulsfjafG5kydPKiDA9yUCAwMlSZZlqU+fPho/frzPRbnNzc0qKipq9boYAABw4fHrDEt2dramTJmiyy+/XMePH9emTZtUXFyswsJCSVJWVpbi4uLkcrkkSenp6Vq+fLnGjh2rlJQUHTx4UAsXLlR6ero3uMybN08zZ85UcnKyrrnmGq1YsUKNjY2aNWtWBy8VAAD0VH4Flvr6emVlZammpkYOh0NJSUkqLCzUDTfcIEmqqKjwOaOSk5Mjm82mnJwcVVVVKTIyUunp6XryySe9Nbfeequ++eYbLVq0SLW1tRozZowKCgrOuhAXAABcuNp9HxYTcB8WAAB6ni65DwsAAEBXIbAAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMbz+9uaTfTDzXrdbnc3dwIAAM7XD+/b53PT/V4RWI4fPy5Jio+P7+ZOAACAv44fPy6Hw3HOml7xXULNzc2qrq5WWFiYbDZbd7fTodxut+Lj41VZWXnBfk/ShX4MWP+FvX6JY3Chr1/qvcfAsiwdP35csbGxPl+e3JJecYYlICBAAwYM6O42OlV4eHiv+iFtiwv9GLD+C3v9EsfgQl+/1DuPwU+dWfkBF90CAADjEVgAAIDxCCyGs9vtys3Nld1u7+5Wus2FfgxY/4W9foljcKGvX+IYSL3kolsAANC7cYYFAAAYj8ACAACMR2ABAADGI7AAAADjEVi6WVVVlX71q1+pf//+CgkJ0ahRo7Rr165W6++8807ZbLazxogRI7qw647l7zGQpI0bN2r06NG6+OKLFRMTo7vuuktHjx7too47VlvW/+yzz+qqq65SSEiIhg0bpldffbWLuu14gwYNavFnes6cOa1u88YbbygxMVHBwcEaNWqUtm3b1oUddyx/179v3z7NmDHDu92KFSu6tuEO5u/6161bp4kTJyoiIkIRERFKTU3Vjh07urjrjuXvMXjrrbeUnJysSy65RH379tWYMWP02muvdXHXXY/A0o3+7//+T9ddd50uuugivfPOO9q/f7+eeeYZRUREtLrNypUrVVNT4x2VlZXq16+fbrnlli7svOO05Rj85S9/UVZWlmbPnq19+/bpjTfe0I4dO3T33Xd3Yecdoy3rX7NmjbKzs7V48WLt27dPS5Ys0Zw5c/T22293YecdZ+fOnT4/09u3b5ekVn+mP/roI2VkZGj27Nnas2ePpk+frunTp+uTTz7pyrY7jL/rP3nypBISEpSXl6fo6OiubLVT+Lv+4uJiZWRk6L333lNJSYni4+N14403qqqqqivb7lD+HoN+/frpscceU0lJif72t79p1qxZmjVrlgoLC7uy7a5nods88sgj1oQJE9q1jy1btlg2m8366quvOqirrtWWY7B06VIrISHBZ27VqlVWXFxcR7bWJdqyfqfTaT300EM+c/PmzbOuu+66jmyt28ydO9caPHiw1dzc3OLz//Zv/2ZNnTrVZy4lJcX6zW9+0xXtdbqfWv8/GjhwoPWf//mfnd9UF/Jn/ZZlWd9//70VFhZmvfLKK53cWdfx9xhYlmWNHTvWysnJ6cSuuh9nWLrR//zP/yg5OVm33HKLLrvsMo0dO1br1q3zax8vvfSSUlNTNXDgwE7qsnO15Rg4nU5VVlZq27ZtsixLdXV1evPNN3XzzTd3Udcdpy3r93g8Cg4O9pkLCQnRjh079N1333Vmu53u9OnT2rBhg+66665Wv8i0pKREqampPnNpaWkqKSnpihY71fmsvzdry/pPnjyp7777Tv369evk7rqGv8fAsiwVFRXp888/1//7f/+vCzrsRt2dmC5kdrvdstvtVnZ2trV7925r7dq1VnBwsPXyyy+f1/ZVVVVWYGCgtXnz5k7utPO09Ri8/vrrVmhoqBUUFGRJstLT063Tp093Udcdpy3rz87OtqKjo61du3ZZzc3N1s6dO62oqChLklVdXd2F3Xe8zZs3W4GBgVZVVVWrNRdddJG1adMmn7lnn33Wuuyyyzq7vU53Puv/R73tDIu/67csy7rvvvushIQE6+9//3sndtZ1zvcYHDt2zOrbt68VFBRk2e1266WXXuqiDrsPgaUbXXTRRZbT6fSZu//++62f/exn57X9U089ZfXv39/yeDyd0V6XaMsx2LdvnxUTE2M9/fTT1l//+leroKDAGjVqlHXXXXd1drsdri3rP3nypDVr1iwrKCjICgwMtGJjY6358+dbkqza2trObrlT3XjjjdbPf/7zc9b05sByPuv/R70tsPi7fpfLZUVERFh//etfO7GrrnW+x6Cpqck6cOCAtWfPHmvZsmWWw+Gw3nvvvc5vsBvxkVA3iomJ0fDhw33mrrrqKlVUVPzktpZlaf369brjjjvUp0+fzmqx07XlGLhcLl133XV6+OGHlZSUpLS0ND333HNav369ampqOrvlDtWW9YeEhGj9+vU6efKkvvrqK1VUVGjQoEEKCwtTZGRkZ7fcab7++mu9++67+vWvf33OuujoaNXV1fnM1dXV9fgLUM93/b2Vv+tftmyZ8vLy9Oc//1lJSUmd3F3X8OcYBAQEaMiQIRozZox+97vf6Ze//KVcLlcXdNl9CCzd6LrrrtPnn3/uM/fFF1+c1/Uo77//vg4ePKjZs2d3Vntdoi3H4OTJkwoI8P3RDQwMlHQmyPUk7fkZuOiiizRgwAAFBgYqPz9fP//5z886Lj3JH/7wB1122WWaOnXqOeucTqeKiop85rZv3y6n09mZ7XW6811/b+XP+p9++mk9/vjjKigoUHJychd01zXa8zPQ3Nwsj8fTCV0ZpLtP8VzIduzYYQUFBVlPPvmkdeDAAWvjxo3WxRdfbG3YsMFbs2DBAuuOO+44a9tf/epXVkpKSle22ynacgz+8Ic/WEFBQdZzzz1nHTp0yPrwww+t5ORk65prrumOJbRLW9b/+eefW6+99pr1xRdfWKWlpdatt95q9evXzzp8+HA3rKBjNDU1WZdffrn1yCOPnPXcHXfcYS1YsMD7+C9/+YsVFBRkLVu2zPr000+t3Nxc66KLLrL27t3blS13KH/W7/F4rD179lh79uyxYmJirIceesjas2ePdeDAga5suUP5s/68vDyrT58+1ptvvmnV1NR4x/Hjx7uy5Q7nzzF46qmnrD//+c/WoUOHrP3791vLli2zgoKCrHXr1nVly12OwNLN3n77bWvkyJGW3W63EhMTrRdeeMHn+ZkzZ1qTJk3ymTt27JgVEhJyVm1P1ZZjsGrVKmv48OFWSEiIFRMTY2VmZlpHjhzpwq47jr/r379/vzVmzBgrJCTECg8Pt6ZNm2Z99tlnXdx1xyosLLQkWZ9//vlZz02aNMmaOXOmz9zrr79uXXnllVafPn2sESNGWH/605+6qNPO4c/6Dx8+bEk6a/zzv5GexJ/1Dxw4sMX15+bmdl3DncCfY/DYY49ZQ4YMsYKDg62IiAjL6XRa+fn5Xdht97BZVg87hw4AAC44PfcDbwAAcMEgsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeP8fEzow8OHBhQAAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair = torch.tensor([7,4], dtype=torch.int64)\n",
    "print(euclidean_algorithm(pair))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T01:39:13.747703Z",
     "start_time": "2023-09-22T01:39:13.533384Z"
    }
   },
   "id": "df34634a93f21f9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T01:34:14.270095Z"
    }
   },
   "id": "8f898665a7eafa78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
