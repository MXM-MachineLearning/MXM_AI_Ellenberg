{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epsilon_greedy_search(Epsilon, qtable, state):\n",
    "    if (random.random() < Epsilon):\n",
    "        # 0 is 'apply matrix A', 1 is 'apply matrix B'\n",
    "        # 2 is 'apply matrix C', 3 is 'apply matrix D'\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    else:\n",
    "        # get the best move for the current state\n",
    "        return best_move_for_a_state(Q_table=qtable, state=state)\n",
    "    \n",
    "# I would like to return the best move for a given state\n",
    "def best_move_for_a_state(Q_table, state):\n",
    "    vals = Q_table[(state[0][1], state[0][2], state[1][2])]\n",
    "\n",
    "    # if we haven't visited this state before, return a random choice of 0, 1, 2, or 3\n",
    "    if vals==[0, 0, 0, 0]:\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    \n",
    "    # if we have visited this state before, return the current best choice\n",
    "    return np.argmax(vals)\n",
    "\n",
    "# over a given state, return the maximum value of the table for that state\n",
    "def max_a_prime(Q_table, state):\n",
    "    return max(Q_table[(state[0][1], state[0][2], state[1][2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B is the inverse of A\n",
    "A = np.array([[1, 1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "B = np.array([[1, -1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "# C is the inverse of D\n",
    "C = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
    "D = np.array([[1, 0, 0], [0, 1, -1], [0, 0, 1]])\n",
    "\n",
    "# together, A, B, C, and D generate the heisenberg group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReward(matrix):\n",
    "    if (matrix==A).all() or (matrix==B).all() or (matrix==C).all() or (matrix==D).all():\n",
    "        return 20\n",
    "    else:\n",
    "        return -1 + 1/(2 + abs(matrix[0][1]) + abs(matrix[0][2]) + abs(matrix[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.75, -0.5, -0.8, -0.8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapted from ChatGPT\n",
    "class CustomDefaultDict(dict):\n",
    "    def __init__(self, default_factory, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        # Compute the default value based on the missing key\n",
    "        default_value = self.default_factory(key)\n",
    "        self[key] = default_value  # Cache the default value for future lookups\n",
    "        return default_value\n",
    "\n",
    "# Example usage:\n",
    "def default_value_for_key(key):\n",
    "    # Define a function that computes the default value based on the key\n",
    "    val1 = key[0]\n",
    "    val2 = key[1]\n",
    "    val3 = key[2]\n",
    "    cur_matrix = np.array([[1, val1, val2], [0, 1, val3], [0, 0, 1]])\n",
    "    output1 = getReward(cur_matrix @ A)\n",
    "    output2 = getReward(cur_matrix @ B)\n",
    "    output3 = getReward(cur_matrix @ C)\n",
    "    output4 = getReward(cur_matrix @ D)\n",
    "    return [output1, output2, output3, output4]\n",
    "\n",
    "custom_dict = CustomDefaultDict(default_value_for_key)\n",
    "\n",
    "cur_mat = A@A@B\n",
    "\n",
    "custom_dict[(cur_mat[0][1], cur_mat[0][2], cur_mat[1][2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heisenberg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(oldObs, action):\n",
    "    # action is always either 0, 1, 2, or 3\n",
    "    next_state = []\n",
    "    if action==0:\n",
    "        next_state = oldObs @ A\n",
    "    elif action==1:\n",
    "        next_state = oldObs @ B\n",
    "    elif action==2:\n",
    "        next_state = oldObs @ C\n",
    "    else:\n",
    "        next_state = oldObs @ D\n",
    "    curReward = getReward(next_state)\n",
    "    done = curReward==20\n",
    "    return (next_state, curReward, done)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for the last 100 iterations: -94.51500676699858\n",
      "epsilon: 0.9038873549665959\n",
      "Average reward for the last 100 iterations: -87.32453028834011\n",
      "epsilon: 0.8178301806491574\n",
      "Average reward for the last 100 iterations: -88.14832549881554\n",
      "epsilon: 0.7399663251239436\n",
      "Average reward for the last 100 iterations: -81.16337450276725\n",
      "epsilon: 0.6695157201007336\n",
      "Average reward for the last 100 iterations: -73.2867423106452\n",
      "epsilon: 0.6057725659163237\n",
      "Average reward for the last 100 iterations: -73.65723737929834\n",
      "epsilon: 0.548098260578011\n",
      "Average reward for the last 100 iterations: -73.64553614675602\n",
      "epsilon: 0.4959150020176678\n",
      "Average reward for the last 100 iterations: -70.53900225156423\n",
      "epsilon: 0.44869999946146477\n",
      "Average reward for the last 100 iterations: -66.9608335153798\n",
      "epsilon: 0.4059802359226587\n",
      "Average reward for the last 100 iterations: -78.10411801080375\n",
      "epsilon: 0.36732772934619257\n",
      "Average reward for the last 100 iterations: -65.91493783919584\n",
      "epsilon: 0.33235524492954527\n",
      "Average reward for the last 100 iterations: -77.22411566416042\n",
      "epsilon: 0.3007124156643058\n",
      "Average reward for the last 100 iterations: -65.0723025952043\n",
      "epsilon: 0.2720822322326576\n",
      "Average reward for the last 100 iterations: -75.11208143179793\n",
      "epsilon: 0.2461778670932771\n",
      "Average reward for the last 100 iterations: -65.05593211037471\n",
      "epsilon: 0.22273980093919937\n",
      "Average reward for the last 100 iterations: -75.23621154499455\n",
      "epsilon: 0.2015332227394583\n",
      "Average reward for the last 100 iterations: -73.40170933456959\n",
      "epsilon: 0.18234567731717977\n",
      "Average reward for the last 100 iterations: -65.42707908150781\n",
      "epsilon: 0.1649849368967147\n",
      "Average reward for the last 100 iterations: -70.2487582328127\n",
      "epsilon: 0.14927707529619813\n",
      "Average reward for the last 100 iterations: -65.531903322467\n",
      "epsilon: 0.13506472547210188\n",
      "Average reward for the last 100 iterations: -71.77249341008414\n",
      "epsilon: 0.12220550295922675\n",
      "Average reward for the last 100 iterations: -66.13550396334331\n",
      "epsilon: 0.11057057941158951\n",
      "Average reward for the last 100 iterations: -66.31512996921653\n",
      "epsilon: 0.10004339195341891\n",
      "Average reward for the last 100 iterations: -68.84385848036233\n",
      "epsilon: 0.09051847541007228\n",
      "Average reward for the last 100 iterations: -64.21566770475195\n",
      "epsilon: 0.08190040571973876\n",
      "Average reward for the last 100 iterations: -64.12653995902797\n",
      "epsilon: 0.07410284394064628\n",
      "Average reward for the last 100 iterations: -62.37714820517108\n",
      "epsilon: 0.06704767127628951\n",
      "Average reward for the last 100 iterations: -59.30843347629876\n",
      "epsilon: 0.060664206453048174\n",
      "Average reward for the last 100 iterations: -67.61666036392764\n",
      "epsilon: 0.05488849760960279\n",
      "Average reward for the last 100 iterations: -68.84835329384829\n",
      "epsilon: 0.049662681604038215\n",
      "Average reward for the last 100 iterations: -65.05646403509677\n",
      "epsilon: 0.04493440431994225\n",
      "Average reward for the last 100 iterations: -63.6390682432559\n",
      "epsilon: 0.04065629616391608\n",
      "Average reward for the last 100 iterations: -68.7076123582719\n",
      "epsilon: 0.03678549749984046\n",
      "Average reward for the last 100 iterations: -75.33514571312004\n",
      "epsilon: 0.03328322926552661\n",
      "Average reward for the last 100 iterations: -66.69563282646646\n",
      "epsilon: 0.030114404470033673\n",
      "Average reward for the last 100 iterations: -66.60148643636857\n",
      "epsilon: 0.027247276679492435\n",
      "Average reward for the last 100 iterations: -68.53489834945167\n",
      "epsilon: 0.024653121969839265\n",
      "Average reward for the last 100 iterations: -64.78434495109279\n",
      "epsilon: 0.022305951160147018\n",
      "Average reward for the last 100 iterations: -62.46438174847599\n",
      "epsilon: 0.02018224944360293\n",
      "Average reward for the last 100 iterations: -55.58385657455315\n",
      "epsilon: 0.018260740807661956\n",
      "Average reward for the last 100 iterations: -67.07677719144874\n",
      "epsilon: 0.016522174883251375\n",
      "Average reward for the last 100 iterations: -65.18660819218593\n",
      "epsilon: 0.014949134087605212\n",
      "Average reward for the last 100 iterations: -62.66869724780096\n",
      "epsilon: 0.01352585912861506\n",
      "Average reward for the last 100 iterations: -64.5503851924128\n",
      "epsilon: 0.012238091122537187\n",
      "Average reward for the last 100 iterations: -72.52119943000802\n",
      "epsilon: 0.011072928743333644\n",
      "Average reward for the last 100 iterations: -57.22798178375488\n",
      "epsilon: 0.010018698972517958\n",
      "Average reward for the last 100 iterations: -63.61365621977956\n",
      "epsilon: 0.009064840154630435\n",
      "Average reward for the last 100 iterations: -67.04072299816491\n",
      "epsilon: 0.008201796186750635\n",
      "Average reward for the last 100 iterations: -50.822323060508204\n",
      "epsilon: 0.007420920781999136\n",
      "Average reward for the last 100 iterations: -62.684659782770005\n",
      "epsilon: 0.006714390847905742\n",
      "Average reward for the last 100 iterations: -55.73659226869018\n",
      "epsilon: 0.006075128111837272\n",
      "Average reward for the last 100 iterations: -61.59527104852305\n",
      "epsilon: 0.005496728208300101\n",
      "Average reward for the last 100 iterations: -69.34600633716425\n",
      "epsilon: 0.004973396517688337\n",
      "Average reward for the last 100 iterations: -55.468233003919586\n",
      "epsilon: 0.004499890113687073\n",
      "Average reward for the last 100 iterations: -59.41877087268803\n",
      "epsilon: 0.004071465237738676\n",
      "Average reward for the last 100 iterations: -54.88145839132878\n",
      "epsilon: 0.003683829774352405\n",
      "Average reward for the last 100 iterations: -60.52304814782835\n",
      "epsilon: 0.0033331002511377216\n",
      "Average reward for the last 100 iterations: -61.171209420089234\n",
      "epsilon: 0.003015762932772144\n",
      "Average reward for the last 100 iterations: -64.69728118961649\n",
      "epsilon: 0.002728638619128845\n",
      "Average reward for the last 100 iterations: -57.81642098593441\n",
      "epsilon: 0.0024688507948989738\n",
      "Average reward for the last 100 iterations: -60.5544956290847\n",
      "epsilon: 0.0022337968116200296\n",
      "Average reward for the last 100 iterations: -62.361688299645756\n",
      "epsilon: 0.0020211218134014433\n",
      "Average reward for the last 100 iterations: -56.807957321827615\n",
      "epsilon: 0.0018286951451258438\n",
      "Average reward for the last 100 iterations: -64.98045895721239\n",
      "epsilon: 0.0016545890067748276\n",
      "Average reward for the last 100 iterations: -68.30503121595834\n",
      "epsilon: 0.0014970591400305351\n",
      "Average reward for the last 100 iterations: -60.95399631574911\n",
      "epsilon: 0.001354527353664429\n",
      "Average reward for the last 100 iterations: -59.53380223973565\n",
      "epsilon: 0.001225565712646288\n",
      "Average reward for the last 100 iterations: -57.30043226393199\n",
      "epsilon: 0.0011088822325741772\n",
      "Average reward for the last 100 iterations: -61.72193981110337\n",
      "epsilon: 0.0010033079361070328\n",
      "Average reward for the last 100 iterations: -58.54467926121164\n",
      "epsilon: 0.0009077851417265054\n",
      "Average reward for the last 100 iterations: -49.478201227653535\n",
      "epsilon: 0.0008213568675006472\n",
      "Average reward for the last 100 iterations: -56.966528216029666\n",
      "epsilon: 0.0007431572436925013\n",
      "Average reward for the last 100 iterations: -46.40648181843799\n",
      "epsilon: 0.0006724028381636441\n",
      "Average reward for the last 100 iterations: -56.73257905638304\n",
      "epsilon: 0.0006083848076674359\n",
      "Average reward for the last 100 iterations: -59.013365767963606\n",
      "epsilon: 0.0005504617964007802\n",
      "Average reward for the last 100 iterations: -61.966872437897564\n",
      "epsilon: 0.0004980535106695312\n",
      "Average reward for the last 100 iterations: -64.0744885913194\n",
      "epsilon: 0.00045063490529620545\n",
      "Average reward for the last 100 iterations: -52.1614712698937\n",
      "epsilon: 0.00040773092352733666\n",
      "Average reward for the last 100 iterations: -57.910655804957095\n",
      "epsilon: 0.00036891173774295443\n",
      "Average reward for the last 100 iterations: -53.21228257814664\n",
      "epsilon: 0.0003337884432878974\n",
      "Average reward for the last 100 iterations: -60.131743829119266\n",
      "epsilon: 0.00030200916228419905\n",
      "Average reward for the last 100 iterations: -57.80200903263204\n",
      "epsilon: 0.0002732555183911334\n",
      "Average reward for the last 100 iterations: -53.315850025862055\n",
      "epsilon: 0.0002472394471957831\n",
      "Average reward for the last 100 iterations: -53.12153160318034\n",
      "epsilon: 0.000223700310279479\n",
      "Average reward for the last 100 iterations: -48.84937048142133\n",
      "epsilon: 0.00020240228404777254\n",
      "Average reward for the last 100 iterations: -46.3280231119259\n",
      "epsilon: 0.00018313199716430296\n",
      "Average reward for the last 100 iterations: -47.67380917408013\n",
      "epsilon: 0.0001656963929195113\n",
      "Average reward for the last 100 iterations: -58.661170129597515\n",
      "epsilon: 0.00014992079511864147\n",
      "Average reward for the last 100 iterations: -53.46493979301544\n",
      "epsilon: 0.0001356471581123901\n",
      "Average reward for the last 100 iterations: -52.37417590809353\n",
      "epsilon: 0.00012273248343838214\n",
      "Average reward for the last 100 iterations: -59.6172266297887\n",
      "epsilon: 0.00011104738721081156\n",
      "Average reward for the last 100 iterations: -54.33581492460891\n",
      "epsilon: 0.00010047480390583761\n",
      "Average reward for the last 100 iterations: -54.67029116904626\n",
      "epsilon: 9.090881355679163e-05\n",
      "Average reward for the last 100 iterations: -63.81201511143885\n",
      "epsilon: 8.225358060960925e-05\n",
      "Average reward for the last 100 iterations: -53.261782268359326\n",
      "epsilon: 7.44223938075589e-05\n",
      "Average reward for the last 100 iterations: -62.45622545774605\n",
      "epsilon: 6.733679748648316e-05\n",
      "Average reward for the last 100 iterations: -59.557283710374016\n",
      "epsilon: 6.09258055775561e-05\n",
      "Average reward for the last 100 iterations: -44.45332482031078\n",
      "epsilon: 5.512519044314936e-05\n",
      "Average reward for the last 100 iterations: -58.64054278944968\n",
      "epsilon: 4.9876839421109216e-05\n",
      "Average reward for the last 100 iterations: -46.126819950682744\n",
      "epsilon: 4.5128172631071065e-05\n",
      "Average reward for the last 100 iterations: -47.57820548935965\n",
      "epsilon: 4.083161621018491e-05\n",
      "Average reward for the last 100 iterations: -55.19918658238644\n",
      "epsilon: 3.69441257009361e-05\n",
      "Average reward for the last 100 iterations: -58.5135889905845\n",
      "epsilon: 3.3426754816188734e-05\n",
      "Average reward for the last 100 iterations: -47.0504372286469\n",
      "epsilon: 3.0244265261182943e-05\n",
      "Average reward for the last 100 iterations: -53.686800815051335\n",
      "epsilon: 2.7364773703542285e-05\n",
      "Average reward for the last 100 iterations: -48.21602507199804\n",
      "epsilon: 2.4759432354508794e-05\n",
      "Average reward for the last 100 iterations: -44.798231225309955\n",
      "epsilon: 2.2402139961352654e-05\n",
      "Average reward for the last 100 iterations: -46.14382768862691\n",
      "epsilon: 2.0269280315574096e-05\n",
      "Average reward for the last 100 iterations: -55.45422291936847\n",
      "epsilon: 1.8339485657177917e-05\n",
      "Average reward for the last 100 iterations: -54.03330876517797\n",
      "epsilon: 1.659342260471908e-05\n",
      "Average reward for the last 100 iterations: -50.81739512459965\n",
      "epsilon: 1.501359846648893e-05\n",
      "Average reward for the last 100 iterations: -54.759594336513395\n",
      "epsilon: 1.3584185992397611e-05\n",
      "Average reward for the last 100 iterations: -44.041214580462054\n",
      "epsilon: 1.2290864810853405e-05\n",
      "Average reward for the last 100 iterations: -49.14057170872219\n",
      "epsilon: 1.1120677962096389e-05\n",
      "Average reward for the last 100 iterations: -58.29998782139026\n",
      "epsilon: 1.006190209068529e-05\n",
      "Average reward for the last 100 iterations: -49.94378156983601\n",
      "epsilon: 9.103929996679068e-06\n",
      "Average reward for the last 100 iterations: -47.2445083773752\n",
      "epsilon: 8.23716436886816e-06\n",
      "Average reward for the last 100 iterations: -52.000657029275054\n",
      "epsilon: 7.452921635436766e-06\n",
      "Average reward for the last 100 iterations: -50.2351824826038\n",
      "epsilon: 6.743344968797045e-06\n",
      "Average reward for the last 100 iterations: -41.49842294130827\n",
      "epsilon: 6.101325573046306e-06\n",
      "Average reward for the last 100 iterations: -50.690850751544694\n",
      "epsilon: 5.5204314654763466e-06\n",
      "Average reward for the last 100 iterations: -42.78598041506936\n",
      "epsilon: 4.994843038642421e-06\n",
      "Average reward for the last 100 iterations: -44.39437260019498\n",
      "epsilon: 4.519294757429241e-06\n",
      "Average reward for the last 100 iterations: -54.74579582084198\n",
      "epsilon: 4.089022407014129e-06\n",
      "Average reward for the last 100 iterations: -53.683767197362585\n",
      "epsilon: 3.6997153632383808e-06\n",
      "Average reward for the last 100 iterations: -54.31683293339805\n",
      "epsilon: 3.3474734072140295e-06\n",
      "Average reward for the last 100 iterations: -47.48516153773257\n",
      "epsilon: 3.0287676515192263e-06\n",
      "Average reward for the last 100 iterations: -53.105709786833465\n",
      "epsilon: 2.7404051865266284e-06\n",
      "Average reward for the last 100 iterations: -46.82036544022396\n",
      "epsilon: 2.4794970926789746e-06\n",
      "Average reward for the last 100 iterations: -44.02874292556495\n",
      "epsilon: 2.243429498247208e-06\n",
      "Average reward for the last 100 iterations: -50.35495541492207\n",
      "epsilon: 2.0298373926173216e-06\n",
      "Average reward for the last 100 iterations: -49.583742694431436\n",
      "epsilon: 1.83658093275792e-06\n",
      "Average reward for the last 100 iterations: -46.29799350599024\n",
      "epsilon: 1.6617240054981357e-06\n",
      "Average reward for the last 100 iterations: -52.78449165355569\n",
      "epsilon: 1.5035148308450506e-06\n",
      "Average reward for the last 100 iterations: -42.80034835614011\n",
      "epsilon: 1.3603684120175983e-06\n",
      "Average reward for the last 100 iterations: -35.894210919687076\n",
      "epsilon: 1.2308506563750686e-06\n",
      "Average reward for the last 100 iterations: -45.63747875472868\n",
      "epsilon: 1.1136640081579159e-06\n",
      "Average reward for the last 100 iterations: -51.0677003650711\n",
      "epsilon: 1.0076344491044587e-06\n",
      "Average reward for the last 100 iterations: -39.0582391476991\n",
      "epsilon: 9.116997367109624e-07\n",
      "Average reward for the last 100 iterations: -38.74974758264332\n",
      "epsilon: 8.248987623017148e-07\n",
      "Average reward for the last 100 iterations: -41.06453092295464\n",
      "epsilon: 7.463619222944092e-07\n",
      "Average reward for the last 100 iterations: -43.041060527928046\n",
      "epsilon: 6.753024061966736e-07\n",
      "Average reward for the last 100 iterations: -46.1845628897031\n",
      "epsilon: 6.110083140537422e-07\n",
      "Average reward for the last 100 iterations: -44.744240467387336\n",
      "epsilon: 5.528355243770125e-07\n",
      "Average reward for the last 100 iterations: -46.930823803610586\n",
      "epsilon: 5.002012411018101e-07\n",
      "Average reward for the last 100 iterations: -50.34260892241747\n",
      "epsilon: 4.5257815492544905e-07\n",
      "Average reward for the last 100 iterations: -47.8170024979762\n",
      "epsilon: 4.094891605317576e-07\n",
      "Average reward for the last 100 iterations: -40.007558773377866\n",
      "epsilon: 3.7050257677731924e-07\n",
      "Average reward for the last 100 iterations: -50.14742802316957\n",
      "epsilon: 3.3522782195351267e-07\n",
      "Average reward for the last 100 iterations: -48.43465700775805\n",
      "epsilon: 3.033115007975709e-07\n",
      "Average reward for the last 100 iterations: -36.15009261420684\n",
      "epsilon: 2.7443386405091567e-07\n",
      "Average reward for the last 100 iterations: -43.21045513302527\n",
      "epsilon: 2.4830560509533956e-07\n",
      "Average reward for the last 100 iterations: -49.24854043272028\n",
      "epsilon: 2.246649615745811e-07\n",
      "Average reward for the last 100 iterations: -42.83014236924091\n",
      "epsilon: 2.032750929642842e-07\n",
      "Average reward for the last 100 iterations: -33.90942614880062\n",
      "epsilon: 1.8392170781789347e-07\n",
      "Average reward for the last 100 iterations: -40.13403048454519\n",
      "epsilon: 1.6641091691737205e-07\n",
      "Average reward for the last 100 iterations: -45.197508480616655\n",
      "epsilon: 1.5056729082083014e-07\n",
      "Average reward for the last 100 iterations: -38.95563834157305\n",
      "epsilon: 1.3623210234687325e-07\n",
      "Average reward for the last 100 iterations: -47.553235939768584\n",
      "epsilon: 1.2326173638824198e-07\n",
      "Average reward for the last 100 iterations: -36.23077736793449\n",
      "epsilon: 1.1152625112368151e-07\n",
      "Average reward for the last 100 iterations: -40.23571682830223\n",
      "epsilon: 1.0090807621373846e-07\n",
      "Average reward for the last 100 iterations: -42.215242619123295\n",
      "epsilon: 9.130083493854227e-08\n",
      "Average reward for the last 100 iterations: -38.1937824192085\n",
      "epsilon: 8.260827847731793e-08\n",
      "Average reward for the last 100 iterations: -58.380137708563815\n",
      "epsilon: 7.474332165285969e-08\n",
      "Average reward for the last 100 iterations: -43.18781195974193\n",
      "epsilon: 6.762717048070146e-08\n",
      "Average reward for the last 100 iterations: -51.608891248737535\n",
      "epsilon: 6.118853278245869e-08\n",
      "Average reward for the last 100 iterations: -42.17602711562666\n",
      "epsilon: 5.5362903954978386e-08\n",
      "Average reward for the last 100 iterations: -39.98753014203475\n",
      "epsilon: 5.009192073987496e-08\n",
      "Average reward for the last 100 iterations: -41.398204854550606\n",
      "epsilon: 4.532277651928118e-08\n",
      "Average reward for the last 100 iterations: -37.88583387656227\n",
      "epsilon: 4.100769228003525e-08\n",
      "Average reward for the last 100 iterations: -36.837916451225766\n",
      "epsilon: 3.710343794623138e-08\n",
      "Average reward for the last 100 iterations: -36.85574019062081\n",
      "epsilon: 3.357089928467093e-08\n",
      "Average reward for the last 100 iterations: -42.489654702185874\n",
      "epsilon: 3.037468604431549e-08\n",
      "Average reward for the last 100 iterations: -40.01606892675134\n",
      "epsilon: 2.748277740394102e-08\n",
      "Average reward for the last 100 iterations: -46.036949697371604\n",
      "epsilon: 2.4866201175959905e-08\n",
      "Average reward for the last 100 iterations: -45.73663567833937\n",
      "epsilon: 2.2498743552558194e-08\n",
      "Average reward for the last 100 iterations: -48.61031579581413\n",
      "epsilon: 2.0356686486279826e-08\n",
      "Average reward for the last 100 iterations: -37.265674217507325\n",
      "epsilon: 1.8418570074041747e-08\n",
      "Average reward for the last 100 iterations: -38.658239634181385\n",
      "epsilon: 1.666497756405654e-08\n",
      "Average reward for the last 100 iterations: -39.18408550238544\n",
      "epsilon: 1.5078340831784492e-08\n",
      "Average reward for the last 100 iterations: -37.83594474780025\n",
      "epsilon: 1.3642764376102604e-08\n",
      "Average reward for the last 100 iterations: -32.80050192209734\n",
      "epsilon: 1.2343866072420293e-08\n",
      "Average reward for the last 100 iterations: -37.262210130201886\n",
      "epsilon: 1.116863308734923e-08\n",
      "Average reward for the last 100 iterations: -34.779050232823366\n",
      "epsilon: 1.0105291511427924e-08\n",
      "Average reward for the last 100 iterations: -55.451625668777545\n",
      "epsilon: 9.143188403834803e-09\n",
      "Average reward for the last 100 iterations: -35.44640042934388\n",
      "epsilon: 8.272685067370861e-09\n",
      "Average reward for the last 100 iterations: -41.98239292386124\n",
      "epsilon: 7.485060484501997e-09\n",
      "Average reward for the last 100 iterations: -46.6580778502883\n",
      "epsilon: 6.77242394704854e-09\n",
      "Average reward for the last 100 iterations: -34.582646530612806\n",
      "epsilon: 6.127636004214353e-09\n",
      "Average reward for the last 100 iterations: -30.121116817575206\n",
      "epsilon: 5.544236936984372e-09\n",
      "Average reward for the last 100 iterations: -39.04748915170229\n",
      "epsilon: 5.016382042321222e-09\n",
      "Average reward for the last 100 iterations: -34.905406914426955\n",
      "epsilon: 4.53878307881447e-09\n",
      "Average reward for the last 100 iterations: -33.88837216718745\n",
      "epsilon: 4.10665528716391e-09\n",
      "Average reward for the last 100 iterations: -43.49009802516311\n",
      "epsilon: 3.7156694547289007e-09\n",
      "Average reward for the last 100 iterations: -32.83352954684176\n",
      "epsilon: 3.3619085439089865e-09\n",
      "Average reward for the last 100 iterations: -36.91497175020744\n",
      "epsilon: 3.0418284498433344e-09\n",
      "Average reward for the last 100 iterations: -43.30024213982145\n",
      "epsilon: 2.7522224942853162e-09\n",
      "Average reward for the last 100 iterations: -37.99922189927911\n",
      "epsilon: 2.4901892999390573e-09\n",
      "Average reward for the last 100 iterations: -31.554640784481713\n",
      "epsilon: 2.2531037234114447e-09\n",
      "Average reward for the last 100 iterations: -40.7317832278794\n",
      "epsilon: 2.038590555575333e-09\n",
      "Average reward for the last 100 iterations: -42.527622040219605\n",
      "epsilon: 1.8445007258647328e-09\n",
      "Average reward for the last 100 iterations: -41.658388146977316\n",
      "epsilon: 1.6688897721079462e-09\n",
      "Average reward for the last 100 iterations: -40.50454781444673\n",
      "epsilon: 1.5099983602016576e-09\n",
      "Average reward for the last 100 iterations: -34.43398590041182\n",
      "epsilon: 1.3662346584650378e-09\n",
      "Average reward for the last 100 iterations: -28.729387983890177\n",
      "epsilon: 1.2361583900937467e-09\n",
      "Average reward for the last 100 iterations: -32.263788980276374\n",
      "epsilon: 1.1184664039455474e-09\n",
      "Average reward for the last 100 iterations: -30.808602242098154\n",
      "epsilon: 1.011979619100441e-09\n",
      "Average reward for the last 100 iterations: -35.835618515497515\n",
      "epsilon: 9.15631212401201e-10\n",
      "Average reward for the last 100 iterations: -36.813248820480794\n",
      "epsilon: 8.284559306328114e-10\n",
      "Average reward for the last 100 iterations: -44.551682165737745\n",
      "epsilon: 7.495804202663469e-10\n",
      "Average reward for the last 100 iterations: -37.0410637129806\n",
      "epsilon: 6.782144778871841e-10\n",
      "Average reward for the last 100 iterations: -45.03197076885147\n",
      "epsilon: 6.136431336511485e-10\n",
      "Average reward for the last 100 iterations: -39.01275365036638\n",
      "epsilon: 5.552194884578073e-10\n",
      "Average reward for the last 100 iterations: -32.241010375147546\n",
      "epsilon: 5.023582330811142e-10\n",
      "Average reward for the last 100 iterations: -30.753538010478152\n",
      "epsilon: 4.545297843297102e-10\n",
      "Average reward for the last 100 iterations: -44.3996596520419\n",
      "epsilon: 4.1125497949080954e-10\n",
      "Average reward for the last 100 iterations: -39.813105089132485\n",
      "epsilon: 3.7210027590469397e-10\n",
      "Average reward for the last 100 iterations: -34.914546999002475\n",
      "epsilon: 3.366734075774115e-10\n",
      "Average reward for the last 100 iterations: -30.786578444610832\n",
      "epsilon: 3.0461945531805506e-10\n",
      "Average reward for the last 100 iterations: -42.50426721428754\n",
      "epsilon: 2.7561729102983154e-10\n",
      "Average reward for the last 100 iterations: -34.83565168575664\n",
      "epsilon: 2.493763605325452e-10\n",
      "Average reward for the last 100 iterations: -29.19546751051524\n",
      "epsilon: 2.2563377268564379e-10\n",
      "Average reward for the last 100 iterations: -38.50698664181205\n",
      "epsilon: 2.0415166564961023e-10\n",
      "Average reward for the last 100 iterations: -31.124975043363953\n",
      "epsilon: 1.8471482389995092e-10\n",
      "Average reward for the last 100 iterations: -32.54957621542308\n",
      "epsilon: 1.6712852212016722e-10\n",
      "Average reward for the last 100 iterations: -24.737865467762877\n",
      "epsilon: 1.5121657437304705e-10\n",
      "Average reward for the last 100 iterations: -44.54818879114711\n",
      "epsilon: 1.3681956900616914e-10\n",
      "Average reward for the last 100 iterations: -29.70004099161357\n",
      "epsilon: 1.2379327160826409e-10\n",
      "Average reward for the last 100 iterations: -33.95586398090947\n",
      "epsilon: 1.1200718001667172e-10\n",
      "Average reward for the last 100 iterations: -39.48436926939446\n",
      "epsilon: 1.0134321689943615e-10\n",
      "Average reward for the last 100 iterations: -31.77790056597887\n",
      "epsilon: 9.169454681385119e-11\n",
      "Average reward for the last 100 iterations: -34.94405734276791\n",
      "epsilon: 8.296450589032293e-11\n",
      "Average reward for the last 100 iterations: -35.49224148521929\n",
      "epsilon: 7.506563341873329e-11\n",
      "Average reward for the last 100 iterations: -37.12928379656144\n",
      "epsilon: 6.79187956353863e-11\n",
      "Average reward for the last 100 iterations: -35.262340118559706\n",
      "epsilon: 6.145239293231837e-11\n",
      "Average reward for the last 100 iterations: -33.60616118690418\n",
      "epsilon: 5.560164254650765e-11\n",
      "Average reward for the last 100 iterations: -34.1643890877474\n",
      "epsilon: 5.0307929542703596e-11\n",
      "Average reward for the last 100 iterations: -29.855831546216873\n",
      "epsilon: 4.551821958778797e-11\n",
      "Average reward for the last 100 iterations: -35.45885819524607\n",
      "epsilon: 4.118452763362796e-11\n",
      "Average reward for the last 100 iterations: -33.15646285630389\n",
      "epsilon: 3.726343718549409e-11\n",
      "Average reward for the last 100 iterations: -36.06522072725992\n",
      "epsilon: 3.3715665339900035e-11\n",
      "Average reward for the last 100 iterations: -40.10765117254962\n",
      "epsilon: 3.050566923425541e-11\n",
      "Average reward for the last 100 iterations: -27.257534259990184\n",
      "epsilon: 2.7601289965602556e-11\n",
      "Average reward for the last 100 iterations: -38.89173053393475\n",
      "epsilon: 2.4973430411085592e-11\n",
      "Average reward for the last 100 iterations: -41.09824148865332\n",
      "epsilon: 2.2595763722440924e-11\n",
      "Average reward for the last 100 iterations: -35.24113537596543\n",
      "epsilon: 2.044446957410138e-11\n",
      "Average reward for the last 100 iterations: -20.992865954791213\n",
      "epsilon: 1.849799552255208e-11\n",
      "Average reward for the last 100 iterations: -33.63417770521036\n",
      "epsilon: 1.6736841086149672e-11\n",
      "Average reward for the last 100 iterations: -33.70227073912366\n",
      "epsilon: 1.5143362382238333e-11\n",
      "Average reward for the last 100 iterations: -26.570886322987857\n",
      "epsilon: 1.3701595364346396e-11\n",
      "Average reward for the last 100 iterations: -32.95878852498609\n",
      "epsilon: 1.2397095888590217e-11\n",
      "Average reward for the last 100 iterations: -31.13448982645322\n",
      "epsilon: 1.1216795007012077e-11\n",
      "Average reward for the last 100 iterations: -31.525583938676096\n",
      "epsilon: 1.0148868038128785e-11\n",
      "Average reward for the last 100 iterations: -27.111476244825646\n",
      "epsilon: 9.182616102992242e-12\n",
      "Average reward for the last 100 iterations: -26.849792402425788\n",
      "epsilon: 8.308358939947264e-12\n",
      "Average reward for the last 100 iterations: -17.879623527521083\n",
      "epsilon: 7.517337924266262e-12\n",
      "Average reward for the last 100 iterations: -33.641365843756475\n",
      "epsilon: 6.801628321076183e-12\n",
      "Average reward for the last 100 iterations: -31.91750057460763\n",
      "epsilon: 6.1540598924959294e-12\n",
      "Average reward for the last 100 iterations: -28.453940637101212\n",
      "epsilon: 5.568145063597754e-12\n",
      "Average reward for the last 100 iterations: -29.334463461425294\n",
      "epsilon: 5.0380139275332125e-12\n",
      "Average reward for the last 100 iterations: -23.13589078634482\n",
      "epsilon: 4.558355438681547e-12\n",
      "Average reward for the last 100 iterations: -32.36492757999469\n",
      "epsilon: 4.12436420467213e-12\n",
      "Average reward for the last 100 iterations: -35.88744062924924\n",
      "epsilon: 3.731692344224219e-12\n",
      "Average reward for the last 100 iterations: -35.30357704058564\n",
      "epsilon: 3.3764059284984217e-12\n",
      "Average reward for the last 100 iterations: -24.317404305589847\n",
      "epsilon: 3.0549455695735444e-12\n",
      "Average reward for the last 100 iterations: -33.84797845055607\n",
      "epsilon: 2.76409076120996e-12\n",
      "Average reward for the last 100 iterations: -29.19961363109925\n",
      "epsilon: 2.500927614652326e-12\n",
      "Average reward for the last 100 iterations: -32.07284419366297\n",
      "epsilon: 2.262819666237245e-12\n",
      "Average reward for the last 100 iterations: -26.177060621456246\n",
      "epsilon: 2.047381464345922e-12\n",
      "Average reward for the last 100 iterations: -31.209213537431182\n",
      "epsilon: 1.8524546710863546e-12\n",
      "Average reward for the last 100 iterations: -35.097124248932786\n",
      "epsilon: 1.6760864392830427e-12\n",
      "Average reward for the last 100 iterations: -41.335812554346745\n",
      "epsilon: 1.5165098481470747e-12\n",
      "Average reward for the last 100 iterations: -36.382522240814986\n",
      "epsilon: 1.372126201624077e-12\n",
      "Average reward for the last 100 iterations: -38.48524498395027\n",
      "epsilon: 1.2414890120784275e-12\n",
      "Average reward for the last 100 iterations: -39.0238101012245\n",
      "epsilon: 1.1232895088565175e-12\n",
      "Average reward for the last 100 iterations: -28.868082283173102\n",
      "epsilon: 1.016343526548593e-12\n",
      "Average reward for the last 100 iterations: -30.561127626315116\n",
      "epsilon: 9.195796415910214e-13\n",
      "Average reward for the last 100 iterations: -27.161049670653092\n",
      "epsilon: 8.320284383571953e-13\n",
      "Average reward for the last 100 iterations: -27.42660247800913\n",
      "epsilon: 7.528127972008729e-13\n",
      "Average reward for the last 100 iterations: -29.107314014230482\n",
      "epsilon: 6.811391071540548e-13\n",
      "Average reward for the last 100 iterations: -38.89774937032716\n",
      "epsilon: 6.162893152450323e-13\n",
      "Average reward for the last 100 iterations: -25.301079957709117\n",
      "epsilon: 5.576137327837901e-13\n",
      "Average reward for the last 100 iterations: -30.478432691189017\n",
      "epsilon: 5.045245265455356e-13\n",
      "Average reward for the last 100 iterations: -25.88840284063754\n",
      "epsilon: 4.564898296446632e-13\n",
      "Average reward for the last 100 iterations: -26.03075658267976\n",
      "epsilon: 4.130284130997659e-13\n",
      "Average reward for the last 100 iterations: -31.57799829005164\n",
      "epsilon: 3.7370486470750513e-13\n",
      "Average reward for the last 100 iterations: -34.14765328452411\n",
      "epsilon: 3.3812522692554173e-13\n",
      "Average reward for the last 100 iterations: -34.900751956828614\n",
      "epsilon: 3.0593305006327097e-13\n",
      "Average reward for the last 100 iterations: -36.742456157700275\n",
      "epsilon: 2.7680582123979286e-13\n",
      "Average reward for the last 100 iterations: -22.74430149909766\n",
      "epsilon: 2.504517333331259e-13\n",
      "Average reward for the last 100 iterations: -32.398718119323874\n",
      "epsilon: 2.2660676155082918e-13\n",
      "Average reward for the last 100 iterations: -28.69600332006616\n",
      "epsilon: 2.050320183340591e-13\n",
      "Average reward for the last 100 iterations: -30.412873022884966\n",
      "epsilon: 1.8551136009553054e-13\n",
      "Average reward for the last 100 iterations: -30.390413783864837\n",
      "epsilon: 1.6784922181481952e-13\n",
      "Average reward for the last 100 iterations: -28.446680991606996\n",
      "epsilon: 1.518686577971957e-13\n",
      "Average reward for the last 100 iterations: -29.237560610764163\n",
      "epsilon: 1.374095689676017e-13\n",
      "Average reward for the last 100 iterations: -28.408836399239213\n",
      "epsilon: 1.243270989401656e-13\n",
      "Average reward for the last 100 iterations: -27.958509438968516\n",
      "epsilon: 1.1249018279449097e-13\n",
      "Average reward for the last 100 iterations: -27.537262969080565\n",
      "epsilon: 1.0178023401984112e-13\n"
     ]
    }
   ],
   "source": [
    "# adapted from CS 540 Spring 2023 HW 10\n",
    "EPISODES = 30000\n",
    "LEARNING_RATE = .1\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .999\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# starts with an estimate of zero reward for each state.\n",
    "# adapted from ChatGPT\n",
    "# the outer dictionary has keys of the string version of the given array, and \n",
    "# values of a dictionary for each of the actions that we could take at that state\n",
    "# Q_table = defaultdict(lambda: [0, 0, 0, 0])\n",
    "Q_table = CustomDefaultDict(default_value_for_key)\n",
    "\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [1, int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [0, 1, int(cur_row['val3'])], \n",
    "        [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        action = epsilon_greedy_search(Epsilon=EPSILON, qtable=Q_table, state=obs)\n",
    "\n",
    "        oldObs = obs\n",
    "        obs,reward,done = get_next_step(oldObs, action)\n",
    "        Q_table[(oldObs[0][1], oldObs[0][2], oldObs[1][2])][action] = (1-LEARNING_RATE) * Q_table[(oldObs[0][1], oldObs[0][2], oldObs[1][2])][action] + (LEARNING_RATE) * (reward + DISCOUNT_FACTOR * (max_a_prime(Q_table, obs)))\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if i%100 ==0 and i>0:\n",
    "        print(\"Average reward for the last 100 iterations: \" + str(sum(list(episode_reward_record))/100))\n",
    "        print(\"epsilon: \" + str(EPSILON) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1462643150000003,\n",
       " -1.1992856311378204,\n",
       " -1.1226688235294118,\n",
       " 16.56527361347188]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test = B@B@B@B@C\n",
    "\n",
    "def matrix_to_tuple(matrix):\n",
    "    return (matrix[0][1], matrix[0][2], matrix[1][2])\n",
    "\n",
    "Q_table[matrix_to_tuple(to_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(\"heisenberg_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val1\n",
      "val2\n",
      "val3\n",
      "last_matrix\n"
     ]
    }
   ],
   "source": [
    "for i in test_df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_matrix = np.array([[1, int(cur_row['val1']), int(cur_row['val2'])], [0, 1, int(cur_row['val3'])], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_num_steps(cur_matrix):\n",
    "    index = 1\n",
    "    for i in range(50):\n",
    "        if (cur_matrix==A).all() or (cur_matrix==B).all() or (cur_matrix==C).all() or (cur_matrix==D).all():\n",
    "            return i\n",
    "        outputs = Q_table[matrix_to_tuple(cur_matrix)]\n",
    "        # print(outputs)\n",
    "        # if outputs==[0, 0, 0, 0]:\n",
    "        #     # this is a problem because we haven't seen this state before \n",
    "        #     # in training so we have no idea how to handle it\n",
    "        #     print(\"Problem.\")\n",
    "        index = np.argmax(outputs)\n",
    "        if index==0:\n",
    "            cur_matrix = cur_matrix @ A\n",
    "        elif index==1:\n",
    "            cur_matrix = cur_matrix @ B\n",
    "        elif index==2:\n",
    "            cur_matrix = cur_matrix @ C\n",
    "        elif index==3:\n",
    "            cur_matrix = cur_matrix @ D\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q_learning(row):\n",
    "    cur_matrix = np.array([[1, int(row['val1']), int(row['val2'])], [0, 1, int(row['val3'])], [0, 0, 1]])\n",
    "    return matrix_to_num_steps(cur_matrix)\n",
    "\n",
    "test_df['num_moves_Q_learning_needs'] = test_df.apply(test_Q_learning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49084908490849083"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \")\n",
    "sum(test_df['num_moves_Q_learning_needs']!=100)/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of these, the proportion of times where we learned a path that was < 20 moves: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9973512632436837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Of these, the proportion of times where we learned a path that was < 20 moves: \")\n",
    "# encouraging because all of these were generated as sequences of 30 moves\n",
    "# so we've found significantly faster paths back to the origin for almost all moves that we find a path to the origin \n",
    "sum(test_df['num_moves_Q_learning_needs']<20)/sum(test_df['num_moves_Q_learning_needs']!=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test_df[test_df['num_moves_Q_learning_needs']!=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16089\\AppData\\Local\\Temp\\ipykernel_9300\\2622295422.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['num_moves_Q_learning_needs'] = filtered_df.apply(first_matrix_to_apply, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def first_matrix_to_apply(row):\n",
    "    outputs = Q_table[(int(row['val1']), int(row['val2']), int(row['val3']))]\n",
    "    return np.argmax(outputs)\n",
    "\n",
    "filtered_df['num_moves_Q_learning_needs'] = filtered_df.apply(first_matrix_to_apply, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4908"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = int(filtered_df.shape[0] * 0.6)\n",
    "plus_one = bound+1\n",
    "train = filtered_df.iloc[1:bound]\n",
    "test = filtered_df.iloc[plus_one:filtered_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"learned_Q_moves.csv\", index=False)\n",
    "test.to_csv(\"learned_Q_moves_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
