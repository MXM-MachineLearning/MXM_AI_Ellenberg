{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epsilon_greedy_search(Epsilon, qtable, state):\n",
    "    if (random.random() < Epsilon):\n",
    "        # 0 is 'apply matrix A', 1 is 'apply matrix B'\n",
    "        # 2 is 'apply matrix C', 3 is 'apply matrix D'\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    else:\n",
    "        # get the best move for the current state\n",
    "        return best_move_for_a_state(Q_table=qtable, state=state)\n",
    "    \n",
    "# I would like to return the best move for a given state\n",
    "def best_move_for_a_state(Q_table, state):\n",
    "    vals = Q_table[str(state)]\n",
    "\n",
    "    # if we haven't visited this state before, return a random choice of 0, 1, 2, or 3\n",
    "    if vals==[0, 0, 0, 0]:\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    \n",
    "    # if we have visited this state before, return the current best choice\n",
    "    return np.argmax(vals)\n",
    "\n",
    "# over a given state, return the maximum value of the table for that state\n",
    "def max_a_prime(Q_table, state):\n",
    "    return max(Q_table[str(state)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B is the inverse of A\n",
    "A = np.array([[1, 1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "B = np.array([[1, -1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "# C is the inverse of D\n",
    "C = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
    "D = np.array([[1, 0, 0], [0, 1, -1], [0, 0, 1]])\n",
    "\n",
    "# together, A, B, C, and D generate the heisenberg group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReward(matrix):\n",
    "    if (matrix==A).all() or (matrix==B).all() or (matrix==C).all() or (matrix==D).all():\n",
    "        return 20\n",
    "    else:\n",
    "        return -1 + 1/(2 + abs(matrix[0][1]) + abs(matrix[0][2]) + abs(matrix[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heisenberg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(oldObs, action):\n",
    "    # action is always either 0, 1, 2, or 3\n",
    "    next_state = []\n",
    "    if action==0:\n",
    "        next_state = oldObs @ A\n",
    "    elif action==1:\n",
    "        next_state = oldObs @ B\n",
    "    elif action==2:\n",
    "        next_state = oldObs @ C\n",
    "    else:\n",
    "        next_state = oldObs @ D\n",
    "    curReward = getReward(next_state)\n",
    "    done = curReward==20\n",
    "    return (next_state, curReward, done)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for the last 100 iterations: -94.84581157451171\n",
      "epsilon: 0.9038873549665959\n",
      "Average reward for the last 100 iterations: -94.44941621299665\n",
      "epsilon: 0.8178301806491574\n",
      "Average reward for the last 100 iterations: -92.23202317001227\n",
      "epsilon: 0.7399663251239436\n",
      "Average reward for the last 100 iterations: -93.05534316200347\n",
      "epsilon: 0.6695157201007336\n",
      "Average reward for the last 100 iterations: -88.70811567379366\n",
      "epsilon: 0.6057725659163237\n",
      "Average reward for the last 100 iterations: -86.86443128075612\n",
      "epsilon: 0.548098260578011\n",
      "Average reward for the last 100 iterations: -85.90764878882217\n",
      "epsilon: 0.4959150020176678\n",
      "Average reward for the last 100 iterations: -82.34057331625243\n",
      "epsilon: 0.44869999946146477\n",
      "Average reward for the last 100 iterations: -82.81209912684376\n",
      "epsilon: 0.4059802359226587\n",
      "Average reward for the last 100 iterations: -84.80373653089877\n",
      "epsilon: 0.36732772934619257\n",
      "Average reward for the last 100 iterations: -85.38248200602844\n",
      "epsilon: 0.33235524492954527\n",
      "Average reward for the last 100 iterations: -79.19835960182014\n",
      "epsilon: 0.3007124156643058\n",
      "Average reward for the last 100 iterations: -88.26283119318234\n",
      "epsilon: 0.2720822322326576\n",
      "Average reward for the last 100 iterations: -83.87576393544826\n",
      "epsilon: 0.2461778670932771\n",
      "Average reward for the last 100 iterations: -90.1164353479598\n",
      "epsilon: 0.22273980093919937\n",
      "Average reward for the last 100 iterations: -78.94381176765019\n",
      "epsilon: 0.2015332227394583\n",
      "Average reward for the last 100 iterations: -74.97035139745603\n",
      "epsilon: 0.18234567731717977\n",
      "Average reward for the last 100 iterations: -81.71050009451601\n",
      "epsilon: 0.1649849368967147\n",
      "Average reward for the last 100 iterations: -85.23000139228797\n",
      "epsilon: 0.14927707529619813\n",
      "Average reward for the last 100 iterations: -79.26807596837443\n",
      "epsilon: 0.13506472547210188\n",
      "Average reward for the last 100 iterations: -83.2193212530724\n",
      "epsilon: 0.12220550295922675\n",
      "Average reward for the last 100 iterations: -79.21834649082828\n",
      "epsilon: 0.11057057941158951\n",
      "Average reward for the last 100 iterations: -82.78820485953284\n",
      "epsilon: 0.10004339195341891\n",
      "Average reward for the last 100 iterations: -79.93952093225471\n",
      "epsilon: 0.09051847541007228\n",
      "Average reward for the last 100 iterations: -82.23888520115665\n",
      "epsilon: 0.08190040571973876\n",
      "Average reward for the last 100 iterations: -77.4117986872698\n",
      "epsilon: 0.07410284394064628\n",
      "Average reward for the last 100 iterations: -73.4172602575992\n",
      "epsilon: 0.06704767127628951\n",
      "Average reward for the last 100 iterations: -83.2946676003162\n",
      "epsilon: 0.060664206453048174\n",
      "Average reward for the last 100 iterations: -73.35508648325131\n",
      "epsilon: 0.05488849760960279\n",
      "Average reward for the last 100 iterations: -79.52367497350296\n",
      "epsilon: 0.049662681604038215\n",
      "Average reward for the last 100 iterations: -80.1109114306352\n",
      "epsilon: 0.04493440431994225\n",
      "Average reward for the last 100 iterations: -77.22572119354156\n",
      "epsilon: 0.04065629616391608\n",
      "Average reward for the last 100 iterations: -62.08768739626547\n",
      "epsilon: 0.03678549749984046\n",
      "Average reward for the last 100 iterations: -78.7752225772752\n",
      "epsilon: 0.03328322926552661\n",
      "Average reward for the last 100 iterations: -74.84236946067223\n",
      "epsilon: 0.030114404470033673\n",
      "Average reward for the last 100 iterations: -74.2892948829907\n",
      "epsilon: 0.027247276679492435\n",
      "Average reward for the last 100 iterations: -81.39131063850519\n",
      "epsilon: 0.024653121969839265\n",
      "Average reward for the last 100 iterations: -82.81261200223233\n",
      "epsilon: 0.022305951160147018\n",
      "Average reward for the last 100 iterations: -74.0587894163636\n",
      "epsilon: 0.02018224944360293\n",
      "Average reward for the last 100 iterations: -70.48117149953305\n",
      "epsilon: 0.018260740807661956\n",
      "Average reward for the last 100 iterations: -73.76166718597963\n",
      "epsilon: 0.016522174883251375\n",
      "Average reward for the last 100 iterations: -68.53404329145715\n",
      "epsilon: 0.014949134087605212\n",
      "Average reward for the last 100 iterations: -78.59980084549078\n",
      "epsilon: 0.01352585912861506\n",
      "Average reward for the last 100 iterations: -75.4932015724396\n",
      "epsilon: 0.012238091122537187\n",
      "Average reward for the last 100 iterations: -72.50808543488529\n",
      "epsilon: 0.011072928743333644\n",
      "Average reward for the last 100 iterations: -74.10850725988212\n",
      "epsilon: 0.010018698972517958\n",
      "Average reward for the last 100 iterations: -70.14223218634727\n",
      "epsilon: 0.009064840154630435\n",
      "Average reward for the last 100 iterations: -74.91523647650644\n",
      "epsilon: 0.008201796186750635\n",
      "Average reward for the last 100 iterations: -68.70477453587877\n",
      "epsilon: 0.007420920781999136\n",
      "Average reward for the last 100 iterations: -67.51812826543642\n",
      "epsilon: 0.006714390847905742\n",
      "Average reward for the last 100 iterations: -80.75209851944193\n",
      "epsilon: 0.006075128111837272\n",
      "Average reward for the last 100 iterations: -73.40011081501814\n",
      "epsilon: 0.005496728208300101\n",
      "Average reward for the last 100 iterations: -68.9847624224026\n",
      "epsilon: 0.004973396517688337\n",
      "Average reward for the last 100 iterations: -64.56236357435483\n",
      "epsilon: 0.004499890113687073\n",
      "Average reward for the last 100 iterations: -66.48784085871371\n",
      "epsilon: 0.004071465237738676\n",
      "Average reward for the last 100 iterations: -63.54700031421537\n",
      "epsilon: 0.003683829774352405\n",
      "Average reward for the last 100 iterations: -74.35337339143918\n",
      "epsilon: 0.0033331002511377216\n",
      "Average reward for the last 100 iterations: -61.94020093815554\n",
      "epsilon: 0.003015762932772144\n",
      "Average reward for the last 100 iterations: -67.92767435051677\n",
      "epsilon: 0.002728638619128845\n",
      "Average reward for the last 100 iterations: -67.22633091139822\n",
      "epsilon: 0.0024688507948989738\n",
      "Average reward for the last 100 iterations: -69.58788334737524\n",
      "epsilon: 0.0022337968116200296\n",
      "Average reward for the last 100 iterations: -76.8176157945806\n",
      "epsilon: 0.0020211218134014433\n",
      "Average reward for the last 100 iterations: -71.7426205183145\n",
      "epsilon: 0.0018286951451258438\n",
      "Average reward for the last 100 iterations: -71.9141252675286\n",
      "epsilon: 0.0016545890067748276\n",
      "Average reward for the last 100 iterations: -64.82052117460802\n",
      "epsilon: 0.0014970591400305351\n",
      "Average reward for the last 100 iterations: -63.01409277934609\n",
      "epsilon: 0.001354527353664429\n",
      "Average reward for the last 100 iterations: -68.14593344051326\n",
      "epsilon: 0.001225565712646288\n",
      "Average reward for the last 100 iterations: -68.24081340632756\n",
      "epsilon: 0.0011088822325741772\n",
      "Average reward for the last 100 iterations: -74.19336310396757\n",
      "epsilon: 0.0010033079361070328\n",
      "Average reward for the last 100 iterations: -64.96242447450678\n",
      "epsilon: 0.0009077851417265054\n",
      "Average reward for the last 100 iterations: -66.4362118332469\n",
      "epsilon: 0.0008213568675006472\n",
      "Average reward for the last 100 iterations: -62.53137677520554\n",
      "epsilon: 0.0007431572436925013\n",
      "Average reward for the last 100 iterations: -67.07960388311044\n",
      "epsilon: 0.0006724028381636441\n",
      "Average reward for the last 100 iterations: -69.08122820649622\n",
      "epsilon: 0.0006083848076674359\n",
      "Average reward for the last 100 iterations: -56.181249485307234\n",
      "epsilon: 0.0005504617964007802\n",
      "Average reward for the last 100 iterations: -65.33565945656964\n",
      "epsilon: 0.0004980535106695312\n",
      "Average reward for the last 100 iterations: -71.07026804973408\n",
      "epsilon: 0.00045063490529620545\n",
      "Average reward for the last 100 iterations: -71.01964261316655\n",
      "epsilon: 0.00040773092352733666\n",
      "Average reward for the last 100 iterations: -68.94412927928278\n",
      "epsilon: 0.00036891173774295443\n",
      "Average reward for the last 100 iterations: -63.648392161010285\n",
      "epsilon: 0.0003337884432878974\n",
      "Average reward for the last 100 iterations: -61.54781260748595\n",
      "epsilon: 0.00030200916228419905\n",
      "Average reward for the last 100 iterations: -58.8817733337973\n",
      "epsilon: 0.0002732555183911334\n",
      "Average reward for the last 100 iterations: -58.10643125435234\n",
      "epsilon: 0.0002472394471957831\n",
      "Average reward for the last 100 iterations: -61.73894779028009\n",
      "epsilon: 0.000223700310279479\n",
      "Average reward for the last 100 iterations: -57.1548351989305\n",
      "epsilon: 0.00020240228404777254\n",
      "Average reward for the last 100 iterations: -64.05909139968135\n",
      "epsilon: 0.00018313199716430296\n",
      "Average reward for the last 100 iterations: -63.73578569929091\n",
      "epsilon: 0.0001656963929195113\n",
      "Average reward for the last 100 iterations: -65.21281898421711\n",
      "epsilon: 0.00014992079511864147\n",
      "Average reward for the last 100 iterations: -67.04478446152966\n",
      "epsilon: 0.0001356471581123901\n",
      "Average reward for the last 100 iterations: -55.30757070294037\n",
      "epsilon: 0.00012273248343838214\n",
      "Average reward for the last 100 iterations: -61.901751720360245\n",
      "epsilon: 0.00011104738721081156\n",
      "Average reward for the last 100 iterations: -64.50916686415123\n",
      "epsilon: 0.00010047480390583761\n",
      "Average reward for the last 100 iterations: -59.182035043027234\n",
      "epsilon: 9.090881355679163e-05\n",
      "Average reward for the last 100 iterations: -64.5498343451364\n",
      "epsilon: 8.225358060960925e-05\n",
      "Average reward for the last 100 iterations: -46.67874124146221\n",
      "epsilon: 7.44223938075589e-05\n",
      "Average reward for the last 100 iterations: -66.25384933696908\n",
      "epsilon: 6.733679748648316e-05\n",
      "Average reward for the last 100 iterations: -62.3216387019953\n",
      "epsilon: 6.09258055775561e-05\n",
      "Average reward for the last 100 iterations: -56.234056972860344\n",
      "epsilon: 5.512519044314936e-05\n",
      "Average reward for the last 100 iterations: -56.26588579989087\n",
      "epsilon: 4.9876839421109216e-05\n",
      "Average reward for the last 100 iterations: -56.411695660880426\n",
      "epsilon: 4.5128172631071065e-05\n",
      "Average reward for the last 100 iterations: -54.81638034819886\n",
      "epsilon: 4.083161621018491e-05\n",
      "Average reward for the last 100 iterations: -61.35556323940652\n",
      "epsilon: 3.69441257009361e-05\n",
      "Average reward for the last 100 iterations: -54.355302146742396\n",
      "epsilon: 3.3426754816188734e-05\n",
      "Average reward for the last 100 iterations: -71.02369776608424\n",
      "epsilon: 3.0244265261182943e-05\n",
      "Average reward for the last 100 iterations: -54.46925070486862\n",
      "epsilon: 2.7364773703542285e-05\n",
      "Average reward for the last 100 iterations: -69.97755650548078\n",
      "epsilon: 2.4759432354508794e-05\n",
      "Average reward for the last 100 iterations: -60.03477731474202\n",
      "epsilon: 2.2402139961352654e-05\n",
      "Average reward for the last 100 iterations: -51.161203847869075\n",
      "epsilon: 2.0269280315574096e-05\n",
      "Average reward for the last 100 iterations: -45.48197890361339\n",
      "epsilon: 1.8339485657177917e-05\n",
      "Average reward for the last 100 iterations: -55.96696866599456\n",
      "epsilon: 1.659342260471908e-05\n",
      "Average reward for the last 100 iterations: -54.33801311616081\n",
      "epsilon: 1.501359846648893e-05\n",
      "Average reward for the last 100 iterations: -55.222670507164324\n",
      "epsilon: 1.3584185992397611e-05\n",
      "Average reward for the last 100 iterations: -59.38236417646323\n",
      "epsilon: 1.2290864810853405e-05\n",
      "Average reward for the last 100 iterations: -50.397816044231476\n",
      "epsilon: 1.1120677962096389e-05\n",
      "Average reward for the last 100 iterations: -57.4647215042699\n",
      "epsilon: 1.006190209068529e-05\n",
      "Average reward for the last 100 iterations: -54.66778830373113\n",
      "epsilon: 9.103929996679068e-06\n",
      "Average reward for the last 100 iterations: -50.84123978075078\n",
      "epsilon: 8.23716436886816e-06\n",
      "Average reward for the last 100 iterations: -54.61971575576742\n",
      "epsilon: 7.452921635436766e-06\n",
      "Average reward for the last 100 iterations: -53.4495784884172\n",
      "epsilon: 6.743344968797045e-06\n",
      "Average reward for the last 100 iterations: -57.210621785836594\n",
      "epsilon: 6.101325573046306e-06\n",
      "Average reward for the last 100 iterations: -57.38176436688904\n",
      "epsilon: 5.5204314654763466e-06\n",
      "Average reward for the last 100 iterations: -46.6011305974964\n",
      "epsilon: 4.994843038642421e-06\n",
      "Average reward for the last 100 iterations: -52.194950514381816\n",
      "epsilon: 4.519294757429241e-06\n",
      "Average reward for the last 100 iterations: -50.133286631741896\n",
      "epsilon: 4.089022407014129e-06\n",
      "Average reward for the last 100 iterations: -59.15701885580672\n",
      "epsilon: 3.6997153632383808e-06\n",
      "Average reward for the last 100 iterations: -56.18896978125453\n",
      "epsilon: 3.3474734072140295e-06\n",
      "Average reward for the last 100 iterations: -59.58641486886866\n",
      "epsilon: 3.0287676515192263e-06\n",
      "Average reward for the last 100 iterations: -49.25421762468383\n",
      "epsilon: 2.7404051865266284e-06\n",
      "Average reward for the last 100 iterations: -49.85704145967796\n",
      "epsilon: 2.4794970926789746e-06\n",
      "Average reward for the last 100 iterations: -56.032491761931176\n",
      "epsilon: 2.243429498247208e-06\n",
      "Average reward for the last 100 iterations: -53.80402542319347\n",
      "epsilon: 2.0298373926173216e-06\n",
      "Average reward for the last 100 iterations: -54.0379462830182\n",
      "epsilon: 1.83658093275792e-06\n",
      "Average reward for the last 100 iterations: -49.98135219048359\n",
      "epsilon: 1.6617240054981357e-06\n",
      "Average reward for the last 100 iterations: -49.99326436685547\n",
      "epsilon: 1.5035148308450506e-06\n",
      "Average reward for the last 100 iterations: -52.368894744333005\n",
      "epsilon: 1.3603684120175983e-06\n",
      "Average reward for the last 100 iterations: -44.54858826325851\n",
      "epsilon: 1.2308506563750686e-06\n",
      "Average reward for the last 100 iterations: -56.70140090717061\n",
      "epsilon: 1.1136640081579159e-06\n",
      "Average reward for the last 100 iterations: -55.56031382465919\n",
      "epsilon: 1.0076344491044587e-06\n",
      "Average reward for the last 100 iterations: -42.7488631841627\n",
      "epsilon: 9.116997367109624e-07\n",
      "Average reward for the last 100 iterations: -39.05408073223993\n",
      "epsilon: 8.248987623017148e-07\n",
      "Average reward for the last 100 iterations: -49.60102581873205\n",
      "epsilon: 7.463619222944092e-07\n",
      "Average reward for the last 100 iterations: -50.05539740330372\n",
      "epsilon: 6.753024061966736e-07\n",
      "Average reward for the last 100 iterations: -54.17613099693577\n",
      "epsilon: 6.110083140537422e-07\n",
      "Average reward for the last 100 iterations: -46.47857787485809\n",
      "epsilon: 5.528355243770125e-07\n",
      "Average reward for the last 100 iterations: -48.23131611003481\n",
      "epsilon: 5.002012411018101e-07\n",
      "Average reward for the last 100 iterations: -30.013487081685735\n",
      "epsilon: 4.5257815492544905e-07\n",
      "Average reward for the last 100 iterations: -52.72515785673543\n",
      "epsilon: 4.094891605317576e-07\n",
      "Average reward for the last 100 iterations: -53.843266391697874\n",
      "epsilon: 3.7050257677731924e-07\n",
      "Average reward for the last 100 iterations: -52.649018891041436\n",
      "epsilon: 3.3522782195351267e-07\n",
      "Average reward for the last 100 iterations: -46.70957435982998\n",
      "epsilon: 3.033115007975709e-07\n",
      "Average reward for the last 100 iterations: -57.762651861468356\n",
      "epsilon: 2.7443386405091567e-07\n",
      "Average reward for the last 100 iterations: -47.61275999678986\n",
      "epsilon: 2.4830560509533956e-07\n",
      "Average reward for the last 100 iterations: -55.340131351003656\n",
      "epsilon: 2.246649615745811e-07\n",
      "Average reward for the last 100 iterations: -42.38420503368496\n",
      "epsilon: 2.032750929642842e-07\n",
      "Average reward for the last 100 iterations: -50.406019533455925\n",
      "epsilon: 1.8392170781789347e-07\n",
      "Average reward for the last 100 iterations: -41.25738958854238\n",
      "epsilon: 1.6641091691737205e-07\n",
      "Average reward for the last 100 iterations: -63.30812586484858\n",
      "epsilon: 1.5056729082083014e-07\n",
      "Average reward for the last 100 iterations: -44.885003301305424\n",
      "epsilon: 1.3623210234687325e-07\n",
      "Average reward for the last 100 iterations: -40.53961949366257\n",
      "epsilon: 1.2326173638824198e-07\n",
      "Average reward for the last 100 iterations: -41.61290926287249\n",
      "epsilon: 1.1152625112368151e-07\n",
      "Average reward for the last 100 iterations: -43.518005231666294\n",
      "epsilon: 1.0090807621373846e-07\n",
      "Average reward for the last 100 iterations: -35.22985213357119\n",
      "epsilon: 9.130083493854227e-08\n",
      "Average reward for the last 100 iterations: -48.87549029154326\n",
      "epsilon: 8.260827847731793e-08\n",
      "Average reward for the last 100 iterations: -49.42875630270526\n",
      "epsilon: 7.474332165285969e-08\n",
      "Average reward for the last 100 iterations: -45.072369645949244\n",
      "epsilon: 6.762717048070146e-08\n",
      "Average reward for the last 100 iterations: -42.36529364068993\n",
      "epsilon: 6.118853278245869e-08\n",
      "Average reward for the last 100 iterations: -54.66575549046386\n",
      "epsilon: 5.5362903954978386e-08\n",
      "Average reward for the last 100 iterations: -48.74556852178804\n",
      "epsilon: 5.009192073987496e-08\n",
      "Average reward for the last 100 iterations: -49.80428820074527\n",
      "epsilon: 4.532277651928118e-08\n",
      "Average reward for the last 100 iterations: -41.33032807293397\n",
      "epsilon: 4.100769228003525e-08\n",
      "Average reward for the last 100 iterations: -54.48786273241782\n",
      "epsilon: 3.710343794623138e-08\n",
      "Average reward for the last 100 iterations: -54.23279974179711\n",
      "epsilon: 3.357089928467093e-08\n",
      "Average reward for the last 100 iterations: -44.969973156829774\n",
      "epsilon: 3.037468604431549e-08\n",
      "Average reward for the last 100 iterations: -50.728418224136384\n",
      "epsilon: 2.748277740394102e-08\n",
      "Average reward for the last 100 iterations: -54.028897342337046\n",
      "epsilon: 2.4866201175959905e-08\n",
      "Average reward for the last 100 iterations: -33.718521950726455\n",
      "epsilon: 2.2498743552558194e-08\n",
      "Average reward for the last 100 iterations: -48.441104581606496\n",
      "epsilon: 2.0356686486279826e-08\n",
      "Average reward for the last 100 iterations: -41.159072850339314\n",
      "epsilon: 1.8418570074041747e-08\n",
      "Average reward for the last 100 iterations: -50.652855572348614\n",
      "epsilon: 1.666497756405654e-08\n",
      "Average reward for the last 100 iterations: -38.9779748273354\n",
      "epsilon: 1.5078340831784492e-08\n",
      "Average reward for the last 100 iterations: -34.18610009651113\n",
      "epsilon: 1.3642764376102604e-08\n",
      "Average reward for the last 100 iterations: -51.31289594158879\n",
      "epsilon: 1.2343866072420293e-08\n",
      "Average reward for the last 100 iterations: -39.46472526466644\n",
      "epsilon: 1.116863308734923e-08\n",
      "Average reward for the last 100 iterations: -36.932917675125545\n",
      "epsilon: 1.0105291511427924e-08\n",
      "Average reward for the last 100 iterations: -39.858632164395146\n",
      "epsilon: 9.143188403834803e-09\n",
      "Average reward for the last 100 iterations: -33.33383721195736\n",
      "epsilon: 8.272685067370861e-09\n",
      "Average reward for the last 100 iterations: -42.3470440177408\n",
      "epsilon: 7.485060484501997e-09\n",
      "Average reward for the last 100 iterations: -44.698786324690644\n",
      "epsilon: 6.77242394704854e-09\n",
      "Average reward for the last 100 iterations: -37.38867115965462\n",
      "epsilon: 6.127636004214353e-09\n",
      "Average reward for the last 100 iterations: -35.997275583188014\n",
      "epsilon: 5.544236936984372e-09\n",
      "Average reward for the last 100 iterations: -42.861410685378395\n",
      "epsilon: 5.016382042321222e-09\n",
      "Average reward for the last 100 iterations: -46.98547671199995\n",
      "epsilon: 4.53878307881447e-09\n",
      "Average reward for the last 100 iterations: -50.10521961982231\n",
      "epsilon: 4.10665528716391e-09\n",
      "Average reward for the last 100 iterations: -46.386456462885214\n",
      "epsilon: 3.7156694547289007e-09\n",
      "Average reward for the last 100 iterations: -45.47205256454443\n",
      "epsilon: 3.3619085439089865e-09\n",
      "Average reward for the last 100 iterations: -42.07016500231063\n",
      "epsilon: 3.0418284498433344e-09\n",
      "Average reward for the last 100 iterations: -32.80977867791976\n",
      "epsilon: 2.7522224942853162e-09\n",
      "Average reward for the last 100 iterations: -37.693712690446716\n",
      "epsilon: 2.4901892999390573e-09\n",
      "Average reward for the last 100 iterations: -39.65697189450909\n",
      "epsilon: 2.2531037234114447e-09\n",
      "Average reward for the last 100 iterations: -49.46069637786222\n",
      "epsilon: 2.038590555575333e-09\n",
      "Average reward for the last 100 iterations: -48.386798547945254\n",
      "epsilon: 1.8445007258647328e-09\n",
      "Average reward for the last 100 iterations: -41.19467523891211\n",
      "epsilon: 1.6688897721079462e-09\n",
      "Average reward for the last 100 iterations: -40.94923319440804\n",
      "epsilon: 1.5099983602016576e-09\n",
      "Average reward for the last 100 iterations: -41.595929503620944\n",
      "epsilon: 1.3662346584650378e-09\n",
      "Average reward for the last 100 iterations: -35.951302041631536\n",
      "epsilon: 1.2361583900937467e-09\n",
      "Average reward for the last 100 iterations: -39.04788026165835\n",
      "epsilon: 1.1184664039455474e-09\n",
      "Average reward for the last 100 iterations: -44.89868867905138\n",
      "epsilon: 1.011979619100441e-09\n",
      "Average reward for the last 100 iterations: -32.204367179267706\n",
      "epsilon: 9.15631212401201e-10\n",
      "Average reward for the last 100 iterations: -42.379716832230095\n",
      "epsilon: 8.284559306328114e-10\n",
      "Average reward for the last 100 iterations: -41.93321732677915\n",
      "epsilon: 7.495804202663469e-10\n",
      "Average reward for the last 100 iterations: -40.33392108693512\n",
      "epsilon: 6.782144778871841e-10\n",
      "Average reward for the last 100 iterations: -43.15887158132335\n",
      "epsilon: 6.136431336511485e-10\n",
      "Average reward for the last 100 iterations: -38.69955028899312\n",
      "epsilon: 5.552194884578073e-10\n",
      "Average reward for the last 100 iterations: -40.7612012432539\n",
      "epsilon: 5.023582330811142e-10\n",
      "Average reward for the last 100 iterations: -37.66421966144399\n",
      "epsilon: 4.545297843297102e-10\n",
      "Average reward for the last 100 iterations: -35.94938660918493\n",
      "epsilon: 4.1125497949080954e-10\n",
      "Average reward for the last 100 iterations: -35.21003458399849\n",
      "epsilon: 3.7210027590469397e-10\n",
      "Average reward for the last 100 iterations: -33.98609927193563\n",
      "epsilon: 3.366734075774115e-10\n",
      "Average reward for the last 100 iterations: -31.469235558941392\n",
      "epsilon: 3.0461945531805506e-10\n",
      "Average reward for the last 100 iterations: -47.52642709264355\n",
      "epsilon: 2.7561729102983154e-10\n",
      "Average reward for the last 100 iterations: -37.41180129748135\n",
      "epsilon: 2.493763605325452e-10\n",
      "Average reward for the last 100 iterations: -32.28804248658325\n",
      "epsilon: 2.2563377268564379e-10\n",
      "Average reward for the last 100 iterations: -28.70530063983696\n",
      "epsilon: 2.0415166564961023e-10\n",
      "Average reward for the last 100 iterations: -37.08158062169082\n",
      "epsilon: 1.8471482389995092e-10\n",
      "Average reward for the last 100 iterations: -38.673847788576765\n",
      "epsilon: 1.6712852212016722e-10\n",
      "Average reward for the last 100 iterations: -36.38681637465434\n",
      "epsilon: 1.5121657437304705e-10\n",
      "Average reward for the last 100 iterations: -33.010107713934865\n",
      "epsilon: 1.3681956900616914e-10\n",
      "Average reward for the last 100 iterations: -40.751937120291196\n",
      "epsilon: 1.2379327160826409e-10\n",
      "Average reward for the last 100 iterations: -41.17076785004894\n",
      "epsilon: 1.1200718001667172e-10\n",
      "Average reward for the last 100 iterations: -39.69291925009984\n",
      "epsilon: 1.0134321689943615e-10\n",
      "Average reward for the last 100 iterations: -33.43115323148161\n",
      "epsilon: 9.169454681385119e-11\n",
      "Average reward for the last 100 iterations: -35.657322113919484\n",
      "epsilon: 8.296450589032293e-11\n",
      "Average reward for the last 100 iterations: -41.16085052069762\n",
      "epsilon: 7.506563341873329e-11\n",
      "Average reward for the last 100 iterations: -29.154751723042267\n",
      "epsilon: 6.79187956353863e-11\n",
      "Average reward for the last 100 iterations: -37.64623468293687\n",
      "epsilon: 6.145239293231837e-11\n",
      "Average reward for the last 100 iterations: -36.46385042108647\n",
      "epsilon: 5.560164254650765e-11\n",
      "Average reward for the last 100 iterations: -45.26964587783206\n",
      "epsilon: 5.0307929542703596e-11\n",
      "Average reward for the last 100 iterations: -39.22733780056207\n",
      "epsilon: 4.551821958778797e-11\n",
      "Average reward for the last 100 iterations: -45.529919514911484\n",
      "epsilon: 4.118452763362796e-11\n",
      "Average reward for the last 100 iterations: -36.495368917606925\n",
      "epsilon: 3.726343718549409e-11\n",
      "Average reward for the last 100 iterations: -43.13341851973532\n",
      "epsilon: 3.3715665339900035e-11\n",
      "Average reward for the last 100 iterations: -38.04002816660291\n",
      "epsilon: 3.050566923425541e-11\n",
      "Average reward for the last 100 iterations: -35.45943460577802\n",
      "epsilon: 2.7601289965602556e-11\n",
      "Average reward for the last 100 iterations: -31.27327909101718\n",
      "epsilon: 2.4973430411085592e-11\n",
      "Average reward for the last 100 iterations: -39.514787439180246\n",
      "epsilon: 2.2595763722440924e-11\n",
      "Average reward for the last 100 iterations: -32.37812667410171\n",
      "epsilon: 2.044446957410138e-11\n",
      "Average reward for the last 100 iterations: -29.39330540906488\n",
      "epsilon: 1.849799552255208e-11\n",
      "Average reward for the last 100 iterations: -35.26378563827035\n",
      "epsilon: 1.6736841086149672e-11\n",
      "Average reward for the last 100 iterations: -41.51764901467459\n",
      "epsilon: 1.5143362382238333e-11\n",
      "Average reward for the last 100 iterations: -31.218771386350486\n",
      "epsilon: 1.3701595364346396e-11\n",
      "Average reward for the last 100 iterations: -47.101063104929544\n",
      "epsilon: 1.2397095888590217e-11\n",
      "Average reward for the last 100 iterations: -29.914419491799684\n",
      "epsilon: 1.1216795007012077e-11\n",
      "Average reward for the last 100 iterations: -29.611078291748708\n",
      "epsilon: 1.0148868038128785e-11\n",
      "Average reward for the last 100 iterations: -40.56053481754996\n",
      "epsilon: 9.182616102992242e-12\n",
      "Average reward for the last 100 iterations: -30.07218963071091\n",
      "epsilon: 8.308358939947264e-12\n",
      "Average reward for the last 100 iterations: -36.117307246932114\n",
      "epsilon: 7.517337924266262e-12\n",
      "Average reward for the last 100 iterations: -33.96909645844207\n",
      "epsilon: 6.801628321076183e-12\n",
      "Average reward for the last 100 iterations: -39.349438524781824\n",
      "epsilon: 6.1540598924959294e-12\n",
      "Average reward for the last 100 iterations: -28.456361644460024\n",
      "epsilon: 5.568145063597754e-12\n",
      "Average reward for the last 100 iterations: -37.78829283486813\n",
      "epsilon: 5.0380139275332125e-12\n",
      "Average reward for the last 100 iterations: -27.63765370486257\n",
      "epsilon: 4.558355438681547e-12\n",
      "Average reward for the last 100 iterations: -34.23863965041468\n",
      "epsilon: 4.12436420467213e-12\n",
      "Average reward for the last 100 iterations: -37.02396525286517\n",
      "epsilon: 3.731692344224219e-12\n",
      "Average reward for the last 100 iterations: -31.078962247862435\n",
      "epsilon: 3.3764059284984217e-12\n",
      "Average reward for the last 100 iterations: -35.68348737033997\n",
      "epsilon: 3.0549455695735444e-12\n",
      "Average reward for the last 100 iterations: -32.81248062080463\n",
      "epsilon: 2.76409076120996e-12\n",
      "Average reward for the last 100 iterations: -30.9152621740212\n",
      "epsilon: 2.500927614652326e-12\n",
      "Average reward for the last 100 iterations: -30.787967204966822\n",
      "epsilon: 2.262819666237245e-12\n",
      "Average reward for the last 100 iterations: -44.64124324643723\n",
      "epsilon: 2.047381464345922e-12\n",
      "Average reward for the last 100 iterations: -35.30235063274479\n",
      "epsilon: 1.8524546710863546e-12\n",
      "Average reward for the last 100 iterations: -32.06140088425868\n",
      "epsilon: 1.6760864392830427e-12\n",
      "Average reward for the last 100 iterations: -33.38167516410558\n",
      "epsilon: 1.5165098481470747e-12\n",
      "Average reward for the last 100 iterations: -35.31580616547494\n",
      "epsilon: 1.372126201624077e-12\n",
      "Average reward for the last 100 iterations: -30.569880781984917\n",
      "epsilon: 1.2414890120784275e-12\n",
      "Average reward for the last 100 iterations: -30.361024855864592\n",
      "epsilon: 1.1232895088565175e-12\n",
      "Average reward for the last 100 iterations: -29.980872605450458\n",
      "epsilon: 1.016343526548593e-12\n",
      "Average reward for the last 100 iterations: -27.90595409249996\n",
      "epsilon: 9.195796415910214e-13\n",
      "Average reward for the last 100 iterations: -36.273294648942844\n",
      "epsilon: 8.320284383571953e-13\n",
      "Average reward for the last 100 iterations: -29.86511012567962\n",
      "epsilon: 7.528127972008729e-13\n",
      "Average reward for the last 100 iterations: -36.30971331477073\n",
      "epsilon: 6.811391071540548e-13\n",
      "Average reward for the last 100 iterations: -27.566026506957172\n",
      "epsilon: 6.162893152450323e-13\n",
      "Average reward for the last 100 iterations: -34.8451482324292\n",
      "epsilon: 5.576137327837901e-13\n",
      "Average reward for the last 100 iterations: -29.294395287695032\n",
      "epsilon: 5.045245265455356e-13\n",
      "Average reward for the last 100 iterations: -34.5974604151122\n",
      "epsilon: 4.564898296446632e-13\n",
      "Average reward for the last 100 iterations: -41.116726707601316\n",
      "epsilon: 4.130284130997659e-13\n",
      "Average reward for the last 100 iterations: -38.798607784701694\n",
      "epsilon: 3.7370486470750513e-13\n",
      "Average reward for the last 100 iterations: -28.35263311455523\n",
      "epsilon: 3.3812522692554173e-13\n",
      "Average reward for the last 100 iterations: -32.336668759438474\n",
      "epsilon: 3.0593305006327097e-13\n",
      "Average reward for the last 100 iterations: -30.481352519346302\n",
      "epsilon: 2.7680582123979286e-13\n",
      "Average reward for the last 100 iterations: -31.8309097118524\n",
      "epsilon: 2.504517333331259e-13\n",
      "Average reward for the last 100 iterations: -21.647554099560185\n",
      "epsilon: 2.2660676155082918e-13\n",
      "Average reward for the last 100 iterations: -20.03474435787012\n",
      "epsilon: 2.050320183340591e-13\n",
      "Average reward for the last 100 iterations: -30.095589172093497\n",
      "epsilon: 1.8551136009553054e-13\n",
      "Average reward for the last 100 iterations: -34.27080452650442\n",
      "epsilon: 1.6784922181481952e-13\n",
      "Average reward for the last 100 iterations: -25.161233159658615\n",
      "epsilon: 1.518686577971957e-13\n",
      "Average reward for the last 100 iterations: -45.05307643226615\n",
      "epsilon: 1.374095689676017e-13\n",
      "Average reward for the last 100 iterations: -27.011778027662814\n",
      "epsilon: 1.243270989401656e-13\n",
      "Average reward for the last 100 iterations: -34.174025559175234\n",
      "epsilon: 1.1249018279449097e-13\n",
      "Average reward for the last 100 iterations: -40.346893085280996\n",
      "epsilon: 1.0178023401984112e-13\n"
     ]
    }
   ],
   "source": [
    "# adapted from CS 540 Spring 2023 HW 10\n",
    "EPISODES = 30000\n",
    "LEARNING_RATE = .1\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .999\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# starts with an estimate of zero reward for each state.\n",
    "# adapted from ChatGPT\n",
    "# the outer dictionary has keys of the string version of the given array, and \n",
    "# values of a dictionary for each of the actions that we could take at that state\n",
    "Q_table = defaultdict(lambda: [0, 0, 0, 0]) \n",
    "\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [1, int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [0, 1, int(cur_row['val3'])], \n",
    "        [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        action = epsilon_greedy_search(Epsilon=EPSILON, qtable=Q_table, state=obs)\n",
    "\n",
    "        oldObs = obs\n",
    "        obs,reward,done = get_next_step(oldObs, action)\n",
    "        Q_table[str(oldObs)][action] = (1-LEARNING_RATE) * Q_table[str(oldObs)][action] + (LEARNING_RATE) * (reward + DISCOUNT_FACTOR * (max_a_prime(Q_table, obs)))\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if i%100 ==0 and i>0:\n",
    "        print(\"Average reward for the last 100 iterations: \" + str(sum(list(episode_reward_record))/100))\n",
    "        print(\"epsilon: \" + str(EPSILON) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.99999999999999,\n",
       " 0.0008089479999999982,\n",
       " 1.4744393101090116,\n",
       " 0.3702767568863788]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table[str(B@B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(\"heisenberg_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df\n",
    "cur_row = test_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_matrix = np.array([[1, int(cur_row['val1']), int(cur_row['val2'])], [0, 1, int(cur_row['val3'])], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -5, 41],\n",
       "       [ 0,  1, -8],\n",
       "       [ 0,  0,  1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = Q_table[str(cur_matrix)]\n",
    "if outputs==[0, 0, 0, 0]:\n",
    "    print(\"Problem.\")\n",
    "index = np.argmax(outputs)\n",
    "new_matrix = cur_matrix\n",
    "if index==0:\n",
    "    new_matrix = cur_matrix @ A\n",
    "elif index==1:\n",
    "    new_matrix = cur_matrix @ B\n",
    "elif index==2:\n",
    "    new_matrix = cur_matrix @ C\n",
    "elif index==3:\n",
    "    new_matrix = cur_matrix @ D\n",
    "\n",
    "cur_matrix = new_matrix\n",
    "new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_num_steps(cur_matrix):\n",
    "    index = 1\n",
    "    for i in range(50):\n",
    "        if (cur_matrix==A).all() or (cur_matrix==B).all() or (cur_matrix==C).all() or (cur_matrix==D).all():\n",
    "            return i\n",
    "        outputs = Q_table[str(cur_matrix)]\n",
    "        print(outputs)\n",
    "        if outputs==[0, 0, 0, 0]:\n",
    "            # this is a problem because we haven't seen this state before \n",
    "            # in training so we have no idea how to handle it\n",
    "            print(\"Problem.\")\n",
    "        index = np.argmax(outputs)\n",
    "        if index==0:\n",
    "            cur_matrix = cur_matrix @ A\n",
    "        elif index==1:\n",
    "            cur_matrix = cur_matrix @ B\n",
    "        elif index==2:\n",
    "            cur_matrix = cur_matrix @ C\n",
    "        elif index==3:\n",
    "            cur_matrix = cur_matrix @ D\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -2 -1]\n",
      " [ 0  1  1]\n",
      " [ 0  0  1]]\n",
      "[-0.21680000000000005, -0.25810473428571434, -0.28254638208174604, -0.19046711425327917]\n",
      "[12.325334272250958, -0.15833333333333335, -0.24144704761904767, -0.17613209000000002]\n",
      "[-0.1407741666666667, -0.08742500000000002, 18.4429905118514, -0.23431904761904765]\n",
      "[19.99999999999999, 1.3336181919354897, 6.369154925478906, 0.32662102670568594]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(B@C@B)\n",
    "\n",
    "matrix_to_num_steps(B@C@B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 1]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymat = B@B@C@B@D@A@A@C@A\n",
    "print(mymat)\n",
    "\n",
    "Q_table[str(mymat)]\n",
    "\n",
    "# cur_matrix = D@D@B@D@A\n",
    "\n",
    "# matrix_to_num_steps(B@B@C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2,  1],\n",
       "       [ 0,  1,  0],\n",
       "       [ 0,  0,  1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B@B@C@B@D@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\16089\\Downloads\\MXM\\heisenberg_group\\Donald\\Q_learning_to_origin.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/16089/Downloads/MXM/heisenberg_group/Donald/Q_learning_to_origin.ipynb#X61sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [output1, output2, output3, output4]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/16089/Downloads/MXM/heisenberg_group/Donald/Q_learning_to_origin.ipynb#X61sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m custom_dict \u001b[39m=\u001b[39m CustomDefaultDict(default_value_for_key)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/16089/Downloads/MXM/heisenberg_group/Donald/Q_learning_to_origin.ipynb#X61sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m custom_dict[\u001b[39mlist\u001b[39;49m(A\u001b[39m@A\u001b[39;49m)]\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# adapted from ChatGPT\n",
    "class CustomDefaultDict(dict):\n",
    "    def __init__(self, default_factory, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        # Compute the default value based on the missing key\n",
    "        default_value = self.default_factory(key)\n",
    "        self[key] = default_value  # Cache the default value for future lookups\n",
    "        return default_value\n",
    "\n",
    "# Example usage:\n",
    "def default_value_for_key(key):\n",
    "    # Define a function that computes the default value based on the key\n",
    "    val1 = key[0][1]\n",
    "    val2 = key[0][2]\n",
    "    val3 = key[1][2]\n",
    "    cur_matrix = np.array([[1, val1, val2], [0, 1, val3], [0, 0, 1]])\n",
    "    output1 = getReward(cur_matrix @ A)\n",
    "    output2 = getReward(cur_matrix @ B)\n",
    "    output3 = getReward(cur_matrix @ C)\n",
    "    output4 = getReward(cur_matrix @ D)\n",
    "    return [output1, output2, output3, output4]\n",
    "\n",
    "custom_dict = CustomDefaultDict(default_value_for_key)\n",
    "\n",
    "custom_dict[list(A@A)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[array([1, 2, 0]), array([0, 1, 0]), array([0, 0, 1])]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(A@A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(A)[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
