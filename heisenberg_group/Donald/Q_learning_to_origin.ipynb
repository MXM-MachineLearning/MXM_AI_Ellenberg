{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epsilon_greedy_search(Epsilon, qtable, state):\n",
    "    if (random.random() < Epsilon):\n",
    "        # 0 is 'apply matrix A', 1 is 'apply matrix B'\n",
    "        # 2 is 'apply matrix C', 3 is 'apply matrix D'\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    else:\n",
    "        # get the best move for the current state\n",
    "        return best_move_for_a_state(Q_table=qtable, state=state)\n",
    "    \n",
    "# I would like to return the best move for a given state\n",
    "def best_move_for_a_state(Q_table, state):\n",
    "    vals = Q_table[(state[0][1], state[0][2], state[1][2])]\n",
    "\n",
    "    # if we haven't visited this state before, return a random choice of 0, 1, 2, or 3\n",
    "    if vals==[0, 0, 0, 0]:\n",
    "        return random.choice([0, 1, 2, 3])\n",
    "    \n",
    "    # if we have visited this state before, return the current best choice\n",
    "    return np.argmax(vals)\n",
    "\n",
    "# over a given state, return the maximum value of the table for that state\n",
    "def max_a_prime(Q_table, state):\n",
    "    return max(Q_table[(state[0][1], state[0][2], state[1][2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B is the inverse of A\n",
    "A = np.array([[1, 1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "B = np.array([[1, -1, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "# C is the inverse of D\n",
    "C = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
    "D = np.array([[1, 0, 0], [0, 1, -1], [0, 0, 1]])\n",
    "\n",
    "# together, A, B, C, and D generate the heisenberg group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReward(matrix):\n",
    "    if (matrix==A).all() or (matrix==B).all() or (matrix==C).all() or (matrix==D).all():\n",
    "        return 20\n",
    "    else:\n",
    "        return -1 + 1/(2 + abs(matrix[0][1]) + abs(matrix[0][2]) + abs(matrix[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.75, -0.5, -0.8, -0.8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapted from ChatGPT\n",
    "class CustomDefaultDict(dict):\n",
    "    def __init__(self, default_factory, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        # Compute the default value based on the missing key\n",
    "        default_value = self.default_factory(key)\n",
    "        self[key] = default_value  # Cache the default value for future lookups\n",
    "        return default_value\n",
    "\n",
    "# Example usage:\n",
    "def default_value_for_key(key):\n",
    "    # Define a function that computes the default value based on the key\n",
    "    val1 = key[0]\n",
    "    val2 = key[1]\n",
    "    val3 = key[2]\n",
    "    cur_matrix = np.array([[1, val1, val2], [0, 1, val3], [0, 0, 1]])\n",
    "    output1 = getReward(cur_matrix @ A)\n",
    "    output2 = getReward(cur_matrix @ B)\n",
    "    output3 = getReward(cur_matrix @ C)\n",
    "    output4 = getReward(cur_matrix @ D)\n",
    "    return [output1, output2, output3, output4]\n",
    "\n",
    "custom_dict = CustomDefaultDict(default_value_for_key)\n",
    "\n",
    "cur_mat = A@A@B\n",
    "\n",
    "custom_dict[(cur_mat[0][1], cur_mat[0][2], cur_mat[1][2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heisenberg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(oldObs, action):\n",
    "    # action is always either 0, 1, 2, or 3\n",
    "    next_state = []\n",
    "    if action==0:\n",
    "        next_state = oldObs @ A\n",
    "    elif action==1:\n",
    "        next_state = oldObs @ B\n",
    "    elif action==2:\n",
    "        next_state = oldObs @ C\n",
    "    else:\n",
    "        next_state = oldObs @ D\n",
    "    curReward = getReward(next_state)\n",
    "    done = curReward==20\n",
    "    return (next_state, curReward, done)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for the last 100 iterations: -89.26391252443506\n",
      "epsilon: 0.9038873549665959\n",
      "Average reward for the last 100 iterations: -88.73080416895395\n",
      "epsilon: 0.8178301806491574\n",
      "Average reward for the last 100 iterations: -84.04895409896336\n",
      "epsilon: 0.7399663251239436\n",
      "Average reward for the last 100 iterations: -75.66846459422796\n",
      "epsilon: 0.6695157201007336\n",
      "Average reward for the last 100 iterations: -73.40194100353149\n",
      "epsilon: 0.6057725659163237\n",
      "Average reward for the last 100 iterations: -69.1596364686203\n",
      "epsilon: 0.548098260578011\n",
      "Average reward for the last 100 iterations: -77.77323334448975\n",
      "epsilon: 0.4959150020176678\n",
      "Average reward for the last 100 iterations: -72.7534170313123\n",
      "epsilon: 0.44869999946146477\n",
      "Average reward for the last 100 iterations: -64.64710241432209\n",
      "epsilon: 0.4059802359226587\n",
      "Average reward for the last 100 iterations: -72.26314518707726\n",
      "epsilon: 0.36732772934619257\n",
      "Average reward for the last 100 iterations: -72.18309584603773\n",
      "epsilon: 0.33235524492954527\n",
      "Average reward for the last 100 iterations: -61.52201881395896\n",
      "epsilon: 0.3007124156643058\n",
      "Average reward for the last 100 iterations: -67.01228438028674\n",
      "epsilon: 0.2720822322326576\n",
      "Average reward for the last 100 iterations: -72.97908817096402\n",
      "epsilon: 0.2461778670932771\n",
      "Average reward for the last 100 iterations: -72.12706831641127\n",
      "epsilon: 0.22273980093919937\n",
      "Average reward for the last 100 iterations: -75.80669265279987\n",
      "epsilon: 0.2015332227394583\n",
      "Average reward for the last 100 iterations: -70.08081896033512\n",
      "epsilon: 0.18234567731717977\n",
      "Average reward for the last 100 iterations: -71.17773533316475\n",
      "epsilon: 0.1649849368967147\n",
      "Average reward for the last 100 iterations: -67.72447176847565\n",
      "epsilon: 0.14927707529619813\n",
      "Average reward for the last 100 iterations: -68.8240350622726\n",
      "epsilon: 0.13506472547210188\n",
      "Average reward for the last 100 iterations: -65.76252567731424\n",
      "epsilon: 0.12220550295922675\n",
      "Average reward for the last 100 iterations: -68.04592152270648\n",
      "epsilon: 0.11057057941158951\n",
      "Average reward for the last 100 iterations: -69.70056338883406\n",
      "epsilon: 0.10004339195341891\n",
      "Average reward for the last 100 iterations: -70.16455380997354\n",
      "epsilon: 0.09051847541007228\n",
      "Average reward for the last 100 iterations: -62.044022729729676\n",
      "epsilon: 0.08190040571973876\n",
      "Average reward for the last 100 iterations: -70.90591674787638\n",
      "epsilon: 0.07410284394064628\n",
      "Average reward for the last 100 iterations: -65.80467730650633\n",
      "epsilon: 0.06704767127628951\n",
      "Average reward for the last 100 iterations: -68.93519713074633\n",
      "epsilon: 0.060664206453048174\n",
      "Average reward for the last 100 iterations: -65.49615029536997\n",
      "epsilon: 0.05488849760960279\n",
      "Average reward for the last 100 iterations: -71.93927504960658\n",
      "epsilon: 0.049662681604038215\n",
      "Average reward for the last 100 iterations: -69.48406933184478\n",
      "epsilon: 0.04493440431994225\n",
      "Average reward for the last 100 iterations: -63.56689627443222\n",
      "epsilon: 0.04065629616391608\n",
      "Average reward for the last 100 iterations: -64.46149943752408\n",
      "epsilon: 0.03678549749984046\n",
      "Average reward for the last 100 iterations: -69.54533424446318\n",
      "epsilon: 0.03328322926552661\n",
      "Average reward for the last 100 iterations: -62.83075414801626\n",
      "epsilon: 0.030114404470033673\n",
      "Average reward for the last 100 iterations: -53.95847899257771\n",
      "epsilon: 0.027247276679492435\n",
      "Average reward for the last 100 iterations: -56.80179073177046\n",
      "epsilon: 0.024653121969839265\n",
      "Average reward for the last 100 iterations: -66.73625179270793\n",
      "epsilon: 0.022305951160147018\n",
      "Average reward for the last 100 iterations: -66.64163735984786\n",
      "epsilon: 0.02018224944360293\n",
      "Average reward for the last 100 iterations: -61.02745961331241\n",
      "epsilon: 0.018260740807661956\n",
      "Average reward for the last 100 iterations: -53.835361549866676\n",
      "epsilon: 0.016522174883251375\n",
      "Average reward for the last 100 iterations: -65.14074990981622\n",
      "epsilon: 0.014949134087605212\n",
      "Average reward for the last 100 iterations: -59.52833149852856\n",
      "epsilon: 0.01352585912861506\n",
      "Average reward for the last 100 iterations: -66.42036000669793\n",
      "epsilon: 0.012238091122537187\n",
      "Average reward for the last 100 iterations: -60.79518756481562\n",
      "epsilon: 0.011072928743333644\n",
      "Average reward for the last 100 iterations: -64.42128365354151\n",
      "epsilon: 0.010018698972517958\n",
      "Average reward for the last 100 iterations: -58.336178100969356\n",
      "epsilon: 0.009064840154630435\n",
      "Average reward for the last 100 iterations: -59.911251292687155\n",
      "epsilon: 0.008201796186750635\n",
      "Average reward for the last 100 iterations: -57.09548997191792\n",
      "epsilon: 0.007420920781999136\n",
      "Average reward for the last 100 iterations: -52.917106349923344\n",
      "epsilon: 0.006714390847905742\n",
      "Average reward for the last 100 iterations: -59.693292352116025\n",
      "epsilon: 0.006075128111837272\n",
      "Average reward for the last 100 iterations: -57.6885125770969\n",
      "epsilon: 0.005496728208300101\n",
      "Average reward for the last 100 iterations: -50.66094232087405\n",
      "epsilon: 0.004973396517688337\n",
      "Average reward for the last 100 iterations: -61.95432431051755\n",
      "epsilon: 0.004499890113687073\n",
      "Average reward for the last 100 iterations: -58.36289438224092\n",
      "epsilon: 0.004071465237738676\n",
      "Average reward for the last 100 iterations: -62.46353999242135\n",
      "epsilon: 0.003683829774352405\n",
      "Average reward for the last 100 iterations: -60.83208491934752\n",
      "epsilon: 0.0033331002511377216\n",
      "Average reward for the last 100 iterations: -58.332885766903445\n",
      "epsilon: 0.003015762932772144\n",
      "Average reward for the last 100 iterations: -66.33168084932987\n",
      "epsilon: 0.002728638619128845\n",
      "Average reward for the last 100 iterations: -60.38857963340929\n",
      "epsilon: 0.0024688507948989738\n",
      "Average reward for the last 100 iterations: -61.488163521000494\n",
      "epsilon: 0.0022337968116200296\n",
      "Average reward for the last 100 iterations: -61.477627835384595\n",
      "epsilon: 0.0020211218134014433\n",
      "Average reward for the last 100 iterations: -60.453059651232394\n",
      "epsilon: 0.0018286951451258438\n",
      "Average reward for the last 100 iterations: -51.31686337107173\n",
      "epsilon: 0.0016545890067748276\n",
      "Average reward for the last 100 iterations: -58.97321092940091\n",
      "epsilon: 0.0014970591400305351\n",
      "Average reward for the last 100 iterations: -57.970647394417874\n",
      "epsilon: 0.001354527353664429\n",
      "Average reward for the last 100 iterations: -68.9189488314245\n",
      "epsilon: 0.001225565712646288\n",
      "Average reward for the last 100 iterations: -59.7734704200839\n",
      "epsilon: 0.0011088822325741772\n",
      "Average reward for the last 100 iterations: -51.62235080082781\n",
      "epsilon: 0.0010033079361070328\n",
      "Average reward for the last 100 iterations: -57.101648602532315\n",
      "epsilon: 0.0009077851417265054\n",
      "Average reward for the last 100 iterations: -54.83121547194145\n",
      "epsilon: 0.0008213568675006472\n",
      "Average reward for the last 100 iterations: -58.9550037290802\n",
      "epsilon: 0.0007431572436925013\n",
      "Average reward for the last 100 iterations: -56.022970585524305\n",
      "epsilon: 0.0006724028381636441\n",
      "Average reward for the last 100 iterations: -47.344403770325904\n",
      "epsilon: 0.0006083848076674359\n",
      "Average reward for the last 100 iterations: -50.371995046998265\n",
      "epsilon: 0.0005504617964007802\n",
      "Average reward for the last 100 iterations: -49.23470743772828\n",
      "epsilon: 0.0004980535106695312\n",
      "Average reward for the last 100 iterations: -57.44140741745411\n",
      "epsilon: 0.00045063490529620545\n",
      "Average reward for the last 100 iterations: -56.90243861228841\n",
      "epsilon: 0.00040773092352733666\n",
      "Average reward for the last 100 iterations: -51.91109843404781\n",
      "epsilon: 0.00036891173774295443\n",
      "Average reward for the last 100 iterations: -56.08154588235825\n",
      "epsilon: 0.0003337884432878974\n",
      "Average reward for the last 100 iterations: -53.06035970903732\n",
      "epsilon: 0.00030200916228419905\n",
      "Average reward for the last 100 iterations: -53.12550417231868\n",
      "epsilon: 0.0002732555183911334\n",
      "Average reward for the last 100 iterations: -51.219525108764756\n",
      "epsilon: 0.0002472394471957831\n",
      "Average reward for the last 100 iterations: -52.10932361992387\n",
      "epsilon: 0.000223700310279479\n",
      "Average reward for the last 100 iterations: -53.78047567033202\n",
      "epsilon: 0.00020240228404777254\n",
      "Average reward for the last 100 iterations: -53.22733649450833\n",
      "epsilon: 0.00018313199716430296\n",
      "Average reward for the last 100 iterations: -51.19530080452409\n",
      "epsilon: 0.0001656963929195113\n",
      "Average reward for the last 100 iterations: -49.29394694685734\n",
      "epsilon: 0.00014992079511864147\n",
      "Average reward for the last 100 iterations: -53.82019754605253\n",
      "epsilon: 0.0001356471581123901\n",
      "Average reward for the last 100 iterations: -48.85408373224011\n",
      "epsilon: 0.00012273248343838214\n",
      "Average reward for the last 100 iterations: -50.61561038114668\n",
      "epsilon: 0.00011104738721081156\n",
      "Average reward for the last 100 iterations: -51.524846062145514\n",
      "epsilon: 0.00010047480390583761\n",
      "Average reward for the last 100 iterations: -54.24594676423879\n",
      "epsilon: 9.090881355679163e-05\n",
      "Average reward for the last 100 iterations: -60.27147682207563\n",
      "epsilon: 8.225358060960925e-05\n",
      "Average reward for the last 100 iterations: -50.724608266742344\n",
      "epsilon: 7.44223938075589e-05\n",
      "Average reward for the last 100 iterations: -50.951281227023344\n",
      "epsilon: 6.733679748648316e-05\n",
      "Average reward for the last 100 iterations: -49.9237953414355\n",
      "epsilon: 6.09258055775561e-05\n",
      "Average reward for the last 100 iterations: -61.158803343548186\n",
      "epsilon: 5.512519044314936e-05\n",
      "Average reward for the last 100 iterations: -55.18975854556006\n",
      "epsilon: 4.9876839421109216e-05\n",
      "Average reward for the last 100 iterations: -46.83245194697507\n",
      "epsilon: 4.5128172631071065e-05\n",
      "Average reward for the last 100 iterations: -49.594191262481\n",
      "epsilon: 4.083161621018491e-05\n",
      "Average reward for the last 100 iterations: -57.857506834792964\n",
      "epsilon: 3.69441257009361e-05\n",
      "Average reward for the last 100 iterations: -48.41764096162205\n",
      "epsilon: 3.3426754816188734e-05\n",
      "Average reward for the last 100 iterations: -48.686463522309204\n",
      "epsilon: 3.0244265261182943e-05\n",
      "Average reward for the last 100 iterations: -44.842420169907356\n",
      "epsilon: 2.7364773703542285e-05\n",
      "Average reward for the last 100 iterations: -58.77630505486601\n",
      "epsilon: 2.4759432354508794e-05\n",
      "Average reward for the last 100 iterations: -48.418388254886516\n",
      "epsilon: 2.2402139961352654e-05\n",
      "Average reward for the last 100 iterations: -52.34103707331013\n",
      "epsilon: 2.0269280315574096e-05\n",
      "Average reward for the last 100 iterations: -42.5650285839267\n",
      "epsilon: 1.8339485657177917e-05\n",
      "Average reward for the last 100 iterations: -50.71155796385097\n",
      "epsilon: 1.659342260471908e-05\n",
      "Average reward for the last 100 iterations: -56.541887807100835\n",
      "epsilon: 1.501359846648893e-05\n",
      "Average reward for the last 100 iterations: -52.33874717948604\n",
      "epsilon: 1.3584185992397611e-05\n",
      "Average reward for the last 100 iterations: -44.6735641554465\n",
      "epsilon: 1.2290864810853405e-05\n",
      "Average reward for the last 100 iterations: -43.293214631446915\n",
      "epsilon: 1.1120677962096389e-05\n",
      "Average reward for the last 100 iterations: -50.53417966717962\n",
      "epsilon: 1.006190209068529e-05\n",
      "Average reward for the last 100 iterations: -38.364426655546474\n",
      "epsilon: 9.103929996679068e-06\n",
      "Average reward for the last 100 iterations: -57.04392346145085\n",
      "epsilon: 8.23716436886816e-06\n",
      "Average reward for the last 100 iterations: -44.5344219918974\n",
      "epsilon: 7.452921635436766e-06\n",
      "Average reward for the last 100 iterations: -55.13137389468278\n",
      "epsilon: 6.743344968797045e-06\n",
      "Average reward for the last 100 iterations: -42.8332141104959\n",
      "epsilon: 6.101325573046306e-06\n",
      "Average reward for the last 100 iterations: -47.955889555304815\n",
      "epsilon: 5.5204314654763466e-06\n",
      "Average reward for the last 100 iterations: -45.95066240224591\n",
      "epsilon: 4.994843038642421e-06\n",
      "Average reward for the last 100 iterations: -44.80237022909366\n",
      "epsilon: 4.519294757429241e-06\n",
      "Average reward for the last 100 iterations: -47.31909236878416\n",
      "epsilon: 4.089022407014129e-06\n",
      "Average reward for the last 100 iterations: -48.48315521215707\n",
      "epsilon: 3.6997153632383808e-06\n",
      "Average reward for the last 100 iterations: -37.97911220155578\n",
      "epsilon: 3.3474734072140295e-06\n",
      "Average reward for the last 100 iterations: -49.24833183737411\n",
      "epsilon: 3.0287676515192263e-06\n",
      "Average reward for the last 100 iterations: -52.73304955016383\n",
      "epsilon: 2.7404051865266284e-06\n",
      "Average reward for the last 100 iterations: -43.395396636301285\n",
      "epsilon: 2.4794970926789746e-06\n",
      "Average reward for the last 100 iterations: -42.28321549608288\n",
      "epsilon: 2.243429498247208e-06\n",
      "Average reward for the last 100 iterations: -40.05749798438788\n",
      "epsilon: 2.0298373926173216e-06\n",
      "Average reward for the last 100 iterations: -50.087097524640306\n",
      "epsilon: 1.83658093275792e-06\n",
      "Average reward for the last 100 iterations: -46.145814002409125\n",
      "epsilon: 1.6617240054981357e-06\n",
      "Average reward for the last 100 iterations: -45.570537138711785\n",
      "epsilon: 1.5035148308450506e-06\n",
      "Average reward for the last 100 iterations: -44.89138144928603\n",
      "epsilon: 1.3603684120175983e-06\n",
      "Average reward for the last 100 iterations: -43.25781931873468\n",
      "epsilon: 1.2308506563750686e-06\n",
      "Average reward for the last 100 iterations: -45.103889313770196\n",
      "epsilon: 1.1136640081579159e-06\n",
      "Average reward for the last 100 iterations: -47.732659353149735\n",
      "epsilon: 1.0076344491044587e-06\n",
      "Average reward for the last 100 iterations: -46.242343729321334\n",
      "epsilon: 9.116997367109624e-07\n",
      "Average reward for the last 100 iterations: -46.79979498424881\n",
      "epsilon: 8.248987623017148e-07\n",
      "Average reward for the last 100 iterations: -48.62293102058775\n",
      "epsilon: 7.463619222944092e-07\n",
      "Average reward for the last 100 iterations: -45.700725547040975\n",
      "epsilon: 6.753024061966736e-07\n",
      "Average reward for the last 100 iterations: -43.45401242495298\n",
      "epsilon: 6.110083140537422e-07\n",
      "Average reward for the last 100 iterations: -44.355698539242375\n",
      "epsilon: 5.528355243770125e-07\n",
      "Average reward for the last 100 iterations: -37.348775290189735\n",
      "epsilon: 5.002012411018101e-07\n",
      "Average reward for the last 100 iterations: -47.93404447292641\n",
      "epsilon: 4.5257815492544905e-07\n",
      "Average reward for the last 100 iterations: -45.67210139213144\n",
      "epsilon: 4.094891605317576e-07\n",
      "Average reward for the last 100 iterations: -44.880856649131495\n",
      "epsilon: 3.7050257677731924e-07\n",
      "Average reward for the last 100 iterations: -42.72842739443506\n",
      "epsilon: 3.3522782195351267e-07\n",
      "Average reward for the last 100 iterations: -38.762746132617295\n",
      "epsilon: 3.033115007975709e-07\n",
      "Average reward for the last 100 iterations: -55.134964468473264\n",
      "epsilon: 2.7443386405091567e-07\n",
      "Average reward for the last 100 iterations: -44.67945498355106\n",
      "epsilon: 2.4830560509533956e-07\n",
      "Average reward for the last 100 iterations: -46.13882292219796\n",
      "epsilon: 2.246649615745811e-07\n",
      "Average reward for the last 100 iterations: -35.45786559111073\n",
      "epsilon: 2.032750929642842e-07\n",
      "Average reward for the last 100 iterations: -33.853309806927875\n",
      "epsilon: 1.8392170781789347e-07\n",
      "Average reward for the last 100 iterations: -40.21761553046608\n",
      "epsilon: 1.6641091691737205e-07\n",
      "Average reward for the last 100 iterations: -36.40379974912387\n",
      "epsilon: 1.5056729082083014e-07\n",
      "Average reward for the last 100 iterations: -36.18435448565207\n",
      "epsilon: 1.3623210234687325e-07\n",
      "Average reward for the last 100 iterations: -38.60623189634626\n",
      "epsilon: 1.2326173638824198e-07\n",
      "Average reward for the last 100 iterations: -44.528254301703434\n",
      "epsilon: 1.1152625112368151e-07\n",
      "Average reward for the last 100 iterations: -53.45097783186826\n",
      "epsilon: 1.0090807621373846e-07\n",
      "Average reward for the last 100 iterations: -38.10036844746296\n",
      "epsilon: 9.130083493854227e-08\n",
      "Average reward for the last 100 iterations: -50.87260391218667\n",
      "epsilon: 8.260827847731793e-08\n",
      "Average reward for the last 100 iterations: -50.85633062752042\n",
      "epsilon: 7.474332165285969e-08\n",
      "Average reward for the last 100 iterations: -37.1314236275078\n",
      "epsilon: 6.762717048070146e-08\n",
      "Average reward for the last 100 iterations: -43.20131386826311\n",
      "epsilon: 6.118853278245869e-08\n",
      "Average reward for the last 100 iterations: -41.84593169994218\n",
      "epsilon: 5.5362903954978386e-08\n",
      "Average reward for the last 100 iterations: -39.65721913649693\n",
      "epsilon: 5.009192073987496e-08\n",
      "Average reward for the last 100 iterations: -38.578250715647464\n",
      "epsilon: 4.532277651928118e-08\n",
      "Average reward for the last 100 iterations: -42.627623404905464\n",
      "epsilon: 4.100769228003525e-08\n",
      "Average reward for the last 100 iterations: -31.573037927274168\n",
      "epsilon: 3.710343794623138e-08\n",
      "Average reward for the last 100 iterations: -48.99404133897687\n",
      "epsilon: 3.357089928467093e-08\n",
      "Average reward for the last 100 iterations: -34.58777776073118\n",
      "epsilon: 3.037468604431549e-08\n",
      "Average reward for the last 100 iterations: -44.42579592351944\n",
      "epsilon: 2.748277740394102e-08\n",
      "Average reward for the last 100 iterations: -39.774738438749544\n",
      "epsilon: 2.4866201175959905e-08\n",
      "Average reward for the last 100 iterations: -33.26999240786033\n",
      "epsilon: 2.2498743552558194e-08\n",
      "Average reward for the last 100 iterations: -35.81904341647954\n",
      "epsilon: 2.0356686486279826e-08\n",
      "Average reward for the last 100 iterations: -42.48358725997916\n",
      "epsilon: 1.8418570074041747e-08\n",
      "Average reward for the last 100 iterations: -38.40651631762694\n",
      "epsilon: 1.666497756405654e-08\n",
      "Average reward for the last 100 iterations: -41.1759971110922\n",
      "epsilon: 1.5078340831784492e-08\n",
      "Average reward for the last 100 iterations: -45.9445584629729\n",
      "epsilon: 1.3642764376102604e-08\n",
      "Average reward for the last 100 iterations: -39.932552374182485\n",
      "epsilon: 1.2343866072420293e-08\n",
      "Average reward for the last 100 iterations: -40.01064886616134\n",
      "epsilon: 1.116863308734923e-08\n",
      "Average reward for the last 100 iterations: -36.915970870071675\n",
      "epsilon: 1.0105291511427924e-08\n",
      "Average reward for the last 100 iterations: -43.075805930427286\n",
      "epsilon: 9.143188403834803e-09\n",
      "Average reward for the last 100 iterations: -42.11882551659009\n",
      "epsilon: 8.272685067370861e-09\n",
      "Average reward for the last 100 iterations: -34.72822632641346\n",
      "epsilon: 7.485060484501997e-09\n",
      "Average reward for the last 100 iterations: -33.03474976524873\n",
      "epsilon: 6.77242394704854e-09\n",
      "Average reward for the last 100 iterations: -38.45745123753055\n",
      "epsilon: 6.127636004214353e-09\n",
      "Average reward for the last 100 iterations: -27.24908648674052\n",
      "epsilon: 5.544236936984372e-09\n",
      "Average reward for the last 100 iterations: -42.78916563714231\n",
      "epsilon: 5.016382042321222e-09\n",
      "Average reward for the last 100 iterations: -37.88084453049408\n",
      "epsilon: 4.53878307881447e-09\n",
      "Average reward for the last 100 iterations: -40.80020636292897\n",
      "epsilon: 4.10665528716391e-09\n",
      "Average reward for the last 100 iterations: -36.43245521848214\n",
      "epsilon: 3.7156694547289007e-09\n",
      "Average reward for the last 100 iterations: -31.69560319533335\n",
      "epsilon: 3.3619085439089865e-09\n",
      "Average reward for the last 100 iterations: -41.208496472681034\n",
      "epsilon: 3.0418284498433344e-09\n",
      "Average reward for the last 100 iterations: -39.435837252868716\n",
      "epsilon: 2.7522224942853162e-09\n",
      "Average reward for the last 100 iterations: -37.28529446154882\n",
      "epsilon: 2.4901892999390573e-09\n",
      "Average reward for the last 100 iterations: -37.51402497895089\n",
      "epsilon: 2.2531037234114447e-09\n",
      "Average reward for the last 100 iterations: -35.53129390432133\n",
      "epsilon: 2.038590555575333e-09\n",
      "Average reward for the last 100 iterations: -36.00878495734643\n",
      "epsilon: 1.8445007258647328e-09\n",
      "Average reward for the last 100 iterations: -30.049965947446708\n",
      "epsilon: 1.6688897721079462e-09\n",
      "Average reward for the last 100 iterations: -43.207581182878236\n",
      "epsilon: 1.5099983602016576e-09\n",
      "Average reward for the last 100 iterations: -41.35316884647308\n",
      "epsilon: 1.3662346584650378e-09\n",
      "Average reward for the last 100 iterations: -39.6314833641283\n",
      "epsilon: 1.2361583900937467e-09\n",
      "Average reward for the last 100 iterations: -42.42589938538638\n",
      "epsilon: 1.1184664039455474e-09\n",
      "Average reward for the last 100 iterations: -39.55152275809383\n",
      "epsilon: 1.011979619100441e-09\n",
      "Average reward for the last 100 iterations: -27.00109242653566\n",
      "epsilon: 9.15631212401201e-10\n",
      "Average reward for the last 100 iterations: -38.83600438608464\n",
      "epsilon: 8.284559306328114e-10\n",
      "Average reward for the last 100 iterations: -26.379073643517476\n",
      "epsilon: 7.495804202663469e-10\n",
      "Average reward for the last 100 iterations: -35.521413906560525\n",
      "epsilon: 6.782144778871841e-10\n",
      "Average reward for the last 100 iterations: -38.24033165217137\n",
      "epsilon: 6.136431336511485e-10\n",
      "Average reward for the last 100 iterations: -28.94231393912128\n",
      "epsilon: 5.552194884578073e-10\n",
      "Average reward for the last 100 iterations: -37.0682863014068\n",
      "epsilon: 5.023582330811142e-10\n",
      "Average reward for the last 100 iterations: -37.56213884949907\n",
      "epsilon: 4.545297843297102e-10\n",
      "Average reward for the last 100 iterations: -42.65306102558417\n",
      "epsilon: 4.1125497949080954e-10\n",
      "Average reward for the last 100 iterations: -39.80327961821673\n",
      "epsilon: 3.7210027590469397e-10\n",
      "Average reward for the last 100 iterations: -31.158314438513326\n",
      "epsilon: 3.366734075774115e-10\n",
      "Average reward for the last 100 iterations: -32.34885573442136\n",
      "epsilon: 3.0461945531805506e-10\n",
      "Average reward for the last 100 iterations: -41.806199961700194\n",
      "epsilon: 2.7561729102983154e-10\n",
      "Average reward for the last 100 iterations: -50.000126505635635\n",
      "epsilon: 2.493763605325452e-10\n",
      "Average reward for the last 100 iterations: -43.153879801309714\n",
      "epsilon: 2.2563377268564379e-10\n",
      "Average reward for the last 100 iterations: -33.1717801524548\n",
      "epsilon: 2.0415166564961023e-10\n",
      "Average reward for the last 100 iterations: -35.24091051303074\n",
      "epsilon: 1.8471482389995092e-10\n",
      "Average reward for the last 100 iterations: -31.827103386117575\n",
      "epsilon: 1.6712852212016722e-10\n",
      "Average reward for the last 100 iterations: -37.787370062283365\n",
      "epsilon: 1.5121657437304705e-10\n",
      "Average reward for the last 100 iterations: -27.418593956585465\n",
      "epsilon: 1.3681956900616914e-10\n",
      "Average reward for the last 100 iterations: -34.892724415745896\n",
      "epsilon: 1.2379327160826409e-10\n",
      "Average reward for the last 100 iterations: -38.97516133860293\n",
      "epsilon: 1.1200718001667172e-10\n",
      "Average reward for the last 100 iterations: -35.11970840487453\n",
      "epsilon: 1.0134321689943615e-10\n",
      "Average reward for the last 100 iterations: -25.893133989087204\n",
      "epsilon: 9.169454681385119e-11\n",
      "Average reward for the last 100 iterations: -32.27701536624601\n",
      "epsilon: 8.296450589032293e-11\n",
      "Average reward for the last 100 iterations: -35.640570811756746\n",
      "epsilon: 7.506563341873329e-11\n",
      "Average reward for the last 100 iterations: -35.81426416284665\n",
      "epsilon: 6.79187956353863e-11\n",
      "Average reward for the last 100 iterations: -46.16687844539739\n",
      "epsilon: 6.145239293231837e-11\n",
      "Average reward for the last 100 iterations: -42.05835786320773\n",
      "epsilon: 5.560164254650765e-11\n",
      "Average reward for the last 100 iterations: -25.917538273419815\n",
      "epsilon: 5.0307929542703596e-11\n",
      "Average reward for the last 100 iterations: -30.413584155050813\n",
      "epsilon: 4.551821958778797e-11\n",
      "Average reward for the last 100 iterations: -38.308776143963954\n",
      "epsilon: 4.118452763362796e-11\n",
      "Average reward for the last 100 iterations: -34.134843540937055\n",
      "epsilon: 3.726343718549409e-11\n",
      "Average reward for the last 100 iterations: -38.53403454342048\n",
      "epsilon: 3.3715665339900035e-11\n",
      "Average reward for the last 100 iterations: -27.929491112447458\n",
      "epsilon: 3.050566923425541e-11\n",
      "Average reward for the last 100 iterations: -32.329538338762625\n",
      "epsilon: 2.7601289965602556e-11\n",
      "Average reward for the last 100 iterations: -29.42517594774808\n",
      "epsilon: 2.4973430411085592e-11\n",
      "Average reward for the last 100 iterations: -28.822915366593808\n",
      "epsilon: 2.2595763722440924e-11\n",
      "Average reward for the last 100 iterations: -39.960234851939866\n",
      "epsilon: 2.044446957410138e-11\n",
      "Average reward for the last 100 iterations: -35.78394625533951\n",
      "epsilon: 1.849799552255208e-11\n",
      "Average reward for the last 100 iterations: -48.42480263892944\n",
      "epsilon: 1.6736841086149672e-11\n",
      "Average reward for the last 100 iterations: -37.404256300583036\n",
      "epsilon: 1.5143362382238333e-11\n",
      "Average reward for the last 100 iterations: -34.69003772563328\n",
      "epsilon: 1.3701595364346396e-11\n",
      "Average reward for the last 100 iterations: -30.123725338872596\n",
      "epsilon: 1.2397095888590217e-11\n",
      "Average reward for the last 100 iterations: -33.08987374175419\n",
      "epsilon: 1.1216795007012077e-11\n",
      "Average reward for the last 100 iterations: -40.744928536200156\n",
      "epsilon: 1.0148868038128785e-11\n",
      "Average reward for the last 100 iterations: -29.19478710619075\n",
      "epsilon: 9.182616102992242e-12\n",
      "Average reward for the last 100 iterations: -33.55056629550822\n",
      "epsilon: 8.308358939947264e-12\n",
      "Average reward for the last 100 iterations: -32.80029794333241\n",
      "epsilon: 7.517337924266262e-12\n",
      "Average reward for the last 100 iterations: -30.75954602000003\n",
      "epsilon: 6.801628321076183e-12\n",
      "Average reward for the last 100 iterations: -37.41712038401408\n",
      "epsilon: 6.1540598924959294e-12\n",
      "Average reward for the last 100 iterations: -37.55202794918351\n",
      "epsilon: 5.568145063597754e-12\n",
      "Average reward for the last 100 iterations: -23.76588460620942\n",
      "epsilon: 5.0380139275332125e-12\n",
      "Average reward for the last 100 iterations: -38.79493899466846\n",
      "epsilon: 4.558355438681547e-12\n",
      "Average reward for the last 100 iterations: -43.973167053768684\n",
      "epsilon: 4.12436420467213e-12\n",
      "Average reward for the last 100 iterations: -31.7407428940408\n",
      "epsilon: 3.731692344224219e-12\n",
      "Average reward for the last 100 iterations: -32.00508804484484\n",
      "epsilon: 3.3764059284984217e-12\n",
      "Average reward for the last 100 iterations: -42.79259936117151\n",
      "epsilon: 3.0549455695735444e-12\n",
      "Average reward for the last 100 iterations: -34.756509613795394\n",
      "epsilon: 2.76409076120996e-12\n",
      "Average reward for the last 100 iterations: -25.664382091783793\n",
      "epsilon: 2.500927614652326e-12\n",
      "Average reward for the last 100 iterations: -25.80968721020733\n",
      "epsilon: 2.262819666237245e-12\n",
      "Average reward for the last 100 iterations: -36.98245149926226\n",
      "epsilon: 2.047381464345922e-12\n",
      "Average reward for the last 100 iterations: -34.65842976820322\n",
      "epsilon: 1.8524546710863546e-12\n",
      "Average reward for the last 100 iterations: -23.489109496098305\n",
      "epsilon: 1.6760864392830427e-12\n",
      "Average reward for the last 100 iterations: -35.88645244434504\n",
      "epsilon: 1.5165098481470747e-12\n",
      "Average reward for the last 100 iterations: -26.32278110936613\n",
      "epsilon: 1.372126201624077e-12\n",
      "Average reward for the last 100 iterations: -32.37181602174382\n",
      "epsilon: 1.2414890120784275e-12\n",
      "Average reward for the last 100 iterations: -31.356123828865098\n",
      "epsilon: 1.1232895088565175e-12\n",
      "Average reward for the last 100 iterations: -28.264841609402882\n",
      "epsilon: 1.016343526548593e-12\n",
      "Average reward for the last 100 iterations: -35.00176874046421\n",
      "epsilon: 9.195796415910214e-13\n",
      "Average reward for the last 100 iterations: -34.98128324421881\n",
      "epsilon: 8.320284383571953e-13\n",
      "Average reward for the last 100 iterations: -32.171422404038665\n",
      "epsilon: 7.528127972008729e-13\n",
      "Average reward for the last 100 iterations: -29.7164021218952\n",
      "epsilon: 6.811391071540548e-13\n",
      "Average reward for the last 100 iterations: -35.08824209070358\n",
      "epsilon: 6.162893152450323e-13\n",
      "Average reward for the last 100 iterations: -29.975963845682646\n",
      "epsilon: 5.576137327837901e-13\n",
      "Average reward for the last 100 iterations: -25.900690774144927\n",
      "epsilon: 5.045245265455356e-13\n",
      "Average reward for the last 100 iterations: -17.433113500713233\n",
      "epsilon: 4.564898296446632e-13\n",
      "Average reward for the last 100 iterations: -28.6771426489742\n",
      "epsilon: 4.130284130997659e-13\n",
      "Average reward for the last 100 iterations: -21.381386788306887\n",
      "epsilon: 3.7370486470750513e-13\n",
      "Average reward for the last 100 iterations: -20.90990714140834\n",
      "epsilon: 3.3812522692554173e-13\n",
      "Average reward for the last 100 iterations: -29.298215098665363\n",
      "epsilon: 3.0593305006327097e-13\n",
      "Average reward for the last 100 iterations: -26.73671671904153\n",
      "epsilon: 2.7680582123979286e-13\n",
      "Average reward for the last 100 iterations: -29.063622005973176\n",
      "epsilon: 2.504517333331259e-13\n",
      "Average reward for the last 100 iterations: -42.51614571941913\n",
      "epsilon: 2.2660676155082918e-13\n",
      "Average reward for the last 100 iterations: -40.48309180494603\n",
      "epsilon: 2.050320183340591e-13\n",
      "Average reward for the last 100 iterations: -30.96605560691304\n",
      "epsilon: 1.8551136009553054e-13\n",
      "Average reward for the last 100 iterations: -24.49743303628321\n",
      "epsilon: 1.6784922181481952e-13\n",
      "Average reward for the last 100 iterations: -35.611109593119075\n",
      "epsilon: 1.518686577971957e-13\n",
      "Average reward for the last 100 iterations: -27.987739624728732\n",
      "epsilon: 1.374095689676017e-13\n",
      "Average reward for the last 100 iterations: -35.108016121291165\n",
      "epsilon: 1.243270989401656e-13\n",
      "Average reward for the last 100 iterations: -27.668634211710554\n",
      "epsilon: 1.1249018279449097e-13\n",
      "Average reward for the last 100 iterations: -30.203383363919933\n",
      "epsilon: 1.0178023401984112e-13\n"
     ]
    }
   ],
   "source": [
    "# adapted from CS 540 Spring 2023 HW 10\n",
    "EPISODES = 30000\n",
    "LEARNING_RATE = .1\n",
    "DISCOUNT_FACTOR = .99\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = .999\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# starts with an estimate of zero reward for each state.\n",
    "# adapted from ChatGPT\n",
    "# the outer dictionary has keys of the string version of the given array, and \n",
    "# values of a dictionary for each of the actions that we could take at that state\n",
    "# Q_table = defaultdict(lambda: [0, 0, 0, 0])\n",
    "Q_table = CustomDefaultDict(default_value_for_key)\n",
    "\n",
    "episode_reward_record = deque(maxlen=100)\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    # choose a random starting row\n",
    "    # adapted from https://stackoverflow.com/questions/15923826/random-row-selection-in-pandas-dataframe\n",
    "    cur_row = df.sample(1)\n",
    "    obs = np.array([\n",
    "        [1, int(cur_row['val1']), int(cur_row['val2'])], \n",
    "        [0, 1, int(cur_row['val3'])], \n",
    "        [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    while (not done):\n",
    "        # perform an epsilon greedy action \n",
    "        # Q(s, a) = (1-LEARNING_RATE)Q(s, a) + (LEARNING_RATE)(r + DISCOUNT_FACTOR(max a'(Q(s', a'))))\n",
    "        action = epsilon_greedy_search(Epsilon=EPSILON, qtable=Q_table, state=obs)\n",
    "\n",
    "        oldObs = obs\n",
    "        obs,reward,done = get_next_step(oldObs, action)\n",
    "        Q_table[(oldObs[0][1], oldObs[0][2], oldObs[1][2])][action] = (1-LEARNING_RATE) * Q_table[(oldObs[0][1], oldObs[0][2], oldObs[1][2])][action] + (LEARNING_RATE) * (reward + DISCOUNT_FACTOR * (max_a_prime(Q_table, obs)))\n",
    "\n",
    "        episode_reward += reward # update episode reward\n",
    "\n",
    "        index += 1\n",
    "        # if we take more than 100 steps, end this iteration early (we are probably not making progress)\n",
    "        if index > 100:\n",
    "            done=True\n",
    "\n",
    "    # decay the epsilon\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    # record the reward for this episode\n",
    "    episode_reward_record.append(episode_reward) \n",
    "\n",
    "    if i%100 ==0 and i>0:\n",
    "        print(\"Average reward for the last 100 iterations: \" + str(sum(list(episode_reward_record))/100))\n",
    "        print(\"epsilon: \" + str(EPSILON) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.138397577870297,\n",
       " -1.1032005356227106,\n",
       " -1.1981417647058823,\n",
       " 16.565255659473515]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test = B@B@B@B@C\n",
    "\n",
    "def matrix_to_tuple(matrix):\n",
    "    return (matrix[0][1], matrix[0][2], matrix[1][2])\n",
    "\n",
    "Q_table[matrix_to_tuple(to_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the other dataframe. \n",
    "test_df = pd.read_csv(\"heisenberg_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val1\n",
      "val2\n",
      "val3\n",
      "last_matrix\n"
     ]
    }
   ],
   "source": [
    "for i in test_df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_matrix = np.array([[1, int(cur_row['val1']), int(cur_row['val2'])], [0, 1, int(cur_row['val3'])], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_num_steps(cur_matrix):\n",
    "    index = 1\n",
    "    for i in range(50):\n",
    "        if (cur_matrix==A).all() or (cur_matrix==B).all() or (cur_matrix==C).all() or (cur_matrix==D).all():\n",
    "            return i\n",
    "        outputs = Q_table[matrix_to_tuple(cur_matrix)]\n",
    "        # print(outputs)\n",
    "        # if outputs==[0, 0, 0, 0]:\n",
    "        #     # this is a problem because we haven't seen this state before \n",
    "        #     # in training so we have no idea how to handle it\n",
    "        #     print(\"Problem.\")\n",
    "        index = np.argmax(outputs)\n",
    "        if index==0:\n",
    "            cur_matrix = cur_matrix @ A\n",
    "        elif index==1:\n",
    "            cur_matrix = cur_matrix @ B\n",
    "        elif index==2:\n",
    "            cur_matrix = cur_matrix @ C\n",
    "        elif index==3:\n",
    "            cur_matrix = cur_matrix @ D\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -2 -1]\n",
      " [ 0  1  1]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(B@C@B)\n",
    "\n",
    "matrix_to_num_steps(B@C@B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 1]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymat = B@B@C@B@D@A@A@C@A\n",
    "print(mymat)\n",
    "\n",
    "\n",
    "cur_matrix = D@D@B@D@A\n",
    "\n",
    "matrix_to_num_steps(cur_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_df['val1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q_learning(row):\n",
    "    cur_matrix = np.array([[1, int(row['val1']), int(row['val2'])], [0, 1, int(row['val3'])], [0, 0, 1]])\n",
    "    return matrix_to_num_steps(cur_matrix)\n",
    "\n",
    "test_df['num_moves_Q_learning_needs'] = test_df.apply(test_Q_learning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48914891489148915"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The proportion of starting positions in the test dataset that we can find a route to the origin that's <50 steps: \")\n",
    "sum(test_df['num_moves_Q_learning_needs']!=100)/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of these, the proportion of times where we learned a path that was < 20 moves: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9989777141688816"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Of these, the proportion of times where we learned a path that was < 20 moves: \")\n",
    "# encouraging because all of these were generated as sequences of 30 moves\n",
    "# so we've found significantly faster paths back to the origin for almost all moves that we find a path to the origin \n",
    "sum(test_df['num_moves_Q_learning_needs']<20)/sum(test_df['num_moves_Q_learning_needs']!=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
