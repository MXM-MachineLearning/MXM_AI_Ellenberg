{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: this doesn't work. This was from Donald's code that I just changed a few things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(string): \n",
    "    a = np.array([[1, 1, 2],[0, 1, 1],[0,-3,-2]])\n",
    "    b = np.array([[-2, 0, -1],[-5, 1, -1],[3,0,1]])\n",
    "\n",
    "    maxMats = 50\n",
    "    dataPoints = 1000\n",
    "    prevMat = -1\n",
    "\n",
    "\n",
    "    for j in range(dataPoints):\n",
    "        nextMat = random.randint(0,1)\n",
    "        if nextMat == 0: \n",
    "            mat = a\n",
    "            prevMat = 0\n",
    "        elif nextMat == 1:\n",
    "            mat = b\n",
    "            prevMat = 1\n",
    "        numOfMatrices = random.randint(1, maxMats)\n",
    "        for i in range(numOfMatrices): \n",
    "            nextMat = random.randint(0,1)\n",
    "            if (nextMat == 0):\n",
    "                mat = np.matmul(a, mat)\n",
    "                prevMat = nextMat\n",
    "            elif (nextMat == 1):\n",
    "                mat = np.matmul(b, mat)\n",
    "                prevMat = nextMat\n",
    "        if j == 0: \n",
    "            df = pd.DataFrame([[mat[0][0],mat[0][1],mat[0][2], mat[1][0],mat[1][1],mat[1][2],mat[2][0],mat[2][1],mat[2][2], prevMat]], columns = ['00', '01', '02','10','11','12', '20', '21','22',\"last\"])\n",
    "        else: \n",
    "            df = pd.concat([df, pd.DataFrame([[mat[0][0],mat[0][1],mat[0][2], mat[1][0],mat[1][1],mat[1][2],mat[2][0],mat[2][1],mat[2][2], prevMat]],columns = ['00', '01', '02','10','11','12', '20', '21','22',\"last\"])])\n",
    "# mat[0][0] = mat[0][0]  % 7\n",
    "# mat [0][1] = mat[0][1]  % 7\n",
    "# mat[0][2] = mat[0][2]  % 7\n",
    "# mat [1][0] = mat[1][0]  % 7\n",
    "# mat [1][1] = mat[1][1]  % 7\n",
    "# mat [1][1] = mat[1][1]  % 7\n",
    "    df.to_csv(string, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from ChatGPT\n",
    "\n",
    "# Define your neural network model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.step1 = nn.Linear(9, 128, bias=True)\n",
    "        self.step2 = nn.ReLU()\n",
    "        self.step3 = nn.Linear(128, 64, bias=True)\n",
    "        self.step4 = nn.ReLU()\n",
    "        self.step5 = nn.Linear(64, 16, bias=True)\n",
    "        self.step6 = nn.ReLU()\n",
    "        self.step7 = nn.Linear(16, 2, bias=True)\n",
    "\n",
    "        # multi-class classification adapted from ChatGPT\n",
    "        self.step8 = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # RUN IT ON A GPU if it exists\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to(\"cuda\")\n",
    "\n",
    "        x = self.step1(x)\n",
    "        x = self.step2(x)\n",
    "        x = self.step3(x)\n",
    "        x = self.step4(x)\n",
    "        x = self.step5(x)\n",
    "        x = self.step6(x)\n",
    "        x = self.step7(x)\n",
    "        x = self.step8(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_model(inputs, desired_outputs, num_epochs=100, learning_rate=0.01, viz_accuracy=False):\n",
    "    # Convert inputs and desired_outputs to PyTorch tensors\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    desired_outputs = torch.tensor(desired_outputs, dtype=torch.float32)\n",
    "    \n",
    "    # Create a DataLoader to handle batching (if needed)\n",
    "    dataset = TensorDataset(inputs, desired_outputs)\n",
    "    dataloader = DataLoader(dataset, batch_size=1000, shuffle=True)  # Adjust batch_size as needed\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SimpleModel()\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Mean Squared Error loss\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    # criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "    losses = []\n",
    "\n",
    "    inputs = inputs.float()\n",
    "    desired_outputs = desired_outputs.long()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_inputs, batch_desired_outputs in dataloader:\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(batch_inputs)  # Forward pass\n",
    "\n",
    "            batch_desired_outputs = batch_desired_outputs.long()\n",
    "\n",
    "            loss = criterion(outputs, batch_desired_outputs)  # Compute the loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update the model's parameters\n",
    "            cur_item = loss.item()\n",
    "            total_loss += cur_item\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print the average loss for this epoch\n",
    "        print(f\"total loss: {total_loss}\")\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        if viz_accuracy:\n",
    "            losses.append(average_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "    \n",
    "    if viz_accuracy:\n",
    "        plt.scatter(x=range(1, len(losses)+1), y=losses)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Average loss\")\n",
    "        plt.show()\n",
    "\n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate('matrices_train.csv')\n",
    "generate('matrices_test.csv')\n",
    "df = pd.read_csv(\"matrices_train.csv\")\n",
    "just_input = df.drop('last', axis=1)\n",
    "\n",
    "# adapted from https://stackoverflow.com/questions/43898035/pandas-combine-column-values-into-a-list-in-a-new-column\n",
    "input_data = np.array(just_input.values.tolist())\n",
    "desired_output = torch.tensor(df['last'].tolist(), dtype=torch.float32).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16089\\AppData\\Local\\Temp\\ipykernel_24780\\363369511.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  desired_outputs = torch.tensor(desired_outputs, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: 0.7589369416236877\n",
      "Epoch [1/500], Loss: 0.7589\n",
      "total loss: 0.7533936500549316\n",
      "Epoch [2/500], Loss: 0.7534\n",
      "total loss: 0.7493364214897156\n",
      "Epoch [3/500], Loss: 0.7493\n",
      "total loss: 0.7549396753311157\n",
      "Epoch [4/500], Loss: 0.7549\n",
      "total loss: 0.7450211048126221\n",
      "Epoch [5/500], Loss: 0.7450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: 0.7148690223693848\n",
      "Epoch [6/500], Loss: 0.7149\n",
      "total loss: 0.7116102576255798\n",
      "Epoch [7/500], Loss: 0.7116\n",
      "total loss: 0.7116051912307739\n",
      "Epoch [8/500], Loss: 0.7116\n",
      "total loss: 0.6620272994041443\n",
      "Epoch [9/500], Loss: 0.6620\n",
      "total loss: 0.6819008588790894\n",
      "Epoch [10/500], Loss: 0.6819\n",
      "total loss: 0.6742511987686157\n",
      "Epoch [11/500], Loss: 0.6743\n",
      "total loss: 0.6791456341743469\n",
      "Epoch [12/500], Loss: 0.6791\n",
      "total loss: 0.6998551487922668\n",
      "Epoch [13/500], Loss: 0.6999\n",
      "total loss: 0.6982890963554382\n",
      "Epoch [14/500], Loss: 0.6983\n",
      "total loss: 0.6867495179176331\n",
      "Epoch [15/500], Loss: 0.6867\n",
      "total loss: 0.6712632775306702\n",
      "Epoch [16/500], Loss: 0.6713\n",
      "total loss: 0.6659562587738037\n",
      "Epoch [17/500], Loss: 0.6660\n",
      "total loss: 0.6786578297615051\n",
      "Epoch [18/500], Loss: 0.6787\n",
      "total loss: 0.6832034587860107\n",
      "Epoch [19/500], Loss: 0.6832\n",
      "total loss: 0.6653193831443787\n",
      "Epoch [20/500], Loss: 0.6653\n",
      "total loss: 0.6591976881027222\n",
      "Epoch [21/500], Loss: 0.6592\n",
      "total loss: 0.6510059237480164\n",
      "Epoch [22/500], Loss: 0.6510\n",
      "total loss: 0.6495602130889893\n",
      "Epoch [23/500], Loss: 0.6496\n",
      "total loss: 0.650738537311554\n",
      "Epoch [24/500], Loss: 0.6507\n",
      "total loss: 0.6462993621826172\n",
      "Epoch [25/500], Loss: 0.6463\n",
      "total loss: 0.6463571786880493\n",
      "Epoch [26/500], Loss: 0.6464\n",
      "total loss: 0.6430491805076599\n",
      "Epoch [27/500], Loss: 0.6430\n",
      "total loss: 0.6441726684570312\n",
      "Epoch [28/500], Loss: 0.6442\n",
      "total loss: 0.642436146736145\n",
      "Epoch [29/500], Loss: 0.6424\n",
      "total loss: 0.643543004989624\n",
      "Epoch [30/500], Loss: 0.6435\n",
      "total loss: 0.6435346007347107\n",
      "Epoch [31/500], Loss: 0.6435\n",
      "total loss: 0.6499804258346558\n",
      "Epoch [32/500], Loss: 0.6500\n",
      "total loss: 0.648541271686554\n",
      "Epoch [33/500], Loss: 0.6485\n",
      "total loss: 0.6443448662757874\n",
      "Epoch [34/500], Loss: 0.6443\n",
      "total loss: 0.6435641646385193\n",
      "Epoch [35/500], Loss: 0.6436\n",
      "total loss: 0.6335406303405762\n",
      "Epoch [36/500], Loss: 0.6335\n",
      "total loss: 0.6293112635612488\n",
      "Epoch [37/500], Loss: 0.6293\n",
      "total loss: 0.6325410604476929\n",
      "Epoch [38/500], Loss: 0.6325\n",
      "total loss: 0.6294060349464417\n",
      "Epoch [39/500], Loss: 0.6294\n",
      "total loss: 0.6226921677589417\n",
      "Epoch [40/500], Loss: 0.6227\n",
      "total loss: 0.6203138828277588\n",
      "Epoch [41/500], Loss: 0.6203\n",
      "total loss: 0.6157834529876709\n",
      "Epoch [42/500], Loss: 0.6158\n",
      "total loss: 0.6097226738929749\n",
      "Epoch [43/500], Loss: 0.6097\n",
      "total loss: 0.6112905144691467\n",
      "Epoch [44/500], Loss: 0.6113\n",
      "total loss: 0.6070670485496521\n",
      "Epoch [45/500], Loss: 0.6071\n",
      "total loss: 0.6009408831596375\n",
      "Epoch [46/500], Loss: 0.6009\n",
      "total loss: 0.6060277819633484\n",
      "Epoch [47/500], Loss: 0.6060\n",
      "total loss: 0.6067025661468506\n",
      "Epoch [48/500], Loss: 0.6067\n",
      "total loss: 0.610455334186554\n",
      "Epoch [49/500], Loss: 0.6105\n",
      "total loss: 0.6043631434440613\n",
      "Epoch [50/500], Loss: 0.6044\n",
      "total loss: 0.5986717343330383\n",
      "Epoch [51/500], Loss: 0.5987\n",
      "total loss: 0.5967168211936951\n",
      "Epoch [52/500], Loss: 0.5967\n",
      "total loss: 0.5999459028244019\n",
      "Epoch [53/500], Loss: 0.5999\n",
      "total loss: 0.6075194478034973\n",
      "Epoch [54/500], Loss: 0.6075\n",
      "total loss: 0.6057605147361755\n",
      "Epoch [55/500], Loss: 0.6058\n",
      "total loss: 0.605890691280365\n",
      "Epoch [56/500], Loss: 0.6059\n",
      "total loss: 0.6092399954795837\n",
      "Epoch [57/500], Loss: 0.6092\n",
      "total loss: 0.607010543346405\n",
      "Epoch [58/500], Loss: 0.6070\n",
      "total loss: 0.6033229231834412\n",
      "Epoch [59/500], Loss: 0.6033\n",
      "total loss: 0.5988520383834839\n",
      "Epoch [60/500], Loss: 0.5989\n",
      "total loss: 0.5910159349441528\n",
      "Epoch [61/500], Loss: 0.5910\n",
      "total loss: 0.5955273509025574\n",
      "Epoch [62/500], Loss: 0.5955\n",
      "total loss: 0.5939998626708984\n",
      "Epoch [63/500], Loss: 0.5940\n",
      "total loss: 0.6104896068572998\n",
      "Epoch [64/500], Loss: 0.6105\n",
      "total loss: 0.605920672416687\n",
      "Epoch [65/500], Loss: 0.6059\n",
      "total loss: 0.6007277369499207\n",
      "Epoch [66/500], Loss: 0.6007\n",
      "total loss: 0.6034924983978271\n",
      "Epoch [67/500], Loss: 0.6035\n",
      "total loss: 0.6054497957229614\n",
      "Epoch [68/500], Loss: 0.6054\n",
      "total loss: 0.5942135453224182\n",
      "Epoch [69/500], Loss: 0.5942\n",
      "total loss: 0.5932654738426208\n",
      "Epoch [70/500], Loss: 0.5933\n",
      "total loss: 0.5917542576789856\n",
      "Epoch [71/500], Loss: 0.5918\n",
      "total loss: 0.5935044884681702\n",
      "Epoch [72/500], Loss: 0.5935\n",
      "total loss: 0.5915622711181641\n",
      "Epoch [73/500], Loss: 0.5916\n",
      "total loss: 0.5957198739051819\n",
      "Epoch [74/500], Loss: 0.5957\n",
      "total loss: 0.6061620116233826\n",
      "Epoch [75/500], Loss: 0.6062\n",
      "total loss: 0.6165336966514587\n",
      "Epoch [76/500], Loss: 0.6165\n",
      "total loss: 0.6185688972473145\n",
      "Epoch [77/500], Loss: 0.6186\n",
      "total loss: 0.6169109344482422\n",
      "Epoch [78/500], Loss: 0.6169\n",
      "total loss: 0.6345509886741638\n",
      "Epoch [79/500], Loss: 0.6346\n",
      "total loss: 0.6440489292144775\n",
      "Epoch [80/500], Loss: 0.6440\n",
      "total loss: 0.6479100584983826\n",
      "Epoch [81/500], Loss: 0.6479\n",
      "total loss: 0.6464523673057556\n",
      "Epoch [82/500], Loss: 0.6465\n",
      "total loss: 0.63844233751297\n",
      "Epoch [83/500], Loss: 0.6384\n",
      "total loss: 0.6257752180099487\n",
      "Epoch [84/500], Loss: 0.6258\n",
      "total loss: 0.6054444909095764\n",
      "Epoch [85/500], Loss: 0.6054\n",
      "total loss: 0.6055726408958435\n",
      "Epoch [86/500], Loss: 0.6056\n",
      "total loss: 0.6047741174697876\n",
      "Epoch [87/500], Loss: 0.6048\n",
      "total loss: 0.6073856353759766\n",
      "Epoch [88/500], Loss: 0.6074\n",
      "total loss: 0.6080037951469421\n",
      "Epoch [89/500], Loss: 0.6080\n",
      "total loss: 0.6052413582801819\n",
      "Epoch [90/500], Loss: 0.6052\n",
      "total loss: 0.6043033599853516\n",
      "Epoch [91/500], Loss: 0.6043\n",
      "total loss: 0.6041296720504761\n",
      "Epoch [92/500], Loss: 0.6041\n",
      "total loss: 0.6004490256309509\n",
      "Epoch [93/500], Loss: 0.6004\n",
      "total loss: 0.5991531014442444\n",
      "Epoch [94/500], Loss: 0.5992\n",
      "total loss: 0.5957188606262207\n",
      "Epoch [95/500], Loss: 0.5957\n",
      "total loss: 0.5948336124420166\n",
      "Epoch [96/500], Loss: 0.5948\n",
      "total loss: 0.5944593548774719\n",
      "Epoch [97/500], Loss: 0.5945\n",
      "total loss: 0.5927270650863647\n",
      "Epoch [98/500], Loss: 0.5927\n",
      "total loss: 0.5876142382621765\n",
      "Epoch [99/500], Loss: 0.5876\n",
      "total loss: 0.5872881412506104\n",
      "Epoch [100/500], Loss: 0.5873\n",
      "total loss: 0.5871142745018005\n",
      "Epoch [101/500], Loss: 0.5871\n",
      "total loss: 0.5848175287246704\n",
      "Epoch [102/500], Loss: 0.5848\n",
      "total loss: 0.5833831429481506\n",
      "Epoch [103/500], Loss: 0.5834\n",
      "total loss: 0.5829218029975891\n",
      "Epoch [104/500], Loss: 0.5829\n",
      "total loss: 0.5849348902702332\n",
      "Epoch [105/500], Loss: 0.5849\n",
      "total loss: 0.583823561668396\n",
      "Epoch [106/500], Loss: 0.5838\n",
      "total loss: 0.5842026472091675\n",
      "Epoch [107/500], Loss: 0.5842\n",
      "total loss: 0.5835452675819397\n",
      "Epoch [108/500], Loss: 0.5835\n",
      "total loss: 0.5841524600982666\n",
      "Epoch [109/500], Loss: 0.5842\n",
      "total loss: 0.5828260183334351\n",
      "Epoch [110/500], Loss: 0.5828\n",
      "total loss: 0.582577645778656\n",
      "Epoch [111/500], Loss: 0.5826\n",
      "total loss: 0.5826162099838257\n",
      "Epoch [112/500], Loss: 0.5826\n",
      "total loss: 0.583820104598999\n",
      "Epoch [113/500], Loss: 0.5838\n",
      "total loss: 0.5835130214691162\n",
      "Epoch [114/500], Loss: 0.5835\n",
      "total loss: 0.5840203166007996\n",
      "Epoch [115/500], Loss: 0.5840\n",
      "total loss: 0.5834197402000427\n",
      "Epoch [116/500], Loss: 0.5834\n",
      "total loss: 0.582015335559845\n",
      "Epoch [117/500], Loss: 0.5820\n",
      "total loss: 0.5817914605140686\n",
      "Epoch [118/500], Loss: 0.5818\n",
      "total loss: 0.5814546346664429\n",
      "Epoch [119/500], Loss: 0.5815\n",
      "total loss: 0.5824618935585022\n",
      "Epoch [120/500], Loss: 0.5825\n",
      "total loss: 0.581209123134613\n",
      "Epoch [121/500], Loss: 0.5812\n",
      "total loss: 0.5807703733444214\n",
      "Epoch [122/500], Loss: 0.5808\n",
      "total loss: 0.5823324918746948\n",
      "Epoch [123/500], Loss: 0.5823\n",
      "total loss: 0.583473801612854\n",
      "Epoch [124/500], Loss: 0.5835\n",
      "total loss: 0.5866370797157288\n",
      "Epoch [125/500], Loss: 0.5866\n",
      "total loss: 0.5871194005012512\n",
      "Epoch [126/500], Loss: 0.5871\n",
      "total loss: 0.5873724222183228\n",
      "Epoch [127/500], Loss: 0.5874\n",
      "total loss: 0.5875555276870728\n",
      "Epoch [128/500], Loss: 0.5876\n",
      "total loss: 0.5874316692352295\n",
      "Epoch [129/500], Loss: 0.5874\n",
      "total loss: 0.5881467461585999\n",
      "Epoch [130/500], Loss: 0.5881\n",
      "total loss: 0.5904771685600281\n",
      "Epoch [131/500], Loss: 0.5905\n",
      "total loss: 0.5905418992042542\n",
      "Epoch [132/500], Loss: 0.5905\n",
      "total loss: 0.5906656384468079\n",
      "Epoch [133/500], Loss: 0.5907\n",
      "total loss: 0.5938703417778015\n",
      "Epoch [134/500], Loss: 0.5939\n",
      "total loss: 0.603652834892273\n",
      "Epoch [135/500], Loss: 0.6037\n",
      "total loss: 0.6083604097366333\n",
      "Epoch [136/500], Loss: 0.6084\n",
      "total loss: 0.605276346206665\n",
      "Epoch [137/500], Loss: 0.6053\n",
      "total loss: 0.5899357795715332\n",
      "Epoch [138/500], Loss: 0.5899\n",
      "total loss: 0.5855616331100464\n",
      "Epoch [139/500], Loss: 0.5856\n",
      "total loss: 0.584805965423584\n",
      "Epoch [140/500], Loss: 0.5848\n",
      "total loss: 0.5841878652572632\n",
      "Epoch [141/500], Loss: 0.5842\n",
      "total loss: 0.5850774049758911\n",
      "Epoch [142/500], Loss: 0.5851\n",
      "total loss: 0.5852126479148865\n",
      "Epoch [143/500], Loss: 0.5852\n",
      "total loss: 0.5830937027931213\n",
      "Epoch [144/500], Loss: 0.5831\n",
      "total loss: 0.5831266045570374\n",
      "Epoch [145/500], Loss: 0.5831\n",
      "total loss: 0.5831693410873413\n",
      "Epoch [146/500], Loss: 0.5832\n",
      "total loss: 0.5832093954086304\n",
      "Epoch [147/500], Loss: 0.5832\n",
      "total loss: 0.5828805565834045\n",
      "Epoch [148/500], Loss: 0.5829\n",
      "total loss: 0.5817159414291382\n",
      "Epoch [149/500], Loss: 0.5817\n",
      "total loss: 0.5812646150588989\n",
      "Epoch [150/500], Loss: 0.5813\n",
      "total loss: 0.5862351655960083\n",
      "Epoch [151/500], Loss: 0.5862\n",
      "total loss: 0.5970946550369263\n",
      "Epoch [152/500], Loss: 0.5971\n",
      "total loss: 0.5976603031158447\n",
      "Epoch [153/500], Loss: 0.5977\n",
      "total loss: 0.5995715260505676\n",
      "Epoch [154/500], Loss: 0.5996\n",
      "total loss: 0.5998710989952087\n",
      "Epoch [155/500], Loss: 0.5999\n",
      "total loss: 0.5997008681297302\n",
      "Epoch [156/500], Loss: 0.5997\n",
      "total loss: 0.5984994769096375\n",
      "Epoch [157/500], Loss: 0.5985\n",
      "total loss: 0.5984494686126709\n",
      "Epoch [158/500], Loss: 0.5984\n",
      "total loss: 0.5973864793777466\n",
      "Epoch [159/500], Loss: 0.5974\n",
      "total loss: 0.5973105430603027\n",
      "Epoch [160/500], Loss: 0.5973\n",
      "total loss: 0.5974641442298889\n",
      "Epoch [161/500], Loss: 0.5975\n",
      "total loss: 0.5972365736961365\n",
      "Epoch [162/500], Loss: 0.5972\n",
      "total loss: 0.5970618724822998\n",
      "Epoch [163/500], Loss: 0.5971\n",
      "total loss: 0.5969640016555786\n",
      "Epoch [164/500], Loss: 0.5970\n",
      "total loss: 0.5968506336212158\n",
      "Epoch [165/500], Loss: 0.5969\n",
      "total loss: 0.5967245697975159\n",
      "Epoch [166/500], Loss: 0.5967\n",
      "total loss: 0.5965882539749146\n",
      "Epoch [167/500], Loss: 0.5966\n",
      "total loss: 0.5964405536651611\n",
      "Epoch [168/500], Loss: 0.5964\n",
      "total loss: 0.5962802171707153\n",
      "Epoch [169/500], Loss: 0.5963\n",
      "total loss: 0.5961111187934875\n",
      "Epoch [170/500], Loss: 0.5961\n",
      "total loss: 0.5959200859069824\n",
      "Epoch [171/500], Loss: 0.5959\n",
      "total loss: 0.5957021117210388\n",
      "Epoch [172/500], Loss: 0.5957\n",
      "total loss: 0.5954706072807312\n",
      "Epoch [173/500], Loss: 0.5955\n",
      "total loss: 0.5952342748641968\n",
      "Epoch [174/500], Loss: 0.5952\n",
      "total loss: 0.5949793457984924\n",
      "Epoch [175/500], Loss: 0.5950\n",
      "total loss: 0.5947059392929077\n",
      "Epoch [176/500], Loss: 0.5947\n",
      "total loss: 0.5944094657897949\n",
      "Epoch [177/500], Loss: 0.5944\n",
      "total loss: 0.5940948128700256\n",
      "Epoch [178/500], Loss: 0.5941\n",
      "total loss: 0.5947701930999756\n",
      "Epoch [179/500], Loss: 0.5948\n",
      "total loss: 0.5944697856903076\n",
      "Epoch [180/500], Loss: 0.5945\n",
      "total loss: 0.5941731929779053\n",
      "Epoch [181/500], Loss: 0.5942\n",
      "total loss: 0.5935068726539612\n",
      "Epoch [182/500], Loss: 0.5935\n",
      "total loss: 0.5919123888015747\n",
      "Epoch [183/500], Loss: 0.5919\n",
      "total loss: 0.59066241979599\n",
      "Epoch [184/500], Loss: 0.5907\n",
      "total loss: 0.5870627164840698\n",
      "Epoch [185/500], Loss: 0.5871\n",
      "total loss: 0.5824021100997925\n",
      "Epoch [186/500], Loss: 0.5824\n",
      "total loss: 0.5797751545906067\n",
      "Epoch [187/500], Loss: 0.5798\n",
      "total loss: 0.578533411026001\n",
      "Epoch [188/500], Loss: 0.5785\n",
      "total loss: 0.5788282752037048\n",
      "Epoch [189/500], Loss: 0.5788\n",
      "total loss: 0.5799849629402161\n",
      "Epoch [190/500], Loss: 0.5800\n",
      "total loss: 0.5811284184455872\n",
      "Epoch [191/500], Loss: 0.5811\n",
      "total loss: 0.5832616090774536\n",
      "Epoch [192/500], Loss: 0.5833\n",
      "total loss: 0.5832631587982178\n",
      "Epoch [193/500], Loss: 0.5833\n",
      "total loss: 0.5825279951095581\n",
      "Epoch [194/500], Loss: 0.5825\n",
      "total loss: 0.5822550654411316\n",
      "Epoch [195/500], Loss: 0.5823\n",
      "total loss: 0.5822859406471252\n",
      "Epoch [196/500], Loss: 0.5823\n",
      "total loss: 0.5823261737823486\n",
      "Epoch [197/500], Loss: 0.5823\n",
      "total loss: 0.5845277905464172\n",
      "Epoch [198/500], Loss: 0.5845\n",
      "total loss: 0.5858937501907349\n",
      "Epoch [199/500], Loss: 0.5859\n",
      "total loss: 0.5844178795814514\n",
      "Epoch [200/500], Loss: 0.5844\n",
      "total loss: 0.5812679529190063\n",
      "Epoch [201/500], Loss: 0.5813\n",
      "total loss: 0.5811960697174072\n",
      "Epoch [202/500], Loss: 0.5812\n",
      "total loss: 0.5804034471511841\n",
      "Epoch [203/500], Loss: 0.5804\n",
      "total loss: 0.5801136493682861\n",
      "Epoch [204/500], Loss: 0.5801\n",
      "total loss: 0.5796276330947876\n",
      "Epoch [205/500], Loss: 0.5796\n",
      "total loss: 0.5805748105049133\n",
      "Epoch [206/500], Loss: 0.5806\n",
      "total loss: 0.5810104012489319\n",
      "Epoch [207/500], Loss: 0.5810\n",
      "total loss: 0.5816082954406738\n",
      "Epoch [208/500], Loss: 0.5816\n",
      "total loss: 0.5829893946647644\n",
      "Epoch [209/500], Loss: 0.5830\n",
      "total loss: 0.5830478072166443\n",
      "Epoch [210/500], Loss: 0.5830\n",
      "total loss: 0.5827766060829163\n",
      "Epoch [211/500], Loss: 0.5828\n",
      "total loss: 0.5826855897903442\n",
      "Epoch [212/500], Loss: 0.5827\n",
      "total loss: 0.5832265615463257\n",
      "Epoch [213/500], Loss: 0.5832\n",
      "total loss: 0.5845453143119812\n",
      "Epoch [214/500], Loss: 0.5845\n",
      "total loss: 0.5822805166244507\n",
      "Epoch [215/500], Loss: 0.5823\n",
      "total loss: 0.582127571105957\n",
      "Epoch [216/500], Loss: 0.5821\n",
      "total loss: 0.5830252766609192\n",
      "Epoch [217/500], Loss: 0.5830\n",
      "total loss: 0.5817329287528992\n",
      "Epoch [218/500], Loss: 0.5817\n",
      "total loss: 0.581566333770752\n",
      "Epoch [219/500], Loss: 0.5816\n",
      "total loss: 0.582463800907135\n",
      "Epoch [220/500], Loss: 0.5825\n",
      "total loss: 0.5823931694030762\n",
      "Epoch [221/500], Loss: 0.5824\n",
      "total loss: 0.580350935459137\n",
      "Epoch [222/500], Loss: 0.5804\n",
      "total loss: 0.581297755241394\n",
      "Epoch [223/500], Loss: 0.5813\n",
      "total loss: 0.5804322957992554\n",
      "Epoch [224/500], Loss: 0.5804\n",
      "total loss: 0.5804135799407959\n",
      "Epoch [225/500], Loss: 0.5804\n",
      "total loss: 0.5803850293159485\n",
      "Epoch [226/500], Loss: 0.5804\n",
      "total loss: 0.5808186531066895\n",
      "Epoch [227/500], Loss: 0.5808\n",
      "total loss: 0.5823920369148254\n",
      "Epoch [228/500], Loss: 0.5824\n",
      "total loss: 0.5837920308113098\n",
      "Epoch [229/500], Loss: 0.5838\n",
      "total loss: 0.584412157535553\n",
      "Epoch [230/500], Loss: 0.5844\n",
      "total loss: 0.5849306583404541\n",
      "Epoch [231/500], Loss: 0.5849\n",
      "total loss: 0.5868359208106995\n",
      "Epoch [232/500], Loss: 0.5868\n",
      "total loss: 0.587088942527771\n",
      "Epoch [233/500], Loss: 0.5871\n",
      "total loss: 0.5871975421905518\n",
      "Epoch [234/500], Loss: 0.5872\n",
      "total loss: 0.5886558294296265\n",
      "Epoch [235/500], Loss: 0.5887\n",
      "total loss: 0.5864333510398865\n",
      "Epoch [236/500], Loss: 0.5864\n",
      "total loss: 0.5837287306785583\n",
      "Epoch [237/500], Loss: 0.5837\n",
      "total loss: 0.5815476179122925\n",
      "Epoch [238/500], Loss: 0.5815\n",
      "total loss: 0.5804991722106934\n",
      "Epoch [239/500], Loss: 0.5805\n",
      "total loss: 0.5800656676292419\n",
      "Epoch [240/500], Loss: 0.5801\n",
      "total loss: 0.5791819095611572\n",
      "Epoch [241/500], Loss: 0.5792\n",
      "total loss: 0.5809193253517151\n",
      "Epoch [242/500], Loss: 0.5809\n",
      "total loss: 0.5815356373786926\n",
      "Epoch [243/500], Loss: 0.5815\n",
      "total loss: 0.5816744565963745\n",
      "Epoch [244/500], Loss: 0.5817\n",
      "total loss: 0.5854088068008423\n",
      "Epoch [245/500], Loss: 0.5854\n",
      "total loss: 0.5858913660049438\n",
      "Epoch [246/500], Loss: 0.5859\n",
      "total loss: 0.5876665115356445\n",
      "Epoch [247/500], Loss: 0.5877\n",
      "total loss: 0.5869278311729431\n",
      "Epoch [248/500], Loss: 0.5869\n",
      "total loss: 0.5869126915931702\n",
      "Epoch [249/500], Loss: 0.5869\n",
      "total loss: 0.5855938792228699\n",
      "Epoch [250/500], Loss: 0.5856\n",
      "total loss: 0.5837736129760742\n",
      "Epoch [251/500], Loss: 0.5838\n",
      "total loss: 0.5816813111305237\n",
      "Epoch [252/500], Loss: 0.5817\n",
      "total loss: 0.5815859436988831\n",
      "Epoch [253/500], Loss: 0.5816\n",
      "total loss: 0.5825221538543701\n",
      "Epoch [254/500], Loss: 0.5825\n",
      "total loss: 0.5824863314628601\n",
      "Epoch [255/500], Loss: 0.5825\n",
      "total loss: 0.5814527869224548\n",
      "Epoch [256/500], Loss: 0.5815\n",
      "total loss: 0.5804376006126404\n",
      "Epoch [257/500], Loss: 0.5804\n",
      "total loss: 0.5804440379142761\n",
      "Epoch [258/500], Loss: 0.5804\n",
      "total loss: 0.5794541835784912\n",
      "Epoch [259/500], Loss: 0.5795\n",
      "total loss: 0.5794625282287598\n",
      "Epoch [260/500], Loss: 0.5795\n",
      "total loss: 0.5794708132743835\n",
      "Epoch [261/500], Loss: 0.5795\n",
      "total loss: 0.5794782042503357\n",
      "Epoch [262/500], Loss: 0.5795\n",
      "total loss: 0.5794786810874939\n",
      "Epoch [263/500], Loss: 0.5795\n",
      "total loss: 0.5794721245765686\n",
      "Epoch [264/500], Loss: 0.5795\n",
      "total loss: 0.5794699192047119\n",
      "Epoch [265/500], Loss: 0.5795\n",
      "total loss: 0.5794651508331299\n",
      "Epoch [266/500], Loss: 0.5795\n",
      "total loss: 0.5794525742530823\n",
      "Epoch [267/500], Loss: 0.5795\n",
      "total loss: 0.5804368853569031\n",
      "Epoch [268/500], Loss: 0.5804\n",
      "total loss: 0.5804213881492615\n",
      "Epoch [269/500], Loss: 0.5804\n",
      "total loss: 0.5804036855697632\n",
      "Epoch [270/500], Loss: 0.5804\n",
      "total loss: 0.5803802013397217\n",
      "Epoch [271/500], Loss: 0.5804\n",
      "total loss: 0.5803540945053101\n",
      "Epoch [272/500], Loss: 0.5804\n",
      "total loss: 0.5803282856941223\n",
      "Epoch [273/500], Loss: 0.5803\n",
      "total loss: 0.5802990794181824\n",
      "Epoch [274/500], Loss: 0.5803\n",
      "total loss: 0.5802675485610962\n",
      "Epoch [275/500], Loss: 0.5803\n",
      "total loss: 0.580235481262207\n",
      "Epoch [276/500], Loss: 0.5802\n",
      "total loss: 0.5802051424980164\n",
      "Epoch [277/500], Loss: 0.5802\n",
      "total loss: 0.5801754593849182\n",
      "Epoch [278/500], Loss: 0.5802\n",
      "total loss: 0.5801440477371216\n",
      "Epoch [279/500], Loss: 0.5801\n",
      "total loss: 0.5801259279251099\n",
      "Epoch [280/500], Loss: 0.5801\n",
      "total loss: 0.5800929665565491\n",
      "Epoch [281/500], Loss: 0.5801\n",
      "total loss: 0.5800621509552002\n",
      "Epoch [282/500], Loss: 0.5801\n",
      "total loss: 0.5790402889251709\n",
      "Epoch [283/500], Loss: 0.5790\n",
      "total loss: 0.5790108442306519\n",
      "Epoch [284/500], Loss: 0.5790\n",
      "total loss: 0.5789792537689209\n",
      "Epoch [285/500], Loss: 0.5790\n",
      "total loss: 0.5789495706558228\n",
      "Epoch [286/500], Loss: 0.5789\n",
      "total loss: 0.578917384147644\n",
      "Epoch [287/500], Loss: 0.5789\n",
      "total loss: 0.5788734555244446\n",
      "Epoch [288/500], Loss: 0.5789\n",
      "total loss: 0.57881760597229\n",
      "Epoch [289/500], Loss: 0.5788\n",
      "total loss: 0.5777559876441956\n",
      "Epoch [290/500], Loss: 0.5778\n",
      "total loss: 0.5776642560958862\n",
      "Epoch [291/500], Loss: 0.5777\n",
      "total loss: 0.5775759220123291\n",
      "Epoch [292/500], Loss: 0.5776\n",
      "total loss: 0.5774477124214172\n",
      "Epoch [293/500], Loss: 0.5774\n",
      "total loss: 0.5771703124046326\n",
      "Epoch [294/500], Loss: 0.5772\n",
      "total loss: 0.5778570175170898\n",
      "Epoch [295/500], Loss: 0.5779\n",
      "total loss: 0.5775298476219177\n",
      "Epoch [296/500], Loss: 0.5775\n",
      "total loss: 0.5773286819458008\n",
      "Epoch [297/500], Loss: 0.5773\n",
      "total loss: 0.577153205871582\n",
      "Epoch [298/500], Loss: 0.5772\n",
      "total loss: 0.5770394802093506\n",
      "Epoch [299/500], Loss: 0.5770\n",
      "total loss: 0.576984167098999\n",
      "Epoch [300/500], Loss: 0.5770\n",
      "total loss: 0.5769593715667725\n",
      "Epoch [301/500], Loss: 0.5770\n",
      "total loss: 0.5769377946853638\n",
      "Epoch [302/500], Loss: 0.5769\n",
      "total loss: 0.5769181847572327\n",
      "Epoch [303/500], Loss: 0.5769\n",
      "total loss: 0.5769054889678955\n",
      "Epoch [304/500], Loss: 0.5769\n",
      "total loss: 0.5768923759460449\n",
      "Epoch [305/500], Loss: 0.5769\n",
      "total loss: 0.5768783688545227\n",
      "Epoch [306/500], Loss: 0.5769\n",
      "total loss: 0.5768746137619019\n",
      "Epoch [307/500], Loss: 0.5769\n",
      "total loss: 0.5768545866012573\n",
      "Epoch [308/500], Loss: 0.5769\n",
      "total loss: 0.5778446197509766\n",
      "Epoch [309/500], Loss: 0.5778\n",
      "total loss: 0.5778359770774841\n",
      "Epoch [310/500], Loss: 0.5778\n",
      "total loss: 0.5788272619247437\n",
      "Epoch [311/500], Loss: 0.5788\n",
      "total loss: 0.5788156986236572\n",
      "Epoch [312/500], Loss: 0.5788\n",
      "total loss: 0.5788019895553589\n",
      "Epoch [313/500], Loss: 0.5788\n",
      "total loss: 0.5787866115570068\n",
      "Epoch [314/500], Loss: 0.5788\n",
      "total loss: 0.5787704586982727\n",
      "Epoch [315/500], Loss: 0.5788\n",
      "total loss: 0.5777570605278015\n",
      "Epoch [316/500], Loss: 0.5778\n",
      "total loss: 0.5777435898780823\n",
      "Epoch [317/500], Loss: 0.5777\n",
      "total loss: 0.5767297148704529\n",
      "Epoch [318/500], Loss: 0.5767\n",
      "total loss: 0.5767228007316589\n",
      "Epoch [319/500], Loss: 0.5767\n",
      "total loss: 0.5777003169059753\n",
      "Epoch [320/500], Loss: 0.5777\n",
      "total loss: 0.578687310218811\n",
      "Epoch [321/500], Loss: 0.5787\n",
      "total loss: 0.5786764621734619\n",
      "Epoch [322/500], Loss: 0.5787\n",
      "total loss: 0.5786309838294983\n",
      "Epoch [323/500], Loss: 0.5786\n",
      "total loss: 0.5776470303535461\n",
      "Epoch [324/500], Loss: 0.5776\n",
      "total loss: 0.5776848793029785\n",
      "Epoch [325/500], Loss: 0.5777\n",
      "total loss: 0.577838659286499\n",
      "Epoch [326/500], Loss: 0.5778\n",
      "total loss: 0.5781198143959045\n",
      "Epoch [327/500], Loss: 0.5781\n",
      "total loss: 0.5783039927482605\n",
      "Epoch [328/500], Loss: 0.5783\n",
      "total loss: 0.5782307386398315\n",
      "Epoch [329/500], Loss: 0.5782\n",
      "total loss: 0.5779889822006226\n",
      "Epoch [330/500], Loss: 0.5780\n",
      "total loss: 0.575751781463623\n",
      "Epoch [331/500], Loss: 0.5758\n",
      "total loss: 0.5756168365478516\n",
      "Epoch [332/500], Loss: 0.5756\n",
      "total loss: 0.575548529624939\n",
      "Epoch [333/500], Loss: 0.5755\n",
      "total loss: 0.5755121111869812\n",
      "Epoch [334/500], Loss: 0.5755\n",
      "total loss: 0.5754896998405457\n",
      "Epoch [335/500], Loss: 0.5755\n",
      "total loss: 0.5754727721214294\n",
      "Epoch [336/500], Loss: 0.5755\n",
      "total loss: 0.5754594802856445\n",
      "Epoch [337/500], Loss: 0.5755\n",
      "total loss: 0.57546466588974\n",
      "Epoch [338/500], Loss: 0.5755\n",
      "total loss: 0.5756194591522217\n",
      "Epoch [339/500], Loss: 0.5756\n",
      "total loss: 0.5754328966140747\n",
      "Epoch [340/500], Loss: 0.5754\n",
      "total loss: 0.5754246711730957\n",
      "Epoch [341/500], Loss: 0.5754\n",
      "total loss: 0.5754193663597107\n",
      "Epoch [342/500], Loss: 0.5754\n",
      "total loss: 0.5754140019416809\n",
      "Epoch [343/500], Loss: 0.5754\n",
      "total loss: 0.575412392616272\n",
      "Epoch [344/500], Loss: 0.5754\n",
      "total loss: 0.5754017233848572\n",
      "Epoch [345/500], Loss: 0.5754\n",
      "total loss: 0.5763956308364868\n",
      "Epoch [346/500], Loss: 0.5764\n",
      "total loss: 0.5763905048370361\n",
      "Epoch [347/500], Loss: 0.5764\n",
      "total loss: 0.5763939619064331\n",
      "Epoch [348/500], Loss: 0.5764\n",
      "total loss: 0.5759957432746887\n",
      "Epoch [349/500], Loss: 0.5760\n",
      "total loss: 0.5772376656532288\n",
      "Epoch [350/500], Loss: 0.5772\n",
      "total loss: 0.5772764682769775\n",
      "Epoch [351/500], Loss: 0.5773\n",
      "total loss: 0.5785492062568665\n",
      "Epoch [352/500], Loss: 0.5785\n",
      "total loss: 0.5788260698318481\n",
      "Epoch [353/500], Loss: 0.5788\n",
      "total loss: 0.579099714756012\n",
      "Epoch [354/500], Loss: 0.5791\n",
      "total loss: 0.5793609619140625\n",
      "Epoch [355/500], Loss: 0.5794\n",
      "total loss: 0.5795857906341553\n",
      "Epoch [356/500], Loss: 0.5796\n",
      "total loss: 0.5797703266143799\n",
      "Epoch [357/500], Loss: 0.5798\n",
      "total loss: 0.5799158811569214\n",
      "Epoch [358/500], Loss: 0.5799\n",
      "total loss: 0.5800095796585083\n",
      "Epoch [359/500], Loss: 0.5800\n",
      "total loss: 0.580078661441803\n",
      "Epoch [360/500], Loss: 0.5801\n",
      "total loss: 0.5801364183425903\n",
      "Epoch [361/500], Loss: 0.5801\n",
      "total loss: 0.5801853537559509\n",
      "Epoch [362/500], Loss: 0.5802\n",
      "total loss: 0.580224871635437\n",
      "Epoch [363/500], Loss: 0.5802\n",
      "total loss: 0.5802555084228516\n",
      "Epoch [364/500], Loss: 0.5803\n",
      "total loss: 0.5802757143974304\n",
      "Epoch [365/500], Loss: 0.5803\n",
      "total loss: 0.5802878141403198\n",
      "Epoch [366/500], Loss: 0.5803\n",
      "total loss: 0.5802930593490601\n",
      "Epoch [367/500], Loss: 0.5803\n",
      "total loss: 0.5802907943725586\n",
      "Epoch [368/500], Loss: 0.5803\n",
      "total loss: 0.5802828073501587\n",
      "Epoch [369/500], Loss: 0.5803\n",
      "total loss: 0.5802706480026245\n",
      "Epoch [370/500], Loss: 0.5803\n",
      "total loss: 0.580255389213562\n",
      "Epoch [371/500], Loss: 0.5803\n",
      "total loss: 0.5802372694015503\n",
      "Epoch [372/500], Loss: 0.5802\n",
      "total loss: 0.5802173018455505\n",
      "Epoch [373/500], Loss: 0.5802\n",
      "total loss: 0.5801961421966553\n",
      "Epoch [374/500], Loss: 0.5802\n",
      "total loss: 0.5801742672920227\n",
      "Epoch [375/500], Loss: 0.5802\n",
      "total loss: 0.5801520943641663\n",
      "Epoch [376/500], Loss: 0.5802\n",
      "total loss: 0.5801303386688232\n",
      "Epoch [377/500], Loss: 0.5801\n",
      "total loss: 0.580109179019928\n",
      "Epoch [378/500], Loss: 0.5801\n",
      "total loss: 0.5800886154174805\n",
      "Epoch [379/500], Loss: 0.5801\n",
      "total loss: 0.5800688862800598\n",
      "Epoch [380/500], Loss: 0.5801\n",
      "total loss: 0.5800502300262451\n",
      "Epoch [381/500], Loss: 0.5801\n",
      "total loss: 0.5800324082374573\n",
      "Epoch [382/500], Loss: 0.5800\n",
      "total loss: 0.5800154209136963\n",
      "Epoch [383/500], Loss: 0.5800\n",
      "total loss: 0.5799992084503174\n",
      "Epoch [384/500], Loss: 0.5800\n",
      "total loss: 0.5799838304519653\n",
      "Epoch [385/500], Loss: 0.5800\n",
      "total loss: 0.579969048500061\n",
      "Epoch [386/500], Loss: 0.5800\n",
      "total loss: 0.579954981803894\n",
      "Epoch [387/500], Loss: 0.5800\n",
      "total loss: 0.5799415111541748\n",
      "Epoch [388/500], Loss: 0.5799\n",
      "total loss: 0.5799286365509033\n",
      "Epoch [389/500], Loss: 0.5799\n",
      "total loss: 0.5799163579940796\n",
      "Epoch [390/500], Loss: 0.5799\n",
      "total loss: 0.5799047946929932\n",
      "Epoch [391/500], Loss: 0.5799\n",
      "total loss: 0.5798940062522888\n",
      "Epoch [392/500], Loss: 0.5799\n",
      "total loss: 0.5798847079277039\n",
      "Epoch [393/500], Loss: 0.5799\n",
      "total loss: 0.5798776149749756\n",
      "Epoch [394/500], Loss: 0.5799\n",
      "total loss: 0.5798729658126831\n",
      "Epoch [395/500], Loss: 0.5799\n",
      "total loss: 0.579868733882904\n",
      "Epoch [396/500], Loss: 0.5799\n",
      "total loss: 0.5798607468605042\n",
      "Epoch [397/500], Loss: 0.5799\n",
      "total loss: 0.5798494815826416\n",
      "Epoch [398/500], Loss: 0.5798\n",
      "total loss: 0.5798383951187134\n",
      "Epoch [399/500], Loss: 0.5798\n",
      "total loss: 0.5798290371894836\n",
      "Epoch [400/500], Loss: 0.5798\n",
      "total loss: 0.5798209309577942\n",
      "Epoch [401/500], Loss: 0.5798\n",
      "total loss: 0.5798134803771973\n",
      "Epoch [402/500], Loss: 0.5798\n",
      "total loss: 0.5798060297966003\n",
      "Epoch [403/500], Loss: 0.5798\n",
      "total loss: 0.5797984004020691\n",
      "Epoch [404/500], Loss: 0.5798\n",
      "total loss: 0.5797905921936035\n",
      "Epoch [405/500], Loss: 0.5798\n",
      "total loss: 0.5797826051712036\n",
      "Epoch [406/500], Loss: 0.5798\n",
      "total loss: 0.5797743201255798\n",
      "Epoch [407/500], Loss: 0.5798\n",
      "total loss: 0.5797659754753113\n",
      "Epoch [408/500], Loss: 0.5798\n",
      "total loss: 0.5797574520111084\n",
      "Epoch [409/500], Loss: 0.5798\n",
      "total loss: 0.5797491073608398\n",
      "Epoch [410/500], Loss: 0.5797\n",
      "total loss: 0.5797407031059265\n",
      "Epoch [411/500], Loss: 0.5797\n",
      "total loss: 0.5797324776649475\n",
      "Epoch [412/500], Loss: 0.5797\n",
      "total loss: 0.5797243714332581\n",
      "Epoch [413/500], Loss: 0.5797\n",
      "total loss: 0.579716682434082\n",
      "Epoch [414/500], Loss: 0.5797\n",
      "total loss: 0.5797093510627747\n",
      "Epoch [415/500], Loss: 0.5797\n",
      "total loss: 0.5797019600868225\n",
      "Epoch [416/500], Loss: 0.5797\n",
      "total loss: 0.5796942114830017\n",
      "Epoch [417/500], Loss: 0.5797\n",
      "total loss: 0.5796864032745361\n",
      "Epoch [418/500], Loss: 0.5797\n",
      "total loss: 0.5796783566474915\n",
      "Epoch [419/500], Loss: 0.5797\n",
      "total loss: 0.5796701908111572\n",
      "Epoch [420/500], Loss: 0.5797\n",
      "total loss: 0.5796619653701782\n",
      "Epoch [421/500], Loss: 0.5797\n",
      "total loss: 0.579653799533844\n",
      "Epoch [422/500], Loss: 0.5797\n",
      "total loss: 0.5796458125114441\n",
      "Epoch [423/500], Loss: 0.5796\n",
      "total loss: 0.5796379446983337\n",
      "Epoch [424/500], Loss: 0.5796\n",
      "total loss: 0.5796297192573547\n",
      "Epoch [425/500], Loss: 0.5796\n",
      "total loss: 0.5796211957931519\n",
      "Epoch [426/500], Loss: 0.5796\n",
      "total loss: 0.5796126127243042\n",
      "Epoch [427/500], Loss: 0.5796\n",
      "total loss: 0.5796037316322327\n",
      "Epoch [428/500], Loss: 0.5796\n",
      "total loss: 0.5795947909355164\n",
      "Epoch [429/500], Loss: 0.5796\n",
      "total loss: 0.579585611820221\n",
      "Epoch [430/500], Loss: 0.5796\n",
      "total loss: 0.5795765519142151\n",
      "Epoch [431/500], Loss: 0.5796\n",
      "total loss: 0.5795671939849854\n",
      "Epoch [432/500], Loss: 0.5796\n",
      "total loss: 0.5795577168464661\n",
      "Epoch [433/500], Loss: 0.5796\n",
      "total loss: 0.5795481204986572\n",
      "Epoch [434/500], Loss: 0.5795\n",
      "total loss: 0.5795381665229797\n",
      "Epoch [435/500], Loss: 0.5795\n",
      "total loss: 0.5795280933380127\n",
      "Epoch [436/500], Loss: 0.5795\n",
      "total loss: 0.5795178413391113\n",
      "Epoch [437/500], Loss: 0.5795\n",
      "total loss: 0.5795072913169861\n",
      "Epoch [438/500], Loss: 0.5795\n",
      "total loss: 0.5794965624809265\n",
      "Epoch [439/500], Loss: 0.5795\n",
      "total loss: 0.5794857144355774\n",
      "Epoch [440/500], Loss: 0.5795\n",
      "total loss: 0.5794746279716492\n",
      "Epoch [441/500], Loss: 0.5795\n",
      "total loss: 0.5794633626937866\n",
      "Epoch [442/500], Loss: 0.5795\n",
      "total loss: 0.5794519186019897\n",
      "Epoch [443/500], Loss: 0.5795\n",
      "total loss: 0.5794402956962585\n",
      "Epoch [444/500], Loss: 0.5794\n",
      "total loss: 0.5784286260604858\n",
      "Epoch [445/500], Loss: 0.5784\n",
      "total loss: 0.5784162878990173\n",
      "Epoch [446/500], Loss: 0.5784\n",
      "total loss: 0.578403651714325\n",
      "Epoch [447/500], Loss: 0.5784\n",
      "total loss: 0.5783902406692505\n",
      "Epoch [448/500], Loss: 0.5784\n",
      "total loss: 0.5783753395080566\n",
      "Epoch [449/500], Loss: 0.5784\n",
      "total loss: 0.5783430933952332\n",
      "Epoch [450/500], Loss: 0.5783\n",
      "total loss: 0.5773999691009521\n",
      "Epoch [451/500], Loss: 0.5774\n",
      "total loss: 0.5772902369499207\n",
      "Epoch [452/500], Loss: 0.5773\n",
      "total loss: 0.5772332549095154\n",
      "Epoch [453/500], Loss: 0.5772\n",
      "total loss: 0.5771752595901489\n",
      "Epoch [454/500], Loss: 0.5772\n",
      "total loss: 0.5771149396896362\n",
      "Epoch [455/500], Loss: 0.5771\n",
      "total loss: 0.5770452618598938\n",
      "Epoch [456/500], Loss: 0.5770\n",
      "total loss: 0.5775493383407593\n",
      "Epoch [457/500], Loss: 0.5775\n",
      "total loss: 0.5772054195404053\n",
      "Epoch [458/500], Loss: 0.5772\n",
      "total loss: 0.5793311595916748\n",
      "Epoch [459/500], Loss: 0.5793\n",
      "total loss: 0.5794190168380737\n",
      "Epoch [460/500], Loss: 0.5794\n",
      "total loss: 0.5794975757598877\n",
      "Epoch [461/500], Loss: 0.5795\n",
      "total loss: 0.5795655846595764\n",
      "Epoch [462/500], Loss: 0.5796\n",
      "total loss: 0.5796191692352295\n",
      "Epoch [463/500], Loss: 0.5796\n",
      "total loss: 0.5796678066253662\n",
      "Epoch [464/500], Loss: 0.5797\n",
      "total loss: 0.5797144770622253\n",
      "Epoch [465/500], Loss: 0.5797\n",
      "total loss: 0.5797610282897949\n",
      "Epoch [466/500], Loss: 0.5798\n",
      "total loss: 0.5798081159591675\n",
      "Epoch [467/500], Loss: 0.5798\n",
      "total loss: 0.5798551440238953\n",
      "Epoch [468/500], Loss: 0.5799\n",
      "total loss: 0.5799016356468201\n",
      "Epoch [469/500], Loss: 0.5799\n",
      "total loss: 0.5799456238746643\n",
      "Epoch [470/500], Loss: 0.5799\n",
      "total loss: 0.579985499382019\n",
      "Epoch [471/500], Loss: 0.5800\n",
      "total loss: 0.5800191760063171\n",
      "Epoch [472/500], Loss: 0.5800\n",
      "total loss: 0.5800452828407288\n",
      "Epoch [473/500], Loss: 0.5800\n",
      "total loss: 0.5800638794898987\n",
      "Epoch [474/500], Loss: 0.5801\n",
      "total loss: 0.5800411105155945\n",
      "Epoch [475/500], Loss: 0.5800\n",
      "total loss: 0.5800151824951172\n",
      "Epoch [476/500], Loss: 0.5800\n",
      "total loss: 0.5799857974052429\n",
      "Epoch [477/500], Loss: 0.5800\n",
      "total loss: 0.5799544453620911\n",
      "Epoch [478/500], Loss: 0.5800\n",
      "total loss: 0.5799219012260437\n",
      "Epoch [479/500], Loss: 0.5799\n",
      "total loss: 0.5798881649971008\n",
      "Epoch [480/500], Loss: 0.5799\n",
      "total loss: 0.5798541903495789\n",
      "Epoch [481/500], Loss: 0.5799\n",
      "total loss: 0.5798205733299255\n",
      "Epoch [482/500], Loss: 0.5798\n",
      "total loss: 0.5797874331474304\n",
      "Epoch [483/500], Loss: 0.5798\n",
      "total loss: 0.5797552466392517\n",
      "Epoch [484/500], Loss: 0.5798\n",
      "total loss: 0.5797235369682312\n",
      "Epoch [485/500], Loss: 0.5797\n",
      "total loss: 0.5796929001808167\n",
      "Epoch [486/500], Loss: 0.5797\n",
      "total loss: 0.5796634554862976\n",
      "Epoch [487/500], Loss: 0.5797\n",
      "total loss: 0.5796352624893188\n",
      "Epoch [488/500], Loss: 0.5796\n",
      "total loss: 0.5796079635620117\n",
      "Epoch [489/500], Loss: 0.5796\n",
      "total loss: 0.5795819759368896\n",
      "Epoch [490/500], Loss: 0.5796\n",
      "total loss: 0.5795568823814392\n",
      "Epoch [491/500], Loss: 0.5796\n",
      "total loss: 0.5795327425003052\n",
      "Epoch [492/500], Loss: 0.5795\n",
      "total loss: 0.5795094966888428\n",
      "Epoch [493/500], Loss: 0.5795\n",
      "total loss: 0.5794870853424072\n",
      "Epoch [494/500], Loss: 0.5795\n",
      "total loss: 0.5794655680656433\n",
      "Epoch [495/500], Loss: 0.5795\n",
      "total loss: 0.5794444680213928\n",
      "Epoch [496/500], Loss: 0.5794\n",
      "total loss: 0.5794240832328796\n",
      "Epoch [497/500], Loss: 0.5794\n",
      "total loss: 0.579404354095459\n",
      "Epoch [498/500], Loss: 0.5794\n",
      "total loss: 0.5793852806091309\n",
      "Epoch [499/500], Loss: 0.5794\n",
      "total loss: 0.5793666243553162\n",
      "Epoch [500/500], Loss: 0.5794\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "trained_model = train_model(input_data, desired_output, 500, viz_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model, new_data, expected_result):\n",
    "    test_input = torch.tensor(new_data, dtype=torch.float32)\n",
    "\n",
    "    test_output = trained_model(test_input)\n",
    "    print(test_output)\n",
    "\n",
    "    predicted_classes = torch.argmax(test_output, dim=1)\n",
    "    print(predicted_classes)\n",
    "\n",
    "    test_output_compare = torch.tensor(expected_result, dtype=torch.int)\n",
    "    print(test_output_compare)\n",
    "\n",
    "    return float(sum(test_output_compare == predicted_classes)/len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 6.3758e-29],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [9.9982e-01, 1.8189e-04],\n",
      "        ...,\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [8.5420e-12, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1], dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16089\\AppData\\Local\\Temp\\ipykernel_24780\\2208809294.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_output_compare = torch.tensor(expected_result, dtype=torch.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7160000205039978"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"matrices_test.csv\")\n",
    "just_input_test = test_df.drop('last', axis=1)\n",
    "input_data_test = np.array(just_input_test.values.tolist())\n",
    "desired_output = torch.tensor(test_df['last'].tolist(), dtype=torch.float32).long()\n",
    "\n",
    "test_model(trained_model, input_data_test, desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
